<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>My Little World</title>
  
  <subtitle>learn and share</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoohannah.github.io/"/>
  <updated>2025-01-31T16:44:28.848Z</updated>
  <id>http://yoohannah.github.io/</id>
  
  <author>
    <name>YooHannah</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>è¶…å‚æ•°è°ƒä¼˜</title>
    <link href="http://yoohannah.github.io/post/deepLearning/HyperparameterTuning.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/HyperparameterTuning.html</id>
    <published>2025-01-31T13:26:37.000Z</published>
    <updated>2025-01-31T16:44:28.848Z</updated>
    
    <content type="html"><![CDATA[<h1 id="è¶…å‚æ•°å¦‚ä½•å–å€¼"><a href="#è¶…å‚æ•°å¦‚ä½•å–å€¼" class="headerlink" title="è¶…å‚æ•°å¦‚ä½•å–å€¼"></a>è¶…å‚æ•°å¦‚ä½•å–å€¼</h1><h2 id="ç›´æ¥è°ƒä¼˜"><a href="#ç›´æ¥è°ƒä¼˜" class="headerlink" title="ç›´æ¥è°ƒä¼˜"></a>ç›´æ¥è°ƒä¼˜</h2><p>æ ¹æ®ç»éªŒå¯¹äºè¶…å‚æ•°çš„é‡è¦æ€§è¿›è¡Œæ’åº</p><ol><li>å­¦ä¹ ç‡</li><li>momentum çš„Î²ï¼ˆ~0.9ï¼‰;éšè—å±‚çš„ç¥ç»å…ƒæ•°é‡;mini batch size</li><li>éšè—å±‚çš„æ•°é‡ï¼›å­¦ä¹ ç‡çš„è¡°å‡ç‡</li><li>adam çš„Î²1ï¼ˆ~0.9ï¼‰ï¼ŒÎ²2ï¼ˆ~0.999ï¼‰Î£ï¼ˆ10^-8ï¼‰è¿™ä¸‰è€…ä¸€èˆ¬å›ºå®šï¼Œå¾ˆå°‘éœ€è¦è°ƒè¯•</li></ol><p>æ•°å€¼é€‰æ‹©ä¸Šéµå¾ªéšæœºå–å€¼å’Œç²¾ç¡®æœç´¢çš„åŸåˆ™<br>éšæœºå–å€¼å¯ä»¥å¿«é€Ÿæ‰¾åˆ°å½±å“è¾ƒå¤§çš„è¶…å‚æ•°ï¼Œç¡®å®šèŒƒå›´åï¼Œç²¾ç¡®æœç´¢å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–è¶…å‚æ•°ï¼Œç”±ç²—ç³™åˆ°ç²¾ç»†</p><p><img src="/image/deepLearning/78.png" alt><br><img src="/image/deepLearning/79.png" alt><br><img src="/image/deepLearning/80.png" alt></p><h2 id="å€Ÿé‰´å·²æœ‰å…¶ä»–é¢†åŸŸæ¨¡å‹ï¼Œå¤ç”¨å…¶å‚æ•°è¿›è¡Œæµ‹è¯•è¯„ä¼°"><a href="#å€Ÿé‰´å·²æœ‰å…¶ä»–é¢†åŸŸæ¨¡å‹ï¼Œå¤ç”¨å…¶å‚æ•°è¿›è¡Œæµ‹è¯•è¯„ä¼°" class="headerlink" title="å€Ÿé‰´å·²æœ‰å…¶ä»–é¢†åŸŸæ¨¡å‹ï¼Œå¤ç”¨å…¶å‚æ•°è¿›è¡Œæµ‹è¯•è¯„ä¼°"></a>å€Ÿé‰´å·²æœ‰å…¶ä»–é¢†åŸŸæ¨¡å‹ï¼Œå¤ç”¨å…¶å‚æ•°è¿›è¡Œæµ‹è¯•è¯„ä¼°</h2><h2 id="æ ¹æ®è®¡ç®—èƒ½åŠ›é€‰æ‹©è°ƒè¯•æ–¹å¼"><a href="#æ ¹æ®è®¡ç®—èƒ½åŠ›é€‰æ‹©è°ƒè¯•æ–¹å¼" class="headerlink" title="æ ¹æ®è®¡ç®—èƒ½åŠ›é€‰æ‹©è°ƒè¯•æ–¹å¼"></a>æ ¹æ®è®¡ç®—èƒ½åŠ›é€‰æ‹©è°ƒè¯•æ–¹å¼</h2><p>1ï¼Œå¦‚æœè®¡ç®—èƒ½åŠ›æœ‰é™ï¼Œä¸€æ¬¡è¿›è¡Œä¸€ä¸ªæ¨¡å‹çš„è®­ç»ƒè°ƒè¯•ï¼Œç”¨æ—¶é—´æ¢å–æ•ˆæœ<br>2ï¼Œå¦‚æœè®¡ç®—èƒ½åŠ›å……è¶³ï¼Œä¸€æ¬¡åŒæ—¶è¿›è¡Œå¤šä¸ªæ¨¡å‹çš„ä¸åŒè¶…å‚è®­ç»ƒè°ƒè¯•ï¼Œç”¨å¹¶è¡Œæ¢å–æ—¶é—´</p><h1 id="batchå½’ä¸€åŒ–å¤„ç†"><a href="#batchå½’ä¸€åŒ–å¤„ç†" class="headerlink" title="batchå½’ä¸€åŒ–å¤„ç†"></a>batchå½’ä¸€åŒ–å¤„ç†</h1><p>åŸºäºå¯¹è¾“å…¥æ ·æœ¬æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†å¯åŠ é€Ÿç®—æ³•è®­ç»ƒå­¦ä¹ çš„åŸç†ï¼Œå¯¹éšå±‚çš„è¾“å…¥æ•°æ®ä¹ŸåŒæ ·è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œ<br>å¯ä»¥é™ä½å‰ä¸€å±‚çš„æ•°æ®è®¡ç®—ç»“æŸå˜åŠ¨å¯¹åä¸€å±‚è®¡ç®—çš„å½±å“ï¼Œé™ä½å‰åå±‚çš„è”ç³»ï¼Œæ¯ä¸€å±‚éƒ½å¯ä»¥ç‹¬ç«‹å­¦ä¹ ï¼Œä»è€ŒåŠ é€Ÿç®—æ³•çš„è®­ç»ƒé€Ÿåº¦<br><img src="/image/deepLearning/81.png" alt><br><img src="/image/deepLearning/82.png" alt><br><img src="/image/deepLearning/83.png" alt><br><img src="/image/deepLearning/84.png" alt><br><img src="/image/deepLearning/85.png" alt><br><img src="/image/deepLearning/86.png" alt></p><h1 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h1><p>Softmax ç®—æ³•æ˜¯ä¸€ç§ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡çš„å‡½æ•°ï¼Œé€šå¸¸åº”ç”¨äºç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚ï¼Œä»¥å°†ç½‘ç»œçš„è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚<br>å®ƒå¯ä»¥å°†ä¸€ä¸ªæœªå½’ä¸€åŒ–çš„å‘é‡ï¼ˆå³åŸå§‹çš„ç½‘ç»œè¾“å‡ºï¼‰è½¬æ¢ä¸ºä¸€ä¸ªå½’ä¸€åŒ–çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´ï¼Œå¹¶ä¸”æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡å’Œä¸º 1ã€‚<br><img src="/image/deepLearning/87.png" alt></p><h1 id="TensorFlow-æ¡†æ¶å­¦ä¹ "><a href="#TensorFlow-æ¡†æ¶å­¦ä¹ " class="headerlink" title="TensorFlow æ¡†æ¶å­¦ä¹ "></a>TensorFlow æ¡†æ¶å­¦ä¹ </h1><p><img src="/image/deepLearning/88.png" alt></p><blockquote><p>What you should remember: - Tensorflow is a programming framework used in deep learning - The two main object classes in tensorflow are Tensors and Operators. - When you code in tensorflow you have to take the following steps: - Create a graph containing Tensors (Variables, Placeholders â€¦) and Operations (tf.matmul, tf.add, â€¦) - Create a session - Initialize the session - Run the session to execute the graph - You can execute the graph multiple times as youâ€™ve seen in model() - The backpropagation and optimization is automatically done when running the session on the â€œoptimizerâ€ object.</p></blockquote><p><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/TensorFlow/index.py" target="_blank" rel="noopener">å®éªŒ</a><br><a href="https://github.com/GeeeekExplorer/AndrewNg-Deep-Learning/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/week7/TensorFlow%20Tutorial%20Solution.ipynb" target="_blank" rel="noopener">ç»ƒä¹ ä»£ç </a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;è¶…å‚æ•°å¦‚ä½•å–å€¼&quot;&gt;&lt;a href=&quot;#è¶…å‚æ•°å¦‚ä½•å–å€¼&quot; class=&quot;headerlink&quot; title=&quot;è¶…å‚æ•°å¦‚ä½•å–å€¼&quot;&gt;&lt;/a&gt;è¶…å‚æ•°å¦‚ä½•å–å€¼&lt;/h1&gt;&lt;h2 id=&quot;ç›´æ¥è°ƒä¼˜&quot;&gt;&lt;a href=&quot;#ç›´æ¥è°ƒä¼˜&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>ä¸€äº›ä¼˜åŒ–æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•</title>
    <link href="http://yoohannah.github.io/post/deepLearning/OptGradientDescent.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/OptGradientDescent.html</id>
    <published>2025-01-31T06:57:37.000Z</published>
    <updated>2025-01-31T16:45:46.479Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•"><a href="#å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•" class="headerlink" title="å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•"></a>å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•</h1><p>åœ¨å•è½®è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸å†ä¸€æ¬¡ä»è®¡ç®—æ•´ä¸ªè®­ç»ƒæ•°æ®ï¼Œå°†æ•´ä¸ªè®­ç»ƒæ•°æ®åˆ†æ‰¹è¿›è¡Œè®­ç»ƒï¼Œæ¯æ‰¹ï¼ˆepochï¼‰è®­ç»ƒçš„æ ·æœ¬æ•°ç§°ä¸ºbatch size</p><p>batch size æœ€å¤§ç­‰äºæ•´ä¸ªè®­ç»ƒæ ·æœ¬æ•°mæ—¶ï¼Œç›¸å½“äºè¿›è¡Œä¸€æ¬¡æ‰¹é‡è¿ç®—ï¼Œå°±æ˜¯æ ‡å‡†çš„æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•,<br>éœ€è¦è®¡ç®—å®ŒåŸºäºæ•´ä¸ªè®­ç»ƒæ ·æœ¬å‚æ•°å’ŒæŸå¤±å‡½æ•°ï¼ŒèŠ±è´¹æ—¶é—´è¾ƒé•¿ï¼Œç„¶åæ‰èƒ½è¿›è¡Œæ¢¯åº¦ä¸‹é™è®¡ç®—</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># (Batch) Gradient Descent:</span><br><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">parameters = initialize_parameters(layers_dims)</span><br><span class="line">for i in range(0, num_iterations):</span><br><span class="line">    # Forward propagation</span><br><span class="line">    a, caches = forward_propagation(X, parameters)</span><br><span class="line">    # Compute cost.</span><br><span class="line">    cost += compute_cost(a, Y)</span><br><span class="line">    # Backward propagation.</span><br><span class="line">    grads = backward_propagation(a, caches, parameters)</span><br><span class="line">    # Update parameters.</span><br><span class="line">    parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure><p>batch size æœ€å°ç­‰äº1æ—¶ï¼Œå°±æ˜¯ä¸€ä¸ªæ‰¹æ¬¡å¤„ç†ä¸€ä¸ªæ•°æ®, é€Ÿåº¦å¿«ï¼Œä½†æ˜¯æ²¡æ³•åˆ©ç”¨å‘é‡åŠ é€Ÿæ¢¯åº¦ä¸‹é™ï¼Œä¹Ÿç§°ä¸ºéšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•Stochastic Gradient Descent:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Stochastic Gradient Descent:</span><br><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">parameters = initialize_parameters(layers_dims)</span><br><span class="line">for i in range(0, num_iterations):</span><br><span class="line">    for j in range(0, m):</span><br><span class="line">        # Forward propagation</span><br><span class="line">        a, caches = forward_propagation(X[:,j], parameters) # X[:,j] ä»måˆ—ä¸­ï¼Œæ¯æ¬¡å–ä¸€åˆ—ï¼Œå°±æ˜¯ä¸€ä¸ªæ ·æœ¬</span><br><span class="line">        # Compute cost</span><br><span class="line">        cost += compute_cost(a, Y[:,j])</span><br><span class="line">        # Backward propagation</span><br><span class="line">        grads = backward_propagation(a, caches, parameters)</span><br><span class="line">        # Update parameters.</span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure></p><p>å½“batch size ä»‹äº1å’Œmä¹‹é—´æ—¶ï¼Œå°±æ˜¯å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•Mini-batch Gradient Descent<br>å°æ‰¹é‡æ¢¯åº¦ä¸‹é™å¤„ç†æ•°æ®åˆ†ä¸¤æ­¥ï¼Œ<br>ä¸€æ­¥æ˜¯æ··æ´—æ•°æ®ï¼Œå°†æ•°æ®é›†é¡ºåºæ‰“ä¹±ï¼Œä½†ä¿è¯X(i) å’Œ Yï¼ˆiï¼‰æ˜¯ä¸€ä¸€å¯¹åº”çš„<br>ç¬¬äºŒæ­¥æ˜¯å°†æ•°æ®åˆ†æˆå¤šä¸ªbatchï¼Œæ¯ä¸ªbatchåŒ…å«batch size ä¸ªæ ·æœ¬ï¼Œéœ€è¦æ³¨æ„å¦‚æœm ä¸èƒ½æ•´é™¤batch sizeï¼Œæœ€åä¸€ä¸ªbatch æ˜¯ä¸è¶³batch size ä¸ªæ ·æœ¬ï¼Œéœ€è¦å•ç‹¬å¤„ç†</p><blockquote><p>Shuffling and Partitioning are the two steps required to build mini-batches -<br>Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: random_mini_batches</span><br><span class="line"></span><br><span class="line">def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Creates a list of random minibatches from (X, Y)</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    X -- input data, of shape (input size, number of examples)</span><br><span class="line">    Y -- true &quot;label&quot; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span><br><span class="line">    mini_batch_size -- size of the mini-batches, integer</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    np.random.seed(seed)            # To make your &quot;random&quot; minibatches the same as ours</span><br><span class="line">    m = X.shape[1]                  # number of training examples</span><br><span class="line">    mini_batches = []</span><br><span class="line">        </span><br><span class="line">    # Step 1: Shuffle (X, Y)</span><br><span class="line">    permutation = list(np.random.permutation(m))</span><br><span class="line">    shuffled_X = X[:, permutation]</span><br><span class="line">    shuffled_Y = Y[:, permutation].reshape((1,m))</span><br><span class="line"></span><br><span class="line">    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span><br><span class="line">    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning</span><br><span class="line">    for k in range(0, num_complete_minibatches):</span><br><span class="line">        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + 1) * mini_batch_size]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + 1) * mini_batch_size]</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">    </span><br><span class="line">    # Handling the end case (last mini-batch &lt; mini_batch_size)</span><br><span class="line">    if m % mini_batch_size != 0:</span><br><span class="line">        ### START CODE HERE ### (approx. 2 lines)</span><br><span class="line">        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size :]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size :]</span><br><span class="line">        ### END CODE HERE ###</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line">    </span><br><span class="line">    return mini_batches</span><br></pre></td></tr></table></figure><p>è¿­ä»£è¿‡ç¨‹å¤„ç†çš„æ•°æ®é›†å°±æ˜¯ä¸Šé¢åˆ†æ‰¹å¥½çš„mini_batches</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mini_batches = random_mini_batches(X, Y, mini_batch_size = 64, seed = 0)</span><br><span class="line">t =  math.floor(m/mini_batch_size)</span><br><span class="line">if m % mini_batch_size != 0</span><br><span class="line">  t+=1</span><br><span class="line">for i in range(0, num_iterations):</span><br><span class="line">    for j in range(0, t):</span><br><span class="line">        # Forward propagation</span><br><span class="line">        a, caches = forward_propagation(mini_batches[j][0], parameters) # å–ä¸€æ‰¹è®¡ç®—ä¸€æ‰¹ï¼Œä¸ç”¨æ•´ä¸ªè®¡ç®—å®Œå†æ›´æ–°æ¢¯åº¦</span><br><span class="line">        # Compute cost</span><br><span class="line">        cost += compute_cost(a, mini_batches[j][1])</span><br><span class="line">        # Backward propagation</span><br><span class="line">        grads = backward_propagation(a, caches, parameters)</span><br><span class="line">        # Update parameters.</span><br><span class="line">        parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure><blockquote><p>The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step. - You have to tune a learning rate hyperparameter  ğ›¼ . - With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).</p></blockquote><p><img src="/image/deepLearning/65.png" alt><br><img src="/image/deepLearning/66.png" alt><br><img src="/image/deepLearning/67.png" alt><br><img src="/image/deepLearning/68.png" alt></p><h1 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h1><h2 id="æŒ‡æ•°åŠ æƒå¹³å‡"><a href="#æŒ‡æ•°åŠ æƒå¹³å‡" class="headerlink" title="æŒ‡æ•°åŠ æƒå¹³å‡"></a>æŒ‡æ•°åŠ æƒå¹³å‡</h2><p>æŒ‡æ•°åŠ æƒå¹³å‡ï¼ˆExponential Weighted Moving Average, EWMAï¼‰æ˜¯ä¸€ç§ç”¨äºå¹³æ»‘æ—¶é—´åºåˆ—æ•°æ®çš„æŠ€æœ¯ã€‚<br>å®ƒé€šè¿‡å¯¹æ•°æ®ç‚¹èµ‹äºˆä¸åŒçš„æƒé‡æ¥è®¡ç®—å¹³å‡å€¼ï¼Œè¾ƒæ–°çš„æ•°æ®ç‚¹æƒé‡è¾ƒå¤§ï¼Œè¾ƒæ—§çš„æ•°æ®ç‚¹æƒé‡è¾ƒå°ã€‚<br>è¿™æ ·å¯ä»¥æ›´æ•æ„Ÿåœ°åæ˜ æœ€æ–°æ•°æ®çš„å˜åŒ–ï¼ŒåŒæ—¶ä¿ç•™å†å²æ•°æ®çš„è¶‹åŠ¿ã€‚<br>æŒ‡æ•°åŠ æƒå¹³å‡çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p><p>St = Î² <em> St-1 + ï¼ˆ1-Î²ï¼‰ </em> Xt<br>å…¶ä¸­ï¼š<br> Stæ˜¯æ—¶é—´ t æ—¶åˆ»çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ã€‚<br> Xtæ˜¯æ—¶é—´ t æ—¶åˆ»çš„å®é™…æ•°æ®å€¼ã€‚<br> Î² æ˜¯å¹³æ»‘å› å­ï¼Œå–å€¼èŒƒå›´åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚è¾ƒå¤§çš„  å€¼ä½¿å¾— EWMA å¯¹æœ€æ–°æ•°æ®æ›´æ•æ„Ÿï¼Œè¾ƒå°çš„  å€¼åˆ™ä½¿å¾— EWMA æ›´å¹³æ»‘ã€‚<br> St-1æ˜¯æ—¶é—´ t-1 æ—¶åˆ»çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ã€‚<br>è§£é‡Š<br>åˆå§‹å€¼ï¼šé€šå¸¸ï¼Œåˆå§‹çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ S0  å¯ä»¥è®¾ç½®ä¸ºç¬¬ä¸€ä¸ªæ•°æ®ç‚¹ X0 ã€‚<br>é€’å½’è®¡ç®—ï¼šæ¯ä¸ªæ–°çš„æ•°æ®ç‚¹éƒ½ä¼šæ›´æ–° EWMAï¼Œæ–°çš„ EWMA æ˜¯å½“å‰æ•°æ®ç‚¹å’Œå‰ä¸€ä¸ª EWMA çš„åŠ æƒå’Œã€‚<br>å¹³æ»‘å› å­ ï¼šå†³å®šäº†æ–°æ•°æ®ç‚¹å’Œå†å²æ•°æ®å¯¹å½“å‰ EWMA çš„å½±å“ç¨‹åº¦ã€‚è¾ƒå¤§çš„  å€¼ä¼šä½¿å¾— EWMA å¯¹æ–°æ•°æ®ç‚¹å˜åŒ–æ›´æ•æ„Ÿï¼Œè¾ƒå°çš„  å€¼ä¼šä½¿å¾— EWMA æ›´å¹³æ»‘ï¼Œå—å†å²æ•°æ®å½±å“æ›´å¤§ã€‚</p><h3 id="åå·®ä¿®æ­£"><a href="#åå·®ä¿®æ­£" class="headerlink" title="åå·®ä¿®æ­£"></a>åå·®ä¿®æ­£</h3><p>åœ¨è®¡ç®— EWMA æ—¶ï¼Œåˆå§‹å€¼çš„é€‰æ‹©å¯¹åç»­è®¡ç®—çš„å½±å“è¾ƒå¤§ã€‚ç‰¹åˆ«æ˜¯åœ¨æ•°æ®åºåˆ—çš„åˆå§‹é˜¶æ®µï¼Œ<br>ç”±äºç¼ºä¹è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œè®¡ç®—çš„å¹³å‡å€¼å¯èƒ½ä¼šåç¦»çœŸå®å€¼ã€‚<br>å› æ­¤ï¼Œéœ€è¦å¯¹åˆå§‹é˜¶æ®µçš„è®¡ç®—ç»“æœè¿›è¡Œä¿®æ­£ï¼Œä»¥å‡å°è¿™ç§åå·®ã€‚<br>ä¸ºäº†è¿›è¡Œåå·®ä¿®æ­£ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼ï¼š<br>St^ = St / (1 - Î²^t)<br>å…¶ä¸­ï¼š<br>St^æ˜¯ç»è¿‡åå·®ä¿®æ­£çš„æ—¶é—´ t æ—¶åˆ»çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ã€‚<br>Stæ˜¯æ—¶é—´ t æ—¶åˆ»çš„æœªä¿®æ­£çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ã€‚<br>tæ˜¯æ—¶é—´æ­¥æ•°ï¼Œä»1 å¼€å§‹ï¼Œå®ƒæ˜¯Î²^t æ˜¯æŒ‡Î²çš„ t æ¬¡æ–¹ã€‚<br>é€šè¿‡å¯¹åˆå§‹å€¼è¿›è¡Œä¿®æ­£ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ EWMA åœ¨åˆå§‹é˜¶æ®µæ›´æ¥è¿‘çœŸå®å€¼ï¼Œä»è€Œå‡å°‘åå·®ã€‚<br>ä¿®æ­£åçš„ EWMA å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å‡†ç¡®åœ°åæ˜ æ•°æ®çš„è¶‹åŠ¿å’Œå˜åŒ–ã€‚</p><h2 id="momentum-1"><a href="#momentum-1" class="headerlink" title="momentum"></a>momentum</h2><p>momentum æ˜¯ä¸€ç§ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºåŠ é€Ÿæ¢¯åº¦ä¸‹é™è¿‡ç¨‹ã€‚å®ƒé€šè¿‡å¼•å…¥åŠ¨é‡ï¼ˆmomentumï¼‰çš„æ¦‚å¿µæ¥åŠ é€Ÿå‚æ•°çš„æ›´æ–°ã€‚<br>åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œmomentum ä¼šè€ƒè™‘ä¸Šä¸€æ¬¡è¿­ä»£çš„æ¢¯åº¦æ–¹å‘ï¼Œå¹¶æ ¹æ®åŠ¨é‡çš„å¤§å°æ¥è°ƒæ•´å½“å‰çš„æ¢¯åº¦æ–¹å‘ã€‚<br>è¿™æ ·å¯ä»¥åœ¨æ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹ä¸­ï¼Œæ›´åŠ å¹³æ»‘åœ°æ›´æ–°å‚æ•°ï¼Œä»è€ŒåŠ é€Ÿæ”¶æ•›ã€‚<br>momentum çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š<br>VdW = Î² <em> VdW + (1 - Î²) </em> dW<br>Vdb = Î² <em> Vdb + (1 - Î²) </em> db<br>W = W - Î± <em> VdW<br>b = b - Î± </em> Vdb<br>å…¶ä¸­ï¼š<br>VdWæ˜¯æƒé‡å‚æ•°Wçš„åŠ¨é‡ã€‚<br>Vdbæ˜¯åç½®å‚æ•°bçš„åŠ¨é‡ã€‚<br>dWæ˜¯æƒé‡å‚æ•°Wçš„æ¢¯åº¦ã€‚<br>dbæ˜¯åç½®å‚æ•°bçš„æ¢¯åº¦ã€‚<br>Î±æ˜¯å­¦ä¹ ç‡ã€‚<br>Î²æ˜¯åŠ¨é‡å› å­ï¼Œé€šå¸¸å–å€¼åœ¨0.9åˆ°0.99ä¹‹é—´ã€‚</p><p>ç”±äºå°æ‰¹é‡æ¢¯åº¦ä¸‹é™æ‰€é‡‡ç”¨çš„è·¯å¾„å°†â€œæŒ¯è¡â€è‡³æ”¶æ•›ï¼Œåˆ©ç”¨momentumå¯ä»¥å‡å°‘è¿™äº›æŒ¯è¡ã€‚<br>ï¼ˆå°†VdWï¼Œå¸¦å…¥Wæ›´æ–°å¼å­è®¡ç®—ï¼Œä¼šå‘ç° W ä¸‹é™çš„æ¯”ä¹‹å‰è¦æ…¢ä¸€äº›ï¼Œè´Ÿè´Ÿå¾—æ­£ï¼Œä¼šåŠ å›æ¥-Î² <em> VdW + Î² </em> dWï¼‰<br><img src="/image/deepLearning/70.png" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: initialize_velocity</span><br><span class="line"></span><br><span class="line">def initialize_velocity(parameters):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Initializes the velocity as a python dictionary with:</span><br><span class="line">                - keys: &quot;dW1&quot;, &quot;db1&quot;, ..., &quot;dWL&quot;, &quot;dbL&quot; </span><br><span class="line">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span><br><span class="line">    Arguments:</span><br><span class="line">    parameters -- python dictionary containing your parameters.</span><br><span class="line">                    parameters[&apos;W&apos; + str(l)] = Wl</span><br><span class="line">                    parameters[&apos;b&apos; + str(l)] = bl</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    v -- python dictionary containing the current velocity.</span><br><span class="line">                    v[&apos;dW&apos; + str(l)] = velocity of dWl</span><br><span class="line">                    v[&apos;db&apos; + str(l)] = velocity of dbl</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // 2 # number of layers in the neural networks</span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    # Initialize velocity</span><br><span class="line">    for l in range(L):</span><br><span class="line">        v[&quot;dW&quot; + str(l+1)] = np.zeros_like(parameters[&quot;W&quot; + str(l+1)])</span><br><span class="line">        v[&quot;db&quot; + str(l+1)] = np.zeros_like(parameters[&quot;b&quot; + str(l+1)])</span><br><span class="line">        </span><br><span class="line">    return v</span><br></pre></td></tr></table></figure></p><p><img src="/image/deepLearning/69.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># GRADED FUNCTION: update_parameters_with_momentum</span><br><span class="line"></span><br><span class="line">def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Update parameters using Momentum</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    parameters -- python dictionary containing your parameters:</span><br><span class="line">                    parameters[&apos;W&apos; + str(l)] = Wl</span><br><span class="line">                    parameters[&apos;b&apos; + str(l)] = bl</span><br><span class="line">    grads -- python dictionary containing your gradients for each parameters:</span><br><span class="line">                    grads[&apos;dW&apos; + str(l)] = dWl</span><br><span class="line">                    grads[&apos;db&apos; + str(l)] = dbl</span><br><span class="line">    v -- python dictionary containing the current velocity:</span><br><span class="line">                    v[&apos;dW&apos; + str(l)] = ...</span><br><span class="line">                    v[&apos;db&apos; + str(l)] = ...</span><br><span class="line">    beta -- the momentum hyperparameter, scalar</span><br><span class="line">    learning_rate -- the learning rate, scalar</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    parameters -- python dictionary containing your updated parameters </span><br><span class="line">    v -- python dictionary containing your updated velocities</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    L = len(parameters) // 2 # number of layers in the neural networks</span><br><span class="line">    </span><br><span class="line">    # Momentum update for each parameter</span><br><span class="line">    for l in range(L):</span><br><span class="line">        </span><br><span class="line">        # compute velocities</span><br><span class="line">        v[&quot;dW&quot; + str(l+1)] = beta * v[&quot;dW&quot; + str(l+1)] + (1 - beta) * grads[&quot;dW&quot; + str(l+1)]</span><br><span class="line">        v[&quot;db&quot; + str(l+1)] = beta * v[&quot;db&quot; + str(l+1)] + (1 - beta) * grads[&quot;db&quot; + str(l+1)]</span><br><span class="line">        # update parameters</span><br><span class="line">        parameters[&quot;W&quot; + str(l+1)] -= learning_rate * v[&quot;dW&quot; + str(l+1)]</span><br><span class="line">        parameters[&quot;b&quot; + str(l+1)] -= learning_rate * v[&quot;db&quot; + str(l+1)]</span><br><span class="line">        </span><br><span class="line">    return parameters, v</span><br></pre></td></tr></table></figure><blockquote><p>Note that:</p></blockquote><blockquote><p>The velocity is initialized with zeros. So the algorithm will take a few iterations to â€œbuild upâ€ velocity and start to take bigger steps.<br>If  ğ›½=0 , then this just becomes standard gradient descent without momentum.<br>How do you choose  ğ›½ ?</p></blockquote><blockquote><p>The larger the momentum  ğ›½  is, the smoother the update because the more we take the past gradients into account. But if  ğ›½  is too big, it could also smooth out the updates too much.<br>Common values for  ğ›½  range from 0.8 to 0.999. If you donâ€™t feel inclined to tune this,  ğ›½=0.9  is often a reasonable default.<br>Tuning the optimal  ğ›½  for your model might need trying several values to see what works best in term of reducing the value of the cost function  ğ½ .</p></blockquote><blockquote><p>Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent. - You have to tune a momentum hyperparameter  ğ›½  and a learning rate  ğ›¼ .</p></blockquote><h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><p>Root Mean Square Propagation<br>ç±»ä¼¼æŒ‡æ•°åŠ æƒå¹³å‡ï¼Œåœ¨æ›´æ”¹æ›´æ–°æ¢¯åº¦çš„é€»è¾‘ï¼Œä¸å†ç›´æ¥å‡å»å­¦ä¹ ç‡ä¹˜ä»¥æ¢¯åº¦ï¼Œè€Œæ˜¯å‡å»å­¦ä¹ ç‡ä¹˜ä»¥ä¼˜åŒ–å¤„ç†åçš„æ¢¯åº¦å€¼ï¼Œè¯¦è§å¦‚ä¸‹å…¬å¼<br><img src="/image/deepLearning/71.png" alt></p><h2 id="Adam-ä¼˜åŒ–ç®—æ³•"><a href="#Adam-ä¼˜åŒ–ç®—æ³•" class="headerlink" title="Adam ä¼˜åŒ–ç®—æ³•"></a>Adam ä¼˜åŒ–ç®—æ³•</h2><p>ç»“åˆæŒ‡æ•°å¹³å‡å’ŒRMSpropä¸¤ç§ç®—æ³•æ›´æ–°æ¢¯åº¦<br><img src="/image/deepLearning/72.png" alt><br><img src="/image/deepLearning/74.png" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: initialize_adam</span><br><span class="line"></span><br><span class="line">def initialize_adam(parameters) :</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Initializes v and s as two python dictionaries with:</span><br><span class="line">                - keys: &quot;dW1&quot;, &quot;db1&quot;, ..., &quot;dWL&quot;, &quot;dbL&quot; </span><br><span class="line">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    parameters -- python dictionary containing your parameters.</span><br><span class="line">                    parameters[&quot;W&quot; + str(l)] = Wl</span><br><span class="line">                    parameters[&quot;b&quot; + str(l)] = bl</span><br><span class="line">    </span><br><span class="line">    Returns: </span><br><span class="line">    v -- python dictionary that will contain the exponentially weighted average of the gradient.</span><br><span class="line">                    v[&quot;dW&quot; + str(l)] = ...</span><br><span class="line">                    v[&quot;db&quot; + str(l)] = ...</span><br><span class="line">    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.</span><br><span class="line">                    s[&quot;dW&quot; + str(l)] = ...</span><br><span class="line">                    s[&quot;db&quot; + str(l)] = ...</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // 2 # number of layers in the neural networks</span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    s = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    # Initialize v, s. Input: &quot;parameters&quot;. Outputs: &quot;v, s&quot;.</span><br><span class="line">    for l in range(L):</span><br><span class="line">        v[&quot;dW&quot; + str(l+1)] = np.zeros_like(parameters[&quot;W&quot; + str(l+1)])</span><br><span class="line">        v[&quot;db&quot; + str(l+1)] = np.zeros_like(parameters[&quot;b&quot; + str(l+1)])</span><br><span class="line">        s[&quot;dW&quot; + str(l+1)] = np.zeros_like(parameters[&quot;W&quot; + str(l+1)])</span><br><span class="line">        s[&quot;db&quot; + str(l+1)] = np.zeros_like(parameters[&quot;b&quot; + str(l+1)])</span><br><span class="line">    </span><br><span class="line">    return v, s</span><br><span class="line"></span><br><span class="line"># GRADED FUNCTION: update_parameters_with_adam</span><br><span class="line"></span><br><span class="line">def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,</span><br><span class="line">                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Update parameters using Adam</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    parameters -- python dictionary containing your parameters:</span><br><span class="line">                    parameters[&apos;W&apos; + str(l)] = Wl</span><br><span class="line">                    parameters[&apos;b&apos; + str(l)] = bl</span><br><span class="line">    grads -- python dictionary containing your gradients for each parameters:</span><br><span class="line">                    grads[&apos;dW&apos; + str(l)] = dWl</span><br><span class="line">                    grads[&apos;db&apos; + str(l)] = dbl</span><br><span class="line">    v -- Adam variable, moving average of the first gradient, python dictionary</span><br><span class="line">    s -- Adam variable, moving average of the squared gradient, python dictionary</span><br><span class="line">    learning_rate -- the learning rate, scalar.</span><br><span class="line">    beta1 -- Exponential decay hyperparameter for the first moment estimates </span><br><span class="line">    beta2 -- Exponential decay hyperparameter for the second moment estimates </span><br><span class="line">    epsilon -- hyperparameter preventing division by zero in Adam updates</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">    parameters -- python dictionary containing your updated parameters </span><br><span class="line">    v -- Adam variable, moving average of the first gradient, python dictionary</span><br><span class="line">    s -- Adam variable, moving average of the squared gradient, python dictionary</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    L = len(parameters) // 2                 # number of layers in the neural networks</span><br><span class="line">    v_corrected = &#123;&#125;                         # Initializing first moment estimate, python dictionary</span><br><span class="line">    s_corrected = &#123;&#125;                         # Initializing second moment estimate, python dictionary</span><br><span class="line">    </span><br><span class="line">    # Perform Adam update on all parameters</span><br><span class="line">    for l in range(L):</span><br><span class="line">        # Moving average of the gradients. Inputs: &quot;v, grads, beta1&quot;. Output: &quot;v&quot;.</span><br><span class="line">        v[&quot;dW&quot; + str(l+1)] = beta1 * v[&quot;dW&quot; + str(l+1)] + (1 - beta1) * grads[&quot;dW&quot; + str(l+1)]</span><br><span class="line">        v[&quot;db&quot; + str(l+1)] = beta1 * v[&quot;db&quot; + str(l+1)] + (1 - beta1) * grads[&quot;db&quot; + str(l+1)]</span><br><span class="line"></span><br><span class="line">        # Compute bias-corrected first moment estimate. Inputs: &quot;v, beta1, t&quot;. Output: &quot;v_corrected&quot;.</span><br><span class="line">        v_corrected[&quot;dW&quot; + str(l+1)] = v[&quot;dW&quot; + str(l+1)] / (1 - beta1 ** t)</span><br><span class="line">        v_corrected[&quot;db&quot; + str(l+1)] = v[&quot;db&quot; + str(l+1)] / (1 - beta1 ** t)</span><br><span class="line"></span><br><span class="line">        # Moving average of the squared gradients. Inputs: &quot;s, grads, beta2&quot;. Output: &quot;s&quot;.</span><br><span class="line">        s[&quot;dW&quot; + str(l+1)] = beta2 * s[&quot;dW&quot; + str(l+1)] + (1 - beta2) * grads[&quot;dW&quot; + str(l+1)] ** 2</span><br><span class="line">        s[&quot;db&quot; + str(l+1)] = beta2 * s[&quot;db&quot; + str(l+1)] + (1 - beta2) * grads[&quot;db&quot; + str(l+1)] ** 2</span><br><span class="line"></span><br><span class="line">        # Compute bias-corrected second raw moment estimate. Inputs: &quot;s, beta2, t&quot;. Output: &quot;s_corrected&quot;.</span><br><span class="line">        s_corrected[&quot;dW&quot; + str(l+1)] = s[&quot;dW&quot; + str(l+1)] / (1 - beta2 ** t)</span><br><span class="line">        s_corrected[&quot;db&quot; + str(l+1)] = s[&quot;db&quot; + str(l+1)] / (1 - beta2 ** t)</span><br><span class="line"></span><br><span class="line">        # Update parameters. Inputs: &quot;parameters, learning_rate, v_corrected, s_corrected, epsilon&quot;. Output: &quot;parameters&quot;.</span><br><span class="line">        parameters[&quot;W&quot; + str(l+1)] -= learning_rate * v_corrected[&quot;dW&quot; + str(l+1)] / (np.sqrt(s_corrected[&quot;dW&quot; + str(l+1)]) + epsilon)</span><br><span class="line">        parameters[&quot;b&quot; + str(l+1)] -= learning_rate * v_corrected[&quot;db&quot; + str(l+1)] / (np.sqrt(s_corrected[&quot;db&quot; + str(l+1)]) + epsilon)</span><br><span class="line"></span><br><span class="line">    return parameters, v, s</span><br></pre></td></tr></table></figure></p><p><img src="/image/deepLearning/73.png" alt><br><a href="https://arxiv.org/pdf/1412.6980" target="_blank" rel="noopener">Adam ç®—æ³•åŸç†</a></p><h1 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h1><p><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/OptGradientDescent/index.py" target="_blank" rel="noopener">ä¸Šé¢ä¸‰ç§ç®—æ³•ç»ƒä¹ </a></p><p>å°ç»“</p><blockquote><p>Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.</p></blockquote><blockquote><p>Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, youâ€™ve seen that Adam converges a lot faster.</p></blockquote><p>å®éªŒæ•ˆæœAdamç®—æ³•é€Ÿåº¦å¿«ï¼Œå‡†ç¡®ç‡é«˜</p><blockquote><p>Some advantages of Adam include:</p></blockquote><blockquote><p>Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum)<br>Usually works well even with little tuning of hyperparameters (except  ğ›¼ )</p></blockquote><h1 id="å­¦ä¹ ç‡è¡°å‡"><a href="#å­¦ä¹ ç‡è¡°å‡" class="headerlink" title="å­¦ä¹ ç‡è¡°å‡"></a>å­¦ä¹ ç‡è¡°å‡</h1><p>åœ¨å°æ‰¹é‡æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œéšç€è®¡ç®—æ‰¹æ¬¡åç§»ï¼Œé€æ¸å‡å°å­¦ä¹ ç‡çš„å€¼ï¼Œå¯ä»¥é™ä½æ¢¯åº¦éœ‡è¡å¹…åº¦ï¼ŒåŠ é€Ÿæ”¶æ•›é€Ÿåº¦<br>ä¸€äº›å­¦ä¹ ç‡è¡°å‡ç®—æ³•å¦‚ä¸‹<br><img src="/image/deepLearning/75.png" alt><br><img src="/image/deepLearning/76.png" alt></p><h1 id="ä¸¤ä¸ªç»éªŒæ³•åˆ™"><a href="#ä¸¤ä¸ªç»éªŒæ³•åˆ™" class="headerlink" title="ä¸¤ä¸ªç»éªŒæ³•åˆ™"></a>ä¸¤ä¸ªç»éªŒæ³•åˆ™</h1><p>Unlikely to get stuck in a bad local optima ä¸€èˆ¬ä¸å­˜åœ¨å±€éƒ¨æœ€ä¼˜è§£ï¼ŒæŸå¤±å‡½æ•°ä¸å‚æ•°å…³ç³»å¾€å¾€æˆé©¬éè£…<br>Plateaus can make learning slow å¹³ç¼“çš„åœ°æ–¹å¾€å¾€ä¼šé€ æˆå­¦ä¹ é€Ÿåº¦ä¸‹é™ï¼Œéœ€è¦èŠ±è´¹æ›´å¤šæ—¶é—´æ‰¾åˆ°æ›´ä¼˜è§£</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•&quot;&gt;&lt;a href=&quot;#å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•&quot; class=&quot;headerlink&quot; title=&quot;å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•&quot;&gt;&lt;/a&gt;å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•&lt;/h1&gt;&lt;p&gt;åœ¨å•è½®è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸å†ä¸€æ¬¡ä»è®¡ç®—æ•´ä¸ªè®­ç»ƒæ•°æ®ï¼Œå°†æ•´ä¸ªè®­ç»ƒæ•°æ®åˆ†æ‰¹è¿›è¡Œè®­ç»ƒï¼Œæ¯æ‰¹ï¼ˆep
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>ä¸€äº›ä¼˜åŒ–æ·±åº¦ç¥ç»ç½‘ç»œã€è®­ç»ƒè¿‡ç¨‹ã€‘çš„æ–¹æ³•</title>
    <link href="http://yoohannah.github.io/post/deepLearning/OptNeuralNetwork.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/OptNeuralNetwork.html</id>
    <published>2025-01-29T02:48:37.000Z</published>
    <updated>2025-01-31T06:56:01.077Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ•°æ®é›†çš„ä½¿ç”¨"><a href="#æ•°æ®é›†çš„ä½¿ç”¨" class="headerlink" title="æ•°æ®é›†çš„ä½¿ç”¨"></a>æ•°æ®é›†çš„ä½¿ç”¨</h1><p>ä¸€èˆ¬å°†æ•°æ®é›†åˆ†æˆä¸‰éƒ¨åˆ†ï¼Œè®­ç»ƒé›†ï¼ˆtraining setï¼‰ï¼Œäº¤å‰éªŒè¯é›†ï¼ˆcross validation set / dev setï¼‰ï¼Œæµ‹è¯•é›†ï¼ˆtest setï¼‰<br>è®­ç»ƒé›†ç”¨äºè®­ç»ƒæ¨¡å‹<br>äº¤å‰éªŒè¯é›†ç”¨äºè°ƒæ•´è¶…å‚æ•°ï¼Œæˆ–è€…æ¯”è¾ƒä¸åŒæ¨¡å‹ç®—æ³•æ€§èƒ½çš„ä¼˜åŠ£<br>æµ‹è¯•é›†ç”¨äºå¯¹æœ€ç»ˆæ¨¡å‹çš„è¿›è¡Œæ— åè¯„ä¼°(æ˜¯å¦å­˜åœ¨æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆ)</p><p>å¦‚æœä¸éœ€è¦è¿›è¡Œæœ€ç»ˆçš„æ— åè¯„ä¼°ï¼Œé‚£ä¹ˆå¯ä»¥å°†äº¤å‰éªŒè¯é›†å’Œæµ‹è¯•é›†åˆå¹¶ä¸ºä¸€ä¸ªæ•°æ®é›†ï¼Œè¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°<br>å°†æµ‹è¯•é›†æ•°æ®åˆå¹¶åˆ°äº¤å‰éªŒè¯é›†ä¸­ï¼Œæ•°æ®é›†æœ€ç»ˆåªä¼šå‰©ä¸‹è®­ç»ƒé›†å’Œæµ‹è¯•éªŒè¯é›†</p><p>å¦å¤–éœ€è¦æ³¨æ„è¿›è¡Œè®­ç»ƒçš„æ•°æ®é›†å’ŒéªŒè¯æµ‹è¯•çš„æ•°æ®é›†è¦æ¥è‡ªåŒä¸€ä¸ªåˆ†å¸ƒï¼Œå¦åˆ™ä¼šå½±å“è®­ç»ƒé€Ÿåº¦<br>æ¯”å¦‚è®­ç»ƒé›†å›¾ç‰‡æ¥è‡ªç½‘ç»œï¼Œåˆ†è¾¨ç‡é«˜ï¼Œæ¸…æ™°åº¦é«˜ï¼Œä½†æ˜¯æµ‹è¯•é›†å›¾ç‰‡æ¥è‡ªæ‰‹æœºï¼Œåˆ†è¾¨ç‡ä½ï¼Œæ¸…æ™°åº¦ä½<br>é‚£ä¹ˆè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¯èƒ½ä¼šå¾ˆå·®</p><p><img src="/image/deepLearning/42.png" alt><br><img src="/image/deepLearning/43.png" alt></p><h1 id="ä½¿ç”¨åå·®-bias-å’Œæ–¹å·®-variance-å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°"><a href="#ä½¿ç”¨åå·®-bias-å’Œæ–¹å·®-variance-å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°" class="headerlink" title="ä½¿ç”¨åå·®(bias)å’Œæ–¹å·®(variance)å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°"></a>ä½¿ç”¨åå·®(bias)å’Œæ–¹å·®(variance)å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°</h1><p>é«˜åå·®ä¸€èˆ¬æ¬ æ‹Ÿåˆ<br>é«˜æ–¹å·®ä¸€èˆ¬è¿‡æ‹Ÿåˆ<br>å…ˆæ¥å¤ä¹ ä¸€ä¸‹åå·®å’Œæ–¹å·®çš„å®šä¹‰<br><a href="https://yoohannah.github.io/post/machineLearning/overfitting.html">è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜</a><br><a href="https://yoohannah.github.io/post/machineLearning/biasVariance.html">é«˜åå·®å’Œé«˜æ–¹å·®</a><br><img src="/image/deepLearning/44.png" alt><br><img src="/image/LLM/119.png" alt></p><h2 id="æ­£åˆ™åŒ–å¤„ç†-Regularization-è¿‡æ‹Ÿåˆé—®é¢˜"><a href="#æ­£åˆ™åŒ–å¤„ç†-Regularization-è¿‡æ‹Ÿåˆé—®é¢˜" class="headerlink" title="æ­£åˆ™åŒ–å¤„ç†(Regularization)è¿‡æ‹Ÿåˆé—®é¢˜"></a>æ­£åˆ™åŒ–å¤„ç†(Regularization)è¿‡æ‹Ÿåˆé—®é¢˜</h2><p>é€šè¿‡ç»™æˆæœ¬å‡½æ•°å¢åŠ æ­£åˆ™åŒ–é¡¹ï¼Œè¿›è¡Œæƒé‡è¡°å‡ï¼Œæ¥é™ä½æ¨¡å‹çš„æ–¹å·®ï¼Œä»è€Œé¿å…è¿‡æ‹Ÿåˆçš„å‡ºç°<br><img src="/image/deepLearning/45.png" alt><br><img src="/image/deepLearning/46.png" alt><br><img src="/image/deepLearning/48.png" alt><br><img src="/image/deepLearning/47.png" alt></p><h2 id="L2-å…·ä½“å®ç°"><a href="#L2-å…·ä½“å®ç°" class="headerlink" title="L2 å…·ä½“å®ç°"></a>L2 å…·ä½“å®ç°</h2><p><img src="/image/deepLearning/60.png" alt><br><img src="/image/deepLearning/61.png" alt></p><h2 id="Dropout-æ­£åˆ™åŒ–"><a href="#Dropout-æ­£åˆ™åŒ–" class="headerlink" title="Dropout æ­£åˆ™åŒ–"></a>Dropout æ­£åˆ™åŒ–</h2><p>dropout æ–¹æ³• å®ç°åŸç†å°±æ˜¯åœ¨æ¯å±‚è®¡ç®—å‰å‰ï¼Œç”Ÿæˆéšæœºè’™å±‚ï¼ŒæŒ‰keep_probæ¯”ä¾‹éšæœºå¹²æ‰ä¸€äº›èŠ‚ç‚¹ï¼Œå†å‚ä¸è¿ç®—ï¼Œè®¡ç®—åé™¤ä»¥keep_probï¼Œä¿è¯æœ€ç»ˆè¾“å‡ºçš„ç»“æœä¸å˜<br>åœ¨åå‘ä¼ æ’­æ—¶ï¼Œä½¿ç”¨å‘å‰ä¼ æ’­çš„è’™å±‚å¯¹æ¢¯åº¦è¿›è¡Œç›¸åº”çš„å¤„ç†ï¼Œä¿è¯è¯¥è½®çš„å‚æ•°çŸ©é˜µç›¸åŒï¼Œæ‰€ä»¥è¦å¯¹å‘å‰ä¼ æ’­çš„è’™å±‚è¿›è¡Œç¼“å­˜å¤„ç†æ–¹ä¾¿ä½¿ç”¨<br><img src="/image/deepLearning/49.png" alt><br><img src="/image/deepLearning/50.png" alt></p><p>å¯ä»¥çœ‹åˆ°ç›¸æ¯”L2 ç±»ä¼¼äºå¯¹w è¿›è¡Œç¼©å°å¤„ç†ï¼Œdropout æ–¹æ³•ç±»ä¼¼äºå¯¹w è¿›è¡Œæ”¾å¤§å¤„ç†, å› ä¸ºå¹²æ‰ä¸€äº›èŠ‚ç‚¹ç›¸å½“äºéšæœºå–æ¶ˆæŸäº›w çš„å½±å“ï¼Œæœ€åé™¤ä»¥keep_prob ç›¸å½“äºå¯¹w è¿›è¡Œæ”¾å¤§å¤„ç†</p><h2 id="å…¶å®ƒæ­£åˆ™åŒ–æ–¹æ³•"><a href="#å…¶å®ƒæ­£åˆ™åŒ–æ–¹æ³•" class="headerlink" title="å…¶å®ƒæ­£åˆ™åŒ–æ–¹æ³•"></a>å…¶å®ƒæ­£åˆ™åŒ–æ–¹æ³•</h2><p>é™¤äº†ä¸Šé¢æåˆ°ç»™costå‡½æ•°æ·»åŠ L1,L2æ­£åˆ™åŒ–é¡¹ï¼Œè¿˜å¯ä»¥é€šè¿‡dropout æ–¹æ³•ï¼Œæ•°æ®å¢å¼ºï¼Œææ—©ç»“æŸè®­ç»ƒç­‰æ­£åˆ™åŒ–æ–¹æ³•æ¥é¿å…è¿‡æ‹Ÿåˆçš„å‡ºç°<br><img src="/image/deepLearning/51.png" alt><br><img src="/image/deepLearning/52.png" alt></p><p><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/Regularization/index.py" target="_blank" rel="noopener">L2å’ŒDropoutå®éªŒ</a></p><h1 id="å½’ä¸€åŒ–è®­ç»ƒé›†"><a href="#å½’ä¸€åŒ–è®­ç»ƒé›†" class="headerlink" title="å½’ä¸€åŒ–è®­ç»ƒé›†"></a>å½’ä¸€åŒ–è®­ç»ƒé›†</h1><p>é€šè¿‡å¯¹è®­ç»ƒæ•°æ®é›†è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ŒåŠ å¿«æ¢¯åº¦ä¸‹é™ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦<br>å¤ä¹ ä¸€ä¸‹<a href="https://yoohannah.github.io/post/machineLearning/lineregression.html">ç‰¹å¾æ”¾ç¼©</a><br><img src="/image/deepLearning/53.png" alt><br><img src="/image/deepLearning/54.png" alt></p><h1 id="åˆå§‹åŒ–å‚æ•°"><a href="#åˆå§‹åŒ–å‚æ•°" class="headerlink" title="åˆå§‹åŒ–å‚æ•°"></a>åˆå§‹åŒ–å‚æ•°</h1><p>ç”±äºç¥ç»ç½‘ç»œçš„å¤šå±‚çš„è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œæƒé‡æ˜¯ä¹˜ç§¯å…³ç³»ï¼Œå¦‚æœå„å±‚åˆå§‹åŒ–å‚æ•°ä¸€å¼€å§‹å¤§äº1 æˆ–è€…å°äº1ï¼Œæ•´ä¸ªä¹˜ç§¯ä¸‹æ¥ï¼Œå°±å¯¼è‡´y^ æ— é™å¤§æˆ–è€…æ— é™å°ï¼Œä»è€Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¢¯åº¦æ¶ˆå¤±<br><img src="/image/deepLearning/55.png" alt><br>è§£å†³<br><img src="/image/deepLearning/56.png" alt><br><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/Initialization/index.py" target="_blank" rel="noopener">ä¸åŒåˆå§‹åŒ–å‚æ•°æ–¹å¼</a></p><h1 id="æ¢¯åº¦æ ¡éªŒ"><a href="#æ¢¯åº¦æ ¡éªŒ" class="headerlink" title="æ¢¯åº¦æ ¡éªŒ"></a>æ¢¯åº¦æ ¡éªŒ</h1><p>åŒè¾¹è¯¯å·®ä¼šæ¯”å•è¾¹è¯¯å·®æ›´å‡†ç¡®<br><img src="/image/deepLearning/57.png" alt><br>æ¢¯åº¦æ ¡éªŒçš„è¿‡ç¨‹å°±æ˜¯æ‹¿åˆ°ä¸€è½®è®­ç»ƒçš„å‚æ•°å’Œæ¢¯åº¦ï¼Œè¿›è¡Œæ‘Šå¹³å¤„ç†ï¼Œå­—å…¸å˜ n * 1 äºŒç»´æ•°ç»„ï¼Œæ¯ä¸€å±‚çš„æ¯ä¸€ä¸ªw æ˜¯ä¸€ä¸ªæ•°ç»„<br>å¯¹æ¯ä¸€å±‚æ¯ä¸€ä¸ªå‚æ•°ä¿®æ”¹ä¸€ä¸ªå¾ˆå°çš„å€¼ï¼Œä¸€æ¬¡åŠ ï¼Œä¸€æ¬¡å‡ï¼Œé‡æ–°è®¡ç®—cost å€¼ï¼Œæ‹¿åˆ°ä¸¤ä¸ªcost å€¼åè¿›è¡ŒåŒè¾¹è¯¯å·®è®¡ç®—ï¼Œ<br>æ•´ä¸ªå‚æ•°éƒ½è®¡ç®—å®Œåï¼Œä¸æ¢¯åº¦è¿›è¡Œæ¯”è¾ƒï¼Œè¯¦è§å…¬å¼<br>å¦‚æœæ¯”è¾ƒå€¼ç›¸å·®ä¸å¤§ï¼Œè¯´æ˜æ¢¯åº¦è®¡ç®—æ²¡æœ‰é—®é¢˜<br><img src="/image/deepLearning/58.png" alt><br><img src="/image/deepLearning/59.png" alt></p><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p><img src="/image/deepLearning/62.png" alt><br><img src="/image/deepLearning/63.png" alt><br><img src="/image/deepLearning/64.png" alt><br><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/GradientChecking/index.py" target="_blank" rel="noopener">å…·ä½“ä»£ç </a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;æ•°æ®é›†çš„ä½¿ç”¨&quot;&gt;&lt;a href=&quot;#æ•°æ®é›†çš„ä½¿ç”¨&quot; class=&quot;headerlink&quot; title=&quot;æ•°æ®é›†çš„ä½¿ç”¨&quot;&gt;&lt;/a&gt;æ•°æ®é›†çš„ä½¿ç”¨&lt;/h1&gt;&lt;p&gt;ä¸€èˆ¬å°†æ•°æ®é›†åˆ†æˆä¸‰éƒ¨åˆ†ï¼Œè®­ç»ƒé›†ï¼ˆtraining setï¼‰ï¼Œäº¤å‰éªŒè¯é›†ï¼ˆcross validation s
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>ä¸€ä¸ªå®ç°æµé€šä¿¡çš„æ¡ˆä¾‹</title>
    <link href="http://yoohannah.github.io/post/nodejs/streamExamp.html"/>
    <id>http://yoohannah.github.io/post/nodejs/streamExamp.html</id>
    <published>2025-01-26T08:17:37.000Z</published>
    <updated>2025-01-26T09:33:11.134Z</updated>
    
    <content type="html"><![CDATA[<h1 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h1><p>å‰ç«¯åŒ…æ‹¬nodeå±‚å’Œçº¯å‰ç«¯å±‚ï¼Œéœ€è¦è¯·æ±‚ç¬¬ä¸‰æ–¹httpæ¥å£åœ¨é¡µé¢å®ç°chatGTPçš„æ‰“å­—æœºæ•ˆæœ</p><h1 id="æ–¹æ¡ˆ"><a href="#æ–¹æ¡ˆ" class="headerlink" title="æ–¹æ¡ˆ"></a>æ–¹æ¡ˆ</h1><ol><li>åœ¨nodeå±‚è°ƒç”¨ç¬¬ä¸‰æ–¹httpæ¥å£ï¼Œé¿å…è·¨åŸŸé—®é¢˜</li><li>ç”±äºç¬¬ä¸‰æ–¹æ¥å£ä¸ºæµå¼æ¥å£ï¼Œä»nodeå±‚å‘å‡ºè¯·æ±‚å†è½¬å‘åˆ°å‰ç«¯ä¹Ÿéœ€è¦è¿›è¡Œæµå¼é€šä¿¡</li><li>å‰ç«¯å±‚å¯¹è¿”å›çš„æµå¼æ•°æ®è¿›è¡Œå¤„ç†åæ›´æ–°æ•°æ®å‘ˆç°åœ¨é¡µé¢ä¸Š</li></ol><h1 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h1><ol><li>å‰ç«¯å±‚ä½¿ç”¨fetchè¿›è¡Œè¯·æ±‚ï¼Œä½¿ç”¨ReadableStreamè¿›è¡Œæµå¼å¤„ç†</li><li>nodeå±‚ä½¿ç”¨axiosè¿›è¡Œè¯·æ±‚ï¼Œä½¿ç”¨streamè¿›è¡Œæµå¼å¤„ç†  </li></ol><h2 id="nodeå±‚å®ç°"><a href="#nodeå±‚å®ç°" class="headerlink" title="nodeå±‚å®ç°"></a>nodeå±‚å®ç°</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">'axios'</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; PassThrough &#125; <span class="keyword">from</span> <span class="string">'stream'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">faqStream</span>(<span class="params">body?: any</span>): <span class="title">Promise</span>&lt;<span class="title">any</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> ctx = useContext&lt;HttpContext&gt;();</span><br><span class="line">  ctx.set(&#123;</span><br><span class="line">    Connection: <span class="string">'keep-alive'</span>,</span><br><span class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/octet-stream'</span> <span class="comment">// è¡¨ç¤ºè¿”å›æ•°æ®æ˜¯ä¸ª stream</span></span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">const</span> stream = <span class="keyword">new</span> PassThrough();</span><br><span class="line">  ctx.body = stream;</span><br><span class="line">  <span class="comment">// å‘èµ·ç¬¬ä¸‰æ–¹è¯·æ±‚</span></span><br><span class="line">  <span class="keyword">const</span> headers = &#123;</span><br><span class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/json'</span></span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">const</span> url = <span class="string">'http://vvvv.xxxx.net/aiBot/oncall_response_stream'</span>;</span><br><span class="line">  axios</span><br><span class="line">    .post(url, ctx.request.body, &#123; <span class="attr">headers</span>: headers, <span class="attr">responseType</span>: <span class="string">'stream'</span> &#125;)</span><br><span class="line">    .then(<span class="function">(<span class="params">response</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (response.status !== <span class="number">200</span>) &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(<span class="string">'Error status:'</span>, response.status);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      response.data.on(<span class="string">'data'</span>, (chunk) =&gt; &#123;</span><br><span class="line">        chunk</span><br><span class="line">          .toString()</span><br><span class="line">          .split(<span class="string">'\n\n'</span>)</span><br><span class="line">          .filter(<span class="function">(<span class="params">item</span>) =&gt;</span> item)</span><br><span class="line">          .forEach(<span class="function">(<span class="params">chunkStr</span>) =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> chunkJson = &#123;&#125;;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              chunkJson = <span class="built_in">JSON</span>.parse(chunkStr);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">              <span class="built_in">console</span>.error(<span class="string">'Error parse:'</span>, error);</span><br><span class="line">              <span class="built_in">console</span>.error(<span class="string">'Error chunkStr:'</span>, chunkStr);</span><br><span class="line">              <span class="built_in">console</span>.error(<span class="string">'Error origin chunk:'</span>, chunk.toString());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (chunkJson?.data?.chunk) &#123;</span><br><span class="line">              <span class="comment">// æ‹¿åˆ°æœ‰æ•ˆæ•°æ®åï¼Œä¼ ç»™å‰ç«¯</span></span><br><span class="line">              stream.write(chunkJson.data.chunk);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">      response.data.on(<span class="string">'end'</span>, () =&gt; &#123;</span><br><span class="line">        <span class="comment">// ç¬¬ä¸‰æ–¹è¯·æ±‚æµç»“æŸåï¼Œå…³é—­å‘å‰ç«¯å†™çš„æµ</span></span><br><span class="line">        stream.end();</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;)</span><br><span class="line">    .catch(<span class="function">(<span class="params">error</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="built_in">console</span>.error(<span class="string">'Error all:'</span>, error);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="å‰ç«¯å±‚å®ç°"><a href="#å‰ç«¯å±‚å®ç°" class="headerlink" title="å‰ç«¯å±‚å®ç°"></a>å‰ç«¯å±‚å®ç°</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">import</span> &#123; useState, useCallback, useRef &#125; <span class="keyword">from</span> <span class="string">'react'</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> [listLoading, setListLoading] = useState(<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">const</span> [hasReport, setHasReport] = useState(<span class="number">-1</span>);</span><br><span class="line">  <span class="keyword">const</span> [AiRemoteData, setAIRemoteData] = useState(<span class="string">''</span>);</span><br><span class="line">  <span class="keyword">const</span> AiRequestController = useRef();</span><br><span class="line">  <span class="keyword">const</span> &#123; addThrottle &#125; = useThrottleFunc();</span><br><span class="line"></span><br><span class="line"><span class="comment">// æ‹‰å–Ai å›ç­”</span></span><br><span class="line">  <span class="keyword">const</span> getAIRemoteData = useCallback(</span><br><span class="line">    addThrottle(</span><br><span class="line">      <span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">        <span class="keyword">const</span> &#123; keyWord &#125; = query;</span><br><span class="line">        <span class="keyword">if</span> (!keyWord) &#123;</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          setListLoading(<span class="function">(<span class="params">val</span>) =&gt;</span> val + <span class="number">1</span>);</span><br><span class="line">          <span class="keyword">if</span> (AiRequestController.current) &#123;</span><br><span class="line">            <span class="comment">// å¦‚æœå½“å‰è¯·æ±‚å­˜åœ¨ï¼Œåˆ™å–æ¶ˆå½“å‰è¯·æ±‚</span></span><br><span class="line">            AiRequestController.current.abort();</span><br><span class="line">          &#125;</span><br><span class="line">          AiRequestController.current = <span class="keyword">new</span> AbortController();</span><br><span class="line">          <span class="keyword">const</span> jwtToken = <span class="keyword">await</span> getJwt();</span><br><span class="line">          <span class="comment">// 1. åˆ›å»ºä¸€ä¸ªæ–°çš„è¯·æ±‚</span></span><br><span class="line">          <span class="keyword">const</span> response = <span class="keyword">await</span> fetch(</span><br><span class="line">            <span class="string">`https://hahahaha.net/api/diagnosisBasic/faqStream`</span>,</span><br><span class="line">            &#123;</span><br><span class="line">              method: <span class="string">'POST'</span>,</span><br><span class="line">              body: <span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">                user_id: userInfo.id,</span><br><span class="line">                query: keyWord,</span><br><span class="line">                class: ''</span><br><span class="line">              &#125;),</span><br><span class="line">              headers: &#123;</span><br><span class="line">                <span class="string">'x-jwt-token'</span>: jwtToken</span><br><span class="line">              &#125;,</span><br><span class="line">              signal: AiRequestController.current.signal</span><br><span class="line">            &#125;</span><br><span class="line">          );</span><br><span class="line">          <span class="keyword">const</span> reader = response.body.getReader(); <span class="comment">// è·å–reader</span></span><br><span class="line">          <span class="keyword">const</span> decoder = <span class="keyword">new</span> TextDecoder(); <span class="comment">// æ–‡æœ¬è§£ç å™¨</span></span><br><span class="line">          <span class="keyword">let</span> answer = <span class="string">''</span>; <span class="comment">// å­˜å‚¨ç­”æ¡ˆ</span></span><br><span class="line">          <span class="comment">// 2. å¾ªç¯å–å€¼</span></span><br><span class="line">          <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// å–å€¼, value æ˜¯åç«¯è¿”å›æµä¿¡æ¯, done è¡¨ç¤ºåç«¯ç»“æŸæµçš„è¾“å‡º</span></span><br><span class="line">            <span class="keyword">const</span> &#123; value, done &#125; = <span class="keyword">await</span> reader.read();</span><br><span class="line">            <span class="keyword">if</span> (done) &#123;</span><br><span class="line">              <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// å¯¹ value è¿›è¡Œè§£ç </span></span><br><span class="line">            <span class="keyword">const</span> val = decoder.decode(value);</span><br><span class="line">            <span class="keyword">if</span> (!answer) &#123;</span><br><span class="line">              setListLoading(<span class="function">(<span class="params">count</span>) =&gt;</span> count - <span class="number">1</span>);</span><br><span class="line">              setHasReport(<span class="number">-1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            answer += val;</span><br><span class="line">            setAIRemoteData(answer);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          setAIRemoteData(<span class="string">''</span>);</span><br><span class="line">          <span class="built_in">console</span>.error(<span class="string">'æ•°æ®è§£æå‡ºé”™'</span>);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          setListLoading(<span class="function">(<span class="params">val</span>) =&gt;</span> val - <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="number">500</span>,</span><br><span class="line">      <span class="string">'getAIRemoteData'</span></span><br><span class="line">    ),</span><br><span class="line">    [query.keyWord]</span><br><span class="line">  );</span><br></pre></td></tr></table></figure><h3 id="ç•ªå¤–-å…¨å±€èŠ‚æµå‡½æ•°"><a href="#ç•ªå¤–-å…¨å±€èŠ‚æµå‡½æ•°" class="headerlink" title="ç•ªå¤–: å…¨å±€èŠ‚æµå‡½æ•°"></a>ç•ªå¤–: å…¨å±€èŠ‚æµå‡½æ•°</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> throttleTimerList: &#123; [key: string]: Timeout | <span class="literal">null</span> &#125; = &#123;&#125;;</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> useThrottleFunc = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> timer = useRef();</span><br><span class="line">  <span class="keyword">const</span> addThrottle = (</span><br><span class="line">    fn: <span class="function">(<span class="params">params?: LooseObject | <span class="literal">undefined</span></span>) =&gt;</span> <span class="keyword">void</span>,</span><br><span class="line">    waitTime?: number,</span><br><span class="line">    timerKey?: string</span><br><span class="line">  ) =&gt; &#123;</span><br><span class="line">    <span class="keyword">const</span> timerFlag = timerKey || <span class="string">'getRemoteData'</span>;</span><br><span class="line">    throttleTimerList[timerFlag] = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="function">(<span class="params">params?: LooseObject | <span class="literal">undefined</span></span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (throttleTimerList[timerFlag]) &#123;</span><br><span class="line">        clearTimeout(throttleTimerList[timerFlag]);</span><br><span class="line">      &#125;</span><br><span class="line">      throttleTimerList[timerFlag] = setTimeout(<span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        fn(params);</span><br><span class="line">        clearTimeout(throttleTimerList[timerFlag]);</span><br><span class="line">        throttleTimerList[timerFlag] = <span class="literal">null</span>;</span><br><span class="line">      &#125;, waitTime || <span class="number">500</span>);</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  useEffect(</span><br><span class="line">    () =&gt; <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="built_in">Object</span>.keys(throttleTimerList).forEach(<span class="function">(<span class="params">key</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (throttleTimerList[key]) &#123;</span><br><span class="line">          clearTimeout(throttleTimerList[key]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">delete</span> throttleTimerList[key];</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;,</span><br><span class="line">    []</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    addThrottle,</span><br><span class="line">    throttleTimer: timer</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="ç›¸å…³çŸ¥è¯†é“¾æ¥"><a href="#ç›¸å…³çŸ¥è¯†é“¾æ¥" class="headerlink" title="ç›¸å…³çŸ¥è¯†é“¾æ¥"></a>ç›¸å…³çŸ¥è¯†é“¾æ¥</h1><p><a href="https://nodejs.cn/api/webstreams.html#%E7%A4%BA%E4%BE%8B-readablestream" target="_blank" rel="noopener">NODE-Stream</a><br><a href="https://nodejs.cn/api/webstreams.html#%E7%A4%BA%E4%BE%8B-readablestream" target="_blank" rel="noopener">NODE-ReadableStream</a><br><a href="https://developer.mozilla.org/zh-CN/docs/Web/API/ReadableStream" target="_blank" rel="noopener">ReadableStream</a><br><a href="https://juejin.cn/post/7211401380770349115" target="_blank" rel="noopener">application/octet-stream vs text/event-stream</a><br><a href="https://developer.mozilla.org/zh-CN/docs/Web/API/AbortController" target="_blank" rel="noopener">AbortController</a><br><a href="https://juejin.cn/post/7329884027186724901" target="_blank" rel="noopener">fetchè·å–æµå¼æ•°æ®ç›¸å…³é—®é¢˜</a><br><a href="https://juejin.cn/post/7212270321622286394#heading-7" target="_blank" rel="noopener">åœ¨ Koa ä¸­åŸºäº gpt-3.5 æ¨¡å‹å®ç°ä¸€ä¸ªæœ€åŸºæœ¬çš„æµå¼é—®ç­” DEMO</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;èƒŒæ™¯&quot;&gt;&lt;a href=&quot;#èƒŒæ™¯&quot; class=&quot;headerlink&quot; title=&quot;èƒŒæ™¯&quot;&gt;&lt;/a&gt;èƒŒæ™¯&lt;/h1&gt;&lt;p&gt;å‰ç«¯åŒ…æ‹¬nodeå±‚å’Œçº¯å‰ç«¯å±‚ï¼Œéœ€è¦è¯·æ±‚ç¬¬ä¸‰æ–¹httpæ¥å£åœ¨é¡µé¢å®ç°chatGTPçš„æ‰“å­—æœºæ•ˆæœ&lt;/p&gt;
&lt;h1 id=&quot;æ–¹æ¡ˆ&quot;&gt;&lt;a href
      
    
    </summary>
    
    
      <category term="nodejs" scheme="http://yoohannah.github.io/tags/nodejs/"/>
    
  </entry>
  
  <entry>
    <title>ç¥ç»ç½‘ç»œçš„ç›¸å…³æ¨å¯¼å…¬å¼</title>
    <link href="http://yoohannah.github.io/post/deepLearning/NeuralNetwork.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/NeuralNetwork.html</id>
    <published>2024-12-01T13:24:37.000Z</published>
    <updated>2025-01-24T09:38:15.024Z</updated>
    
    <content type="html"><![CDATA[<h1 id="çŸ©é˜µç»´åº¦"><a href="#çŸ©é˜µç»´åº¦" class="headerlink" title="çŸ©é˜µç»´åº¦"></a>çŸ©é˜µç»´åº¦</h1><p>ä¸ºæ–¹ä¾¿é‡å¤è®¡ç®—ï¼Œå‡å°‘forå¾ªç¯çš„ä½¿ç”¨ï¼Œåœ¨ç¥ç»ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œå°½å¯èƒ½çš„å°†æ•°æ®è½¬æˆå‘é‡è¿›è¡Œè®¡ç®—<br>åˆ©ç”¨å‘é‡çš„å¹¿æ’­èƒ½åŠ›è¿›è¡Œå¿«é€Ÿè®¡ç®—ï¼Œç¥ç»ç½‘ç»œå¤šå±‚ä¼ é€’è¿‡ç¨‹ä¸­ï¼ŒçŸ©é˜µçš„ç»´åº¦ä¸€èˆ¬éµå¾ªä»¥ä¸‹å…³ç³»</p><p>å¦‚æœå‰ä¸€å±‚ï¼ˆè¾“å…¥ï¼‰ç»´åº¦ä¸ºï¼ˆm,1ï¼‰ï¼Œä¸­é—´å±‚ç»´åº¦æ˜¯ï¼ˆn, 1ï¼‰, åä¸€å±‚ï¼ˆè¾“å‡ºï¼‰ç»´åº¦æ˜¯ï¼ˆpï¼Œ 1ï¼‰<br>é‚£ä¹ˆ ä¸­é—´å±‚wçš„ç»´åº¦å°±æ˜¯ï¼ˆn, mï¼‰ï¼Œ b çš„ç»´åº¦å°±æ˜¯ï¼ˆnï¼Œ1ï¼‰, b çš„ç»´åº¦å§‹ç»ˆå’Œä¸­é—´å±‚ä¸€è‡´<br>è¾“å‡ºå±‚Wçš„ç»´åº¦ï¼ˆp,nï¼‰ï¼Œb çš„ç»´åº¦å°±æ˜¯(p,1)</p><p><img src="/image/deepLearning/11.png" alt></p><h3 id="å‚æ•°çš„çŸ©é˜µç»´åº¦å…³ç³»"><a href="#å‚æ•°çš„çŸ©é˜µç»´åº¦å…³ç³»" class="headerlink" title="å‚æ•°çš„çŸ©é˜µç»´åº¦å…³ç³»"></a>å‚æ•°çš„çŸ©é˜µç»´åº¦å…³ç³»</h3><p><img src="/image/deepLearning/28.png" alt></p><h1 id="å‘å‰ä¼ æ’­è®¡ç®—è¿‡ç¨‹"><a href="#å‘å‰ä¼ æ’­è®¡ç®—è¿‡ç¨‹" class="headerlink" title="å‘å‰ä¼ æ’­è®¡ç®—è¿‡ç¨‹"></a>å‘å‰ä¼ æ’­è®¡ç®—è¿‡ç¨‹</h1><h2 id="ä¸€ä¸ªç¥ç»å…ƒçš„è®¡ç®—"><a href="#ä¸€ä¸ªç¥ç»å…ƒçš„è®¡ç®—" class="headerlink" title="ä¸€ä¸ªç¥ç»å…ƒçš„è®¡ç®—"></a>ä¸€ä¸ªç¥ç»å…ƒçš„è®¡ç®—</h2><p>æ¯ä¸ªç¥ç»å…ƒçš„è®¡ç®—åŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼Œå…ˆè®¡ç®—z,åœ¨ç”¨æ¿€æ´»å‡½æ•°è®¡ç®—a,<br>åŒä¸€å±‚ä¸åŒç¥ç»å…ƒè®¡ç®—çš„åŒºåˆ«å°±åœ¨äºä½¿ç”¨ä¸åŒçš„å‚æ•°<br><img src="/image/deepLearning/12.png" alt><br>å¦‚æœå°†å‚æ•°wå’Œbæ•´ç†æˆå‘é‡ï¼Œå¯¹å½“å‰æ ·æœ¬æ•°æ®è¿›è¡Œä¸€æ¬¡æ€§å‘é‡è®¡ç®—<br>å°±å¯ä»¥ç›´æ¥å¾—åˆ°å½“å‰å±‚çš„ç›´æ¥äº§å‡ºå‘é‡<br><img src="/image/deepLearning/13.png" alt></p><h2 id="ä¸€å±‚ç¥ç»å…ƒçš„è®¡ç®—"><a href="#ä¸€å±‚ç¥ç»å…ƒçš„è®¡ç®—" class="headerlink" title="ä¸€å±‚ç¥ç»å…ƒçš„è®¡ç®—"></a>ä¸€å±‚ç¥ç»å…ƒçš„è®¡ç®—</h2><p>åŒæ ·ï¼Œæ¯ä¸€å±‚éƒ½å¯ä»¥ç”¨ç›¸åŒçš„è®¡ç®—å¼è¡¨ç¤º<br><img src="/image/deepLearning/14.png" alt></p><h2 id="ä¸€ç»„æ ·æœ¬æ•°æ®çš„è®¡ç®—"><a href="#ä¸€ç»„æ ·æœ¬æ•°æ®çš„è®¡ç®—" class="headerlink" title="ä¸€ç»„æ ·æœ¬æ•°æ®çš„è®¡ç®—"></a>ä¸€ç»„æ ·æœ¬æ•°æ®çš„è®¡ç®—</h2><p>é€šè¿‡for å¾ªç¯è¿›è¡Œæ¯ä¸€å±‚çš„è®¡ç®—å¯å¾—åˆ°æ‰€æœ‰æ ·æœ¬æ•°æ®çš„é¢„æµ‹æ•°æ®y^<br><img src="/image/deepLearning/15.png" alt><br>ä½†æ˜¯é€šè¿‡å°†è¾“å…¥å±‚ç»´åº¦(m,1) çš„å‘é‡å¢åŠ ä¸ºï¼ˆm,xï¼‰çš„å‘é‡ï¼Œå¯ä»¥å®ç°ä¸€æ¬¡è®¡ç®—xä¸ªæ ·æœ¬çš„æ•ˆæœï¼Œä»è€Œå»æ‰forå¾ªç¯<br>å¦‚æœä¸­é—´å±‚æœ‰nä¸ªç¥ç»å…ƒï¼Œè¾“å‡ºå¾—åˆ°çš„ç»“æœå°±æ˜¯(n,x)çš„çŸ©é˜µ<br>ç¬¬n - 1è¡Œ ä¸Šçš„xä¸ªæ•°ï¼Œæ¯ä¸ªæ•°ä»£è¡¨æ¯ä¸ªæ ·æœ¬æ•°æ®åœ¨ä¸­é—´å±‚ç¬¬n-1ä¸ªç¥ç»å…ƒçš„è®¡ç®—åçš„å€¼<br>ç¬¬x - 1åˆ— ä¸Šçš„nä¸ªæ•°ï¼Œæ¯ä¸ªæ•°ä»£è¡¨ç¬¬x-iä¸ªæ ·æœ¬æ•°æ®åœ¨ä¸­é—´å±‚è®¡ç®—åçš„æ¯ä¸ªç¥ç»å…ƒçš„å€¼<br><img src="/image/deepLearning/16.png" alt><br>æœ€ç»ˆç»è¿‡ä¸¤å±‚ç¥ç»å…ƒå¤„ç†åå˜æˆï¼Œç»“æœå˜æˆ(1,x)çš„å‘é‡ï¼Œæ¯ä¸ªå€¼ä»£è¡¨æ¯ä¸ªæ ·æœ¬ç»è¿‡ç¥ç»ç½‘ç»œè®¡ç®—åçš„é¢„æµ‹å€¼</p><h3 id="è¾“å…¥è¾“å‡ºå€¼çŸ©é˜µç»´åº¦ä¹‹é—´çš„å…³ç³»"><a href="#è¾“å…¥è¾“å‡ºå€¼çŸ©é˜µç»´åº¦ä¹‹é—´çš„å…³ç³»" class="headerlink" title="è¾“å…¥è¾“å‡ºå€¼çŸ©é˜µç»´åº¦ä¹‹é—´çš„å…³ç³»"></a>è¾“å…¥è¾“å‡ºå€¼çŸ©é˜µç»´åº¦ä¹‹é—´çš„å…³ç³»</h3><p><img src="/image/deepLearning/29.png" alt></p><h2 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h2><p><img src="/image/deepLearning/17.png" alt></p><h1 id="å…¶ä»–æ¿€æ´»å‡½æ•°"><a href="#å…¶ä»–æ¿€æ´»å‡½æ•°" class="headerlink" title="å…¶ä»–æ¿€æ´»å‡½æ•°"></a>å…¶ä»–æ¿€æ´»å‡½æ•°</h1><p>é™¤äº†sigmoid æ¿€æ´»å‡½æ•°å¤–ï¼Œå¸¸è§çš„æ¿€æ´»å‡½æ•°è¿˜æœ‰Tanh, ReLu,å’Œleaky ReLu,<br>åä¸‰è€…æ›´å¸¸è§ï¼Œä¸”ä½¿ç”¨æ›´å¹¿æ³›ï¼ŒsigmoidåŸºæœ¬åªç”¨äºäºŒåˆ†ç±»åœºæ™¯<br><img src="/image/deepLearning/18.png" alt></p><h2 id="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨çº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°"><a href="#ä¸ºä»€ä¹ˆä¸ä½¿ç”¨çº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°" class="headerlink" title="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨çº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°"></a>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨çº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°</h2><p>å› ä¸ºå¦‚æœä½¿ç”¨çº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œæ— è®ºç¥ç»ç½‘ç»œæœ‰å¤šå°‘å±‚ï¼Œéƒ½ç›¸å½“äºåªè¿›è¡Œäº†ä¸€æ¬¡çº¿æ€§å‡½æ•°è®¡ç®—ï¼Œéšè—å±‚ä½œç”¨æ¶ˆå¤±<br><img src="/image/deepLearning/19.png" alt></p><h2 id="ä¸åŒæ¿€æ´»å‡½æ•°çš„å¯¼æ•°"><a href="#ä¸åŒæ¿€æ´»å‡½æ•°çš„å¯¼æ•°" class="headerlink" title="ä¸åŒæ¿€æ´»å‡½æ•°çš„å¯¼æ•°"></a>ä¸åŒæ¿€æ´»å‡½æ•°çš„å¯¼æ•°</h2><p><img src="/image/deepLearning/20.png" alt><br><img src="/image/deepLearning/21.png" alt><br><img src="/image/deepLearning/22.png" alt></p><h1 id="å‘åä¼ æ’­è¿‡ç¨‹"><a href="#å‘åä¼ æ’­è¿‡ç¨‹" class="headerlink" title="å‘åä¼ æ’­è¿‡ç¨‹"></a>å‘åä¼ æ’­è¿‡ç¨‹</h1><p>å›é¡¾ä¸€ä¸‹æ¢¯åº¦ä¸‹é™çš„è®¡ç®—è¿‡ç¨‹<br><img src="/image/deepLearning/24.png" alt><br>å¯¹äºå•ä¸ªç¥ç»å…ƒçš„å‘åä¼ æ’­è¿‡ç¨‹ï¼Œå°±æ˜¯è®¡ç®—å•ä¸ªç¥ç»å…ƒå‚æ•°åå¯¼æ•°çš„è¿‡ç¨‹<br><img src="/image/deepLearning/23.png" alt></p><p>å¯¹äºå¤šå±‚çš„ç¥ç»ç½‘ç»œè¿›è¡Œå¸¦å…¥<br><img src="/image/deepLearning/25.png" alt></p><h2 id="å°ç»“-1"><a href="#å°ç»“-1" class="headerlink" title="å°ç»“"></a>å°ç»“</h2><p>åŒå‘å‰ä¼ æ’­ä¸€æ ·ï¼Œé€šè¿‡å¼•å…¥å‘é‡çŸ©é˜µï¼Œå‡å°‘forå¾ªç¯<br><img src="/image/deepLearning/26.png" alt></p><h1 id="ä¸ºå•¥ä¸èƒ½åˆå§‹åŒ–å‚æ•°ä¸º0ï¼Ÿ"><a href="#ä¸ºå•¥ä¸èƒ½åˆå§‹åŒ–å‚æ•°ä¸º0ï¼Ÿ" class="headerlink" title="ä¸ºå•¥ä¸èƒ½åˆå§‹åŒ–å‚æ•°ä¸º0ï¼Ÿ"></a>ä¸ºå•¥ä¸èƒ½åˆå§‹åŒ–å‚æ•°ä¸º0ï¼Ÿ</h1><p>å¦‚æœåˆå§‹åŒ–å‚æ•°ä¸º0æˆ–ç›¸åŒå€¼ï¼Œé‚£ä¹ˆæ‰€æœ‰èŠ‚ç‚¹è®¡ç®—çš„å€¼éƒ½ç›¸åŒï¼Œä¼šäº§ç”Ÿå¯¹ç§°æ€§ï¼Œå¯¹åç»­è®¡ç®—çš„å½±å“ä¹Ÿç›¸åŒï¼ŒåŒæ ·ä¼šå¯¼è‡´éšè—å±‚èŠ‚ç‚¹ç»“ç®—æ— æ•ˆ<br>è§£å†³åŠæ³•å°±æ˜¯éšæœºåˆå§‹åŒ–å‚æ•°<br><img src="/image/deepLearning/27.png" alt><br>ä¸€èˆ¬ä¸€å¼€å§‹ä¼šå°†å‚æ•°éšæœºæˆæ¯”è¾ƒå°çš„å€¼ï¼Œå¦‚æœä¸€å¼€å§‹æ˜¯æ¯”è¾ƒå¤§çš„å€¼ï¼Œz çš„å€¼å°±ä¼šæ¯”è¾ƒå¤§ï¼Œ<br>å½“æ¿€æ´»å‡½æ•°æ˜¯sigmoid æˆ–è€…tanh è¿™æ ·çš„æ¿€æ´»å‡½æ•°æ—¶ï¼Œ<br>è®¡ç®—ç»“æœæ‰€åœ¨çš„ä½ç½®å°±ä¼šåœ¨æ¢¯åº¦æ¯”è¾ƒå¹³ç¼“çš„åœ°æ–¹å¯¼è‡´ï¼Œæ¿€æ´»å‡½æ•°å¤„äºæ¯”è¾ƒé¥±å’Œçš„çŠ¶æ€ï¼Œæ¢¯åº¦ä¸‹é™æ¯”è¾ƒæ…¢ï¼Œå½±å“å­¦ä¹ é€Ÿåº¦</p><h1 id="æ·±åº¦ç½‘ç»œ"><a href="#æ·±åº¦ç½‘ç»œ" class="headerlink" title="æ·±åº¦ç½‘ç»œ"></a>æ·±åº¦ç½‘ç»œ</h1><h2 id="å‘å‰ä¼ æ’­"><a href="#å‘å‰ä¼ æ’­" class="headerlink" title="å‘å‰ä¼ æ’­"></a>å‘å‰ä¼ æ’­</h2><p><img src="/image/deepLearning/30.png" alt></p><h2 id="å‘åä¼ æ’­"><a href="#å‘åä¼ æ’­" class="headerlink" title="å‘åä¼ æ’­"></a>å‘åä¼ æ’­</h2><p><img src="/image/deepLearning/31.png" alt></p><h2 id="ä¸€äº›è¶…å‚æ•°"><a href="#ä¸€äº›è¶…å‚æ•°" class="headerlink" title="ä¸€äº›è¶…å‚æ•°"></a>ä¸€äº›è¶…å‚æ•°</h2><p><img src="/image/deepLearning/32.png" alt></p><h2 id="å°ç»“-2"><a href="#å°ç»“-2" class="headerlink" title="å°ç»“"></a>å°ç»“</h2><p><img src="/image/deepLearning/33.png" alt></p><h3 id="ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ·±å±‚ç½‘ç»œ"><a href="#ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ·±å±‚ç½‘ç»œ" class="headerlink" title="ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ·±å±‚ç½‘ç»œ"></a>ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ·±å±‚ç½‘ç»œ</h3><p>ä½¿ç”¨å°çš„ï¼ˆå•å±‚ç¥ç»å…ƒæ•°æ®é‡å°‘çš„ï¼‰çš„ä½†æ˜¯æœ‰å¤šå±‚çš„æ·±å±‚ç½‘ç»œï¼Œå¾€å¾€ä¼šæ¯”ä½¿ç”¨æµ…å±‚(layeræ•°å°‘)ç½‘ç»œè®¡ç®—æ­¥éª¤æ›´ç®€æ´<br>æ¯”å¦‚ä¸‹é¢çš„ç”µè·¯ä¸æˆ–éé—¨è®¡ç®—è¿‡ç¨‹<br>å¦‚æœåƒå·¦ä¾§ä½¿ç”¨æ·±å±‚ç½‘ç»œï¼Œæ¯ä¸€æ¬¡å±‚ç¥ç»å…ƒéƒ½å°‘ä¸€åŠ<br>å¦‚æœä½¿ç”¨å³ä¾§å•å±‚ç¥ç»ç½‘ç»œï¼Œè¿™ä¸€å±‚ä¸Šçš„ç¥ç»å…ƒä¼šä»¥2çš„æŒ‡æ•°æ–¹å¼è®¡ç®—<br>æ€»ä½“ç®—ä¸‹æ¥ï¼Œæ·±å±‚ç½‘ç»œéœ€è¦å¤„ç†çš„ç¥ç»å…ƒä¼šå°‘å¾ˆå¤š</p><p><img src="/image/deepLearning/34.png" alt></p><h1 id="å®éªŒç»ƒä¹ "><a href="#å®éªŒç»ƒä¹ " class="headerlink" title="å®éªŒç»ƒä¹ "></a>å®éªŒç»ƒä¹ </h1><h2 id="é€»è¾‘å›å½’å…¨è¿‡ç¨‹"><a href="#é€»è¾‘å›å½’å…¨è¿‡ç¨‹" class="headerlink" title="é€»è¾‘å›å½’å…¨è¿‡ç¨‹"></a>é€»è¾‘å›å½’å…¨è¿‡ç¨‹</h2><p><a href="https://github.com/GeeeekExplorer/AndrewNg-Deep-Learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset%20Solution.ipynb" target="_blank" rel="noopener">gitbub[ipynb]é“¾æ¥</a><br><a href="https://colab.research.google.com/github/GeeeekExplorer/AndrewNg-Deep-Learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%202/Logistic%20Regression%20as%20a%20Neural%20Network/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset%20Solution.ipynb#scrollTo=OEOpKgClZLco" target="_blank" rel="noopener">å®éªŒ</a></p><h2 id="æ€è·¯æ¢³ç†"><a href="#æ€è·¯æ¢³ç†" class="headerlink" title="æ€è·¯æ¢³ç†"></a>æ€è·¯æ¢³ç†</h2><h2 id="æ•°æ®å¤„ç†"><a href="#æ•°æ®å¤„ç†" class="headerlink" title="æ•°æ®å¤„ç†"></a>æ•°æ®å¤„ç†</h2><h3 id="å‘é‡åŒ–"><a href="#å‘é‡åŒ–" class="headerlink" title="å‘é‡åŒ–"></a>å‘é‡åŒ–</h3><p>å®éªŒä¸­è¦å®ç°å¯¹ä¸€å¼ å›¾ç‰‡æ˜¯å¦æ˜¯çŒ«çš„åˆ¤æ–­ï¼Œ<br>é¦–å…ˆè¦å¯¹å›¾ç‰‡è¿›è¡Œå¤„ç†ï¼Œå°†å›¾ç‰‡è½¬æ¢æˆå‘é‡ï¼Œ<br>ä¸€ä¸ªåƒç´ ç‚¹ç”±RGBä¸‰ä¸ªæ•°æ®ç»„æˆ, ç°åœ¨å¦‚æœæ¨ªç«–éƒ½å–å›¾ç‰‡çš„64ä¸ªåƒç´ ç‚¹<br>ä¸€å¼ 64X64çš„å›¾ç‰‡å°±æœ‰64X64=4096ä¸ª [r,g,b] è¿™æ ·çš„æ•°æ®ï¼Œ<br>ä¸€å¼ å›¾ç‰‡çš„æ•°æ®è¡¨ç¤ºå°±æ˜¯</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    [[196 192 190], [193 186 182],...ä¸­é—´è¿˜æœ‰61ç»„, [188 179 174]], æ¯ä¸€è¡Œ æœ‰64ä¸ª</span><br><span class="line">    [[196 192 190], [193 186 182],..., [188 179 174]],</span><br><span class="line">    ... ä¸­é—´æœ‰60è¡Œ</span><br><span class="line">    [[196 192 190], [193 186 182],..., [188 179 174]]</span><br><span class="line">    [[196 192 190], [193 186 182],..., [88 79 74]]</span><br><span class="line">] ä¸€å…±64è¡Œ</span><br></pre></td></tr></table></figure><p>ç°åœ¨æŠŠæ‰€æœ‰æ•°æ®æ‘Šå¹³å†è½¬ç½®ï¼Œå°±å¯è½¬æˆä¸€ä¸ª[64X64X3=12288, 1]çš„å‘é‡,<br>ä¹Ÿå°±æ˜¯mä¸ªæµ‹è¯•æ•°æ®ç»„æˆçš„çŸ©é˜µä¸­çš„ä¸€åˆ—</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[196,], [192,],..., [88,], [79,],[74,]]</span><br></pre></td></tr></table></figure><p>A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b âˆ— c âˆ— d, a) is to use:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_flatten = X.reshape(X.shape[0], -1).T</span><br></pre></td></tr></table></figure><p>ç°åœ¨æˆ‘ä»¬æœ‰209ä¸ªè®­ç»ƒæ•°æ®çš„è®­ç»ƒé›†train_set_x_origçš„ç»´åº¦æ˜¯(209, 64, 64, 3)<br>a å°±æ˜¯209<br>ç°å°†è¦å°†è®­ç»ƒé›†æ•°æ®ä¸€æ¬¡æ€§è½¬æˆ209åˆ—çš„å‘é‡<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m_train = train_set_x_orig.shape[0] // 209</span><br><span class="line">train_set_x_flatten = train_set_x_orig.reshape(m_train, -1).T</span><br></pre></td></tr></table></figure></p><p>train_set_x_flatten ç°åœ¨çš„ç»´åº¦å°±æ˜¯(12288, 209)<br>æ¯ä¸€åˆ—æ˜¯ä¸€å¼ å›¾ç‰‡çš„åƒç´ æ•°æ®</p><h3 id="æ•°æ®ä¸­å¿ƒæ ‡å‡†åŒ–"><a href="#æ•°æ®ä¸­å¿ƒæ ‡å‡†åŒ–" class="headerlink" title="æ•°æ®ä¸­å¿ƒæ ‡å‡†åŒ–"></a>æ•°æ®ä¸­å¿ƒæ ‡å‡†åŒ–</h3><p>åŸºäºç°åœ¨å¤„ç†çš„æ˜¯å›¾ç‰‡çš„åƒç´ æ•°æ®ï¼Œæ‰€ä»¥æ‰€æœ‰çš„æ•°æ®è‚¯å®šéƒ½åœ¨0~255ä¹‹é—´</p><blockquote><p>One common preprocessing step in machine learning is to center and standardize your dataset,<br>meaning that you substract the mean of the whole numpy array from each example,<br>and then divide each example by the standard deviation of the whole numpy array.<br>But for picture datasets,<br>it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).</p></blockquote><p>ä¸€ä¸ªå¸¸è§çš„é¢„å¤„ç†æ­¥éª¤æ˜¯å°½å¯èƒ½å°†æ•°æ®èšæ‹¢åˆ°åæ ‡ç³»0é™„è¿‘ï¼Œå¸¸ç”¨çš„æ–¹æ³•æ˜¯å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œ<br>ä¹Ÿå°±æ˜¯å°†æ•°æ®å‡å»å‡å€¼ï¼Œç„¶åå°†æ•°æ®é™¤ä»¥æ ‡å‡†å·®<br>ä½†æ˜¯å¯¹äºå›¾ç‰‡æ•°æ®é›†æ¥è¯´ï¼Œ<br>é™¤ä»¥255ï¼ˆåƒç´ é€šé“çš„æœ€å¤§å€¼ï¼‰ï¼Œä¼šæ›´ç®€å•ï¼Œè€Œä¸”æ•ˆæœä¹Ÿå·®ä¸å¤š<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_set_x = train_set_x_flatten / 255.</span><br></pre></td></tr></table></figure></p><h3 id="å°ç»“-3"><a href="#å°ç»“-3" class="headerlink" title="å°ç»“"></a>å°ç»“</h3><blockquote><p>What you need to remember:<br>Common steps for pre-processing a new dataset are:<br>Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, â€¦)<br>Reshape the datasets such that each example is now a vector of size (num_px <em> num_px </em> 3, 1)<br>â€œStandardizeâ€ the data</p></blockquote><p>å¸¸è§çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼š</p><ol><li>ç¡®å®šé—®é¢˜çš„ç»´åº¦å’Œå½¢çŠ¶ï¼ˆm_train, m_test, num_px, â€¦ï¼‰</li><li>å°†æ•°æ®é›†é‡æ–°ç»„ç»‡æˆæ¯ä¸ªç¤ºä¾‹éƒ½æ˜¯å¤§å°ä¸ºï¼ˆnum_px <em> num_px </em> 3, 1ï¼‰çš„å‘é‡</li><li>æ ‡å‡†åŒ–æ•°æ®</li></ol><h2 id="æ„å»ºæ¨¡å‹"><a href="#æ„å»ºæ¨¡å‹" class="headerlink" title="æ„å»ºæ¨¡å‹"></a>æ„å»ºæ¨¡å‹</h2><blockquote><p>The main steps for building a Neural Network are:</p></blockquote><blockquote><p>Define the model structure (such as number of input features)<br>Initialize the modelâ€™s parameters<br>Loop:<br>Calculate current loss (forward propagation)<br>Calculate current gradient (backward propagation)<br>Update parameters (gradient descent)<br>You often build 1-3 separately and integrate them into one function we call model().</p></blockquote><p>æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹çš„ä¸»è¦æ­¥éª¤ï¼š</p><ol><li>å®šä¹‰æ¨¡å‹ç»“æ„ï¼ˆä¾‹å¦‚è¾“å…¥ç‰¹å¾çš„æ•°é‡,è¿™é‡Œæ˜¯ä¸€å¼ å›¾ç‰‡çš„12288ä¸ªrgbæ•°æ®ï¼‰</li><li>åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°</li><li>å¾ªç¯ï¼š<br> è®¡ç®—å½“å‰æŸå¤±ï¼ˆå‰å‘ä¼ æ’­ï¼‰<br> è®¡ç®—å½“å‰æ¢¯åº¦ï¼ˆåå‘ä¼ æ’­ï¼‰<br> æ›´æ–°å‚æ•°ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰<br>é€šå¸¸ä¼šå°†1-3åˆ†åˆ«æ„å»º, ç„¶åå°†å®ƒä»¬é›†æˆåˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºmodel()ã€‚<br><img src="/image/deepLearning/LogReg_kiank.png" alt></li></ol><h3 id="ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘å‡½æ•°å®ç°"><a href="#ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘å‡½æ•°å®ç°" class="headerlink" title="ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘å‡½æ•°å®ç°"></a>ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘å‡½æ•°å®ç°</h3><p>ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘(ğ‘¤ğ‘‡ğ‘¥+ğ‘)=1/(1+ğ‘’âˆ’(ğ‘¤ğ‘‡ğ‘¥+ğ‘))<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">    Compute the sigmoid of z</span><br><span class="line">    Arguments:</span><br><span class="line">    z -- A scalar or numpy array of any size.</span><br><span class="line">    Return:</span><br><span class="line">    s -- sigmoid(z)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">def sigmoid(z):</span><br><span class="line">    s = 1/(1+np.exp(-z))</span><br><span class="line">    return s</span><br></pre></td></tr></table></figure></p><h3 id="åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°"><a href="#åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°" class="headerlink" title="åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°"></a>åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°</h3><p>ç”¨0æ¥åˆå§‹åŒ–å‚æ•°<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.</span><br><span class="line">Argument:</span><br><span class="line">dim -- num_px * num_px * 3</span><br><span class="line">Returns:</span><br><span class="line">w -- initialized vector of shape (dim, 1)</span><br><span class="line">b -- initialized scalar (corresponds to the bias)</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">def initialize_with_zeros(dim):</span><br><span class="line">    w = np.zeros((dim, 1))</span><br><span class="line">    b = 0</span><br><span class="line">    return w, b</span><br><span class="line"></span><br><span class="line">## æµ‹è¯•</span><br><span class="line">dim = 2</span><br><span class="line">w, b = initialize_with_zeros(dim)</span><br><span class="line"></span><br><span class="line">==&gt;</span><br><span class="line">w = [[0.]</span><br><span class="line"> [0.]]</span><br><span class="line">b = 0.0</span><br></pre></td></tr></table></figure></p><h3 id="å‰å‘å‘åä¼ æ’­å®ç°"><a href="#å‰å‘å‘åä¼ æ’­å®ç°" class="headerlink" title="å‰å‘å‘åä¼ æ’­å®ç°"></a>å‰å‘å‘åä¼ æ’­å®ç°</h3><p>æ ¹æ®å…¬å¼è¿›è¡Œä»£ç å®ç°<br><img src="/image/deepLearning/35.png" alt><br>æœ€ç»ˆå¾—åˆ°æ¯è½®è®­ç»ƒçš„æŸå¤±å‡½æ•°å’Œæ¢¯åº¦</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: propagate</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Implement the cost function and its gradient for the propagation explained above</span><br><span class="line"></span><br><span class="line">Arguments:</span><br><span class="line">w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span><br><span class="line">b -- bias, a scalar</span><br><span class="line">X -- data of size (num_px * num_px * 3, number of examples)</span><br><span class="line">Y -- true &quot;label&quot; vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)</span><br><span class="line"></span><br><span class="line">Return:</span><br><span class="line">cost -- negative log-likelihood cost for logistic regression</span><br><span class="line">dw -- gradient of the loss with respect to w, thus same shape as w</span><br><span class="line">db -- gradient of the loss with respect to b, thus same shape as b</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def propagate(w, b, X, Y):</span><br><span class="line">   </span><br><span class="line">    </span><br><span class="line">    m = X.shape[1]</span><br><span class="line">    </span><br><span class="line">    # FORWARD PROPAGATION (FROM X TO COST)</span><br><span class="line">    A = sigmoid(w.T @ X + b)                                    # compute activation å¾—åˆ° (m,1) çš„çŸ©é˜µA,m æ˜¯è®­ç»ƒé›†æ ·æœ¬æ•°</span><br><span class="line">    cost = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))    # compute cost, åœ¨æŸäº› NumPy çš„ç‰¹å®šç‰ˆæœ¬æˆ–ä¸Šä¸‹æ–‡ä¸­, np.mean çš„è¾“å‡ºå¯èƒ½æ˜¯å½¢çŠ¶ä¸º (1,) çš„æ•°ç»„ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªçº¯æ ‡é‡</span><br><span class="line">    </span><br><span class="line">    # BACKWARD PROPAGATION (TO FIND GRAD)</span><br><span class="line">    dw = X @ (A - Y).T / m</span><br><span class="line">    db = np.mean(A - Y)</span><br><span class="line"></span><br><span class="line">    assert(dw.shape == w.shape)</span><br><span class="line">    assert(db.dtype == float)</span><br><span class="line">    cost = np.squeeze(cost) # ç§»é™¤å¤šä½™çš„å•ä¸€ç»´åº¦ï¼Œç¡®ä¿ cost æ˜¯æ ‡é‡</span><br><span class="line">    assert(cost.shape == ()) # è¿™é‡Œæ˜ç¡®è¦æ±‚ cost çš„å½¢çŠ¶æ˜¯ ()ï¼Œå³é›¶ç»´æ ‡é‡ã€‚å¦‚æœ cost æ˜¯ (1,)ï¼Œé‚£ä¹ˆä¼šè§¦å‘æ–­è¨€é”™è¯¯ã€‚</span><br><span class="line">    </span><br><span class="line">    grads = &#123;&quot;dw&quot;: dw,</span><br><span class="line">             &quot;db&quot;: db&#125;</span><br><span class="line">    </span><br><span class="line">    return grads, cost</span><br></pre></td></tr></table></figure><h3 id="æ¢¯åº¦ä¸‹é™å®ç°"><a href="#æ¢¯åº¦ä¸‹é™å®ç°" class="headerlink" title="æ¢¯åº¦ä¸‹é™å®ç°"></a>æ¢¯åº¦ä¸‹é™å®ç°</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">This function optimizes w and b by running a gradient descent algorithm</span><br><span class="line"></span><br><span class="line">Arguments:</span><br><span class="line">w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span><br><span class="line">b -- bias, a scalar</span><br><span class="line">X -- data of shape (num_px * num_px * 3, number of examples)</span><br><span class="line">Y -- true &quot;label&quot; vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)</span><br><span class="line">num_iterations -- number of iterations of the optimization loop</span><br><span class="line">learning_rate -- learning rate of the gradient descent update rule</span><br><span class="line">print_cost -- True to print the loss every 100 steps</span><br><span class="line"></span><br><span class="line">Returns:</span><br><span class="line">params -- dictionary containing the weights w and bias b</span><br><span class="line">grads -- dictionary containing the gradients of the weights and bias with respect to the cost function</span><br><span class="line">costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.</span><br><span class="line"></span><br><span class="line">1) Calculate the cost and the gradient for the current parameters. Use propagate().</span><br><span class="line">2) Update the parameters using gradient descent rule for w and b.</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):</span><br><span class="line">     costs = [] // æ”¶é›†æ¯è½®è®¡ç®—çš„æŸå¤±å‡½æ•°å€¼</span><br><span class="line">    </span><br><span class="line">    for i in range(num_iterations):</span><br><span class="line">        </span><br><span class="line">        # Cost and gradient calculation (â‰ˆ 1-4 lines of code)</span><br><span class="line">        # ç¬¬ä¸€è½®ç”¨åˆå§‹åŒ–wå’Œbè®¡ç®—çš„æŸå¤±å‡½æ•°å’Œæ¢¯åº¦</span><br><span class="line">        # åé¢ç”¨æ›´æ–°åçš„wå’Œbè®¡ç®—çš„æŸå¤±å‡½æ•°å’Œæ¢¯åº¦</span><br><span class="line">        grads, cost = propagate(w, b, X, Y) </span><br><span class="line">        </span><br><span class="line">        # è§£æ„æ¢¯åº¦</span><br><span class="line">        dw = grads[&quot;dw&quot;]</span><br><span class="line">        db = grads[&quot;db&quot;]</span><br><span class="line">        </span><br><span class="line">        # æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°</span><br><span class="line">        w = w - learning_rate * dw</span><br><span class="line">        b = b - learning_rate * db</span><br><span class="line">        </span><br><span class="line">        # Record the costs</span><br><span class="line">        # æ¯100è½®è®°å½•ä¸€æ¬¡æŸå¤±å‡½æ•°å€¼</span><br><span class="line">        if i % 100 == 0: </span><br><span class="line">            costs.append(cost)</span><br><span class="line">        </span><br><span class="line">        # å¦‚æœéœ€è¦æ¯100è½®æ‰“å°ä¸‹æŸå¤±å‡½æ•°å°±å†æ‰“å°ä¸‹</span><br><span class="line">        if print_cost and i % 100 == 0:</span><br><span class="line">            print (&quot;Cost after iteration %i: %f&quot; %(i, cost))</span><br><span class="line">    </span><br><span class="line">    # num_iterationsè½® è®­ç»ƒç»“æŸåè¿”å›æœ€ç»ˆæ›´æ–°åˆ°çš„å‚æ•°ï¼Œæ¢¯åº¦ï¼Œå’ŒæŸå¤±å‡½æ•°é›†åˆ(å¯ä»¥ç”¨äºç»˜åˆ¶å­¦ä¹ æ›²çº¿)</span><br><span class="line">    params = &#123;&quot;w&quot;: w,</span><br><span class="line">              &quot;b&quot;: b&#125;</span><br><span class="line">    </span><br><span class="line">    grads = &#123;&quot;dw&quot;: dw,</span><br><span class="line">             &quot;db&quot;: db&#125;</span><br><span class="line">    </span><br><span class="line">    return params, grads, costs</span><br></pre></td></tr></table></figure><h3 id="é¢„æµ‹å‡½æ•°"><a href="#é¢„æµ‹å‡½æ•°" class="headerlink" title="é¢„æµ‹å‡½æ•°"></a>é¢„æµ‹å‡½æ•°</h3><p>æ ¹æ®å…¬å¼å®ç°é¢„æµ‹å‡½æ•°</p><p>  ğ‘ŒÌ‚ =ğ´=ğœ(ğ‘¤ğ‘‡ğ‘‹+ğ‘)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&apos;&apos;&apos;</span><br><span class="line">Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)</span><br><span class="line"></span><br><span class="line">Arguments:</span><br><span class="line">w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span><br><span class="line">b -- bias, a scalar</span><br><span class="line">X -- data of size (num_px * num_px * 3, number of examples)</span><br><span class="line"></span><br><span class="line">Returns:</span><br><span class="line">Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"># X æ˜¯æ‘Šå¹³åæ•°æ® (12288, m), X.shape[0] æ˜¯å½±å“å› ç´ ä¸ªæ•° 12288 ä¸ªRGBå€¼, X.shape[1] æ˜¯è®­ç»ƒé›†æ ·æœ¬æ•°</span><br><span class="line">def predict(w, b, X):</span><br><span class="line">    </span><br><span class="line">    m = X.shape[1]</span><br><span class="line">    Y_prediction = np.zeros((1,m))</span><br><span class="line">    w = w.reshape(X.shape[0], 1)</span><br><span class="line">    </span><br><span class="line">    # Compute vector &quot;A&quot; predicting the probabilities of a cat being present in the picture</span><br><span class="line">    A = sigmoid(w.T @ X + b)</span><br><span class="line">    </span><br><span class="line">    for i in range(A.shape[1]):</span><br><span class="line">        # Convert probabilities A[0,i] to actual predictions p[0,i] </span><br><span class="line">        # å¤§äº0.5 é¢„æµ‹ä¸º1 æ˜¯çŒ«, å°äº0.5 é¢„æµ‹ä¸º0, ä¸æ˜¯çŒ«</span><br><span class="line">        Y_prediction[0, i] = A[0, i] &gt; 0.5</span><br><span class="line">    </span><br><span class="line">    assert(Y_prediction.shape == (1, m))</span><br><span class="line">    </span><br><span class="line">    return Y_prediction</span><br></pre></td></tr></table></figure><h3 id="ç»„è£…æ¨¡å‹"><a href="#ç»„è£…æ¨¡å‹" class="headerlink" title="ç»„è£…æ¨¡å‹"></a>ç»„è£…æ¨¡å‹</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Builds the logistic regression model by calling the function you&apos;ve implemented previously</span><br><span class="line"></span><br><span class="line">Arguments:</span><br><span class="line">X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)</span><br><span class="line">Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)</span><br><span class="line">X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)</span><br><span class="line">Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)</span><br><span class="line">num_iterations -- hyperparameter representing the number of iterations to optimize the parameters</span><br><span class="line">learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()</span><br><span class="line">print_cost -- Set to true to print the cost every 100 iterations</span><br><span class="line"></span><br><span class="line">Returns:</span><br><span class="line">d -- dictionary containing information about the model.</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):</span><br><span class="line"></span><br><span class="line">    # initialize parameters with zeros (â‰ˆ 1 line of code)</span><br><span class="line">    # åˆå§‹åŒ–æ¨¡å‹çš„å‚æ•°</span><br><span class="line">    w, b = initialize_with_zeros(X_train.shape[0])</span><br><span class="line"></span><br><span class="line">    # Gradient descent (â‰ˆ 1 line of code)</span><br><span class="line">    # æ ¹æ®è®­ç»ƒæ•°æ®é‡‡ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•æ›´æ–°å‚æ•°</span><br><span class="line">    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)</span><br><span class="line">    </span><br><span class="line">    # Retrieve parameters w and b from dictionary &quot;parameters&quot;</span><br><span class="line">    w = parameters[&quot;w&quot;]</span><br><span class="line">    b = parameters[&quot;b&quot;]</span><br><span class="line">    </span><br><span class="line">    # Predict test/train set examples (â‰ˆ 2 lines of code)</span><br><span class="line">    # ç”¨è®­ç»ƒå¥½çš„å‚æ•°é¢„æµ‹æµ‹è¯•é›†å’Œè®­ç»ƒé›†çš„ç»“æœ</span><br><span class="line">    Y_prediction_test = predict(w, b, X_test)</span><br><span class="line">    Y_prediction_train = predict(w, b, X_train)</span><br><span class="line"></span><br><span class="line">    # Print train/test Errors</span><br><span class="line">    # æ‰“å°è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡†ç¡®ç‡</span><br><span class="line">    print(&quot;train accuracy: &#123;&#125; %&quot;.format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))</span><br><span class="line">    print(&quot;test accuracy: &#123;&#125; %&quot;.format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))</span><br><span class="line"></span><br><span class="line">    # è¿”å›æ¨¡å‹è®­ç»ƒçš„æŸå¤±å‡½æ•°å€¼(å­¦ä¹ æ›²çº¿)ï¼Œè®­ç»ƒæµ‹è¯•æ•°æ®é›†çš„é¢„æµ‹ç»“æœ(åˆ¤æ–­æ¨¡å‹æ˜¯å¦æ‹Ÿåˆ)ï¼Œæ¨¡å‹çš„å‚æ•°, å­¦ä¹ ç‡ï¼Œè¿­ä»£æ¬¡æ•°ç­‰ä¿¡æ¯</span><br><span class="line">    d = &#123;&quot;costs&quot;: costs,</span><br><span class="line">         &quot;Y_prediction_test&quot;: Y_prediction_test, </span><br><span class="line">         &quot;Y_prediction_train&quot; : Y_prediction_train, </span><br><span class="line">         &quot;w&quot; : w, </span><br><span class="line">         &quot;b&quot; : b,</span><br><span class="line">         &quot;learning_rate&quot; : learning_rate,</span><br><span class="line">         &quot;num_iterations&quot;: num_iterations&#125;</span><br><span class="line">    </span><br><span class="line">    return d</span><br><span class="line"></span><br><span class="line"># è°ƒç”¨æ¨¡å‹</span><br><span class="line"># æ³¨æ„å…¥å‚train_set_x, train_set_y, test_set_x, test_set_y, æ˜¯ç»è¿‡é¢„å¤„ç†çš„æ•°æ®é›†</span><br><span class="line">d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)</span><br></pre></td></tr></table></figure><h3 id="æ¨¡å‹åˆ†æ"><a href="#æ¨¡å‹åˆ†æ" class="headerlink" title="æ¨¡å‹åˆ†æ"></a>æ¨¡å‹åˆ†æ</h3><ol><li>é¢„æµ‹ç»“æœåˆ†æ</li></ol><p>é™¤äº†å‡½æ•°æœ¬èº«é‡Œé¢çš„å‡†ç¡®ç‡è®¡ç®—ï¼Œå¯ä»¥åˆæ­¥åˆ¤æ–­æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œè¿˜å¯ä»¥å•ç‹¬æ‹¿å‡ºä¸€ä¸ªæµ‹è¯•æ•°æ®ï¼Œå’Œ é¢„æµ‹æ•°æ®è¿›è¡Œç»“æœæ¯”è¾ƒï¼Œè¿›è¡ŒéªŒè¯</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = 14</span><br><span class="line">plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))</span><br><span class="line">print (&quot;y = &quot; + str(test_set_y[0,index]) + &quot;, you predicted that it is a \&quot;&quot; + classes[int(d[&quot;Y_prediction_test&quot;][0,index])].decode(&quot;utf-8&quot;) +  &quot;\&quot; picture.&quot;)</span><br></pre></td></tr></table></figure><ol start="2"><li>å­¦ä¹ æ›²çº¿åˆ†æ</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Plot learning curve (with costs)</span><br><span class="line">costs = np.squeeze(d[&apos;costs&apos;])</span><br><span class="line">plt.plot(costs)</span><br><span class="line">plt.ylabel(&apos;cost&apos;)</span><br><span class="line">plt.xlabel(&apos;iterations (per hundreds)&apos;)</span><br><span class="line">plt.title(&quot;Learning rate =&quot; + str(d[&quot;learning_rate&quot;]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><ol start="3"><li>å­¦ä¹ ç‡åˆ†æ or è¶…å‚æ•°åˆ†æ</li></ol><p>å¢åŠ è®­ç»ƒæ¬¡æ•°ï¼Œè§‚å¯Ÿå­¦ä¹ æ›²çº¿å˜åŒ–åŒç†</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">learning_rates = [0.01, 0.001, 0.0001]</span><br><span class="line">models = &#123;&#125;</span><br><span class="line">for i in learning_rates:</span><br><span class="line">    print (&quot;learning rate is: &quot; + str(i))</span><br><span class="line">    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)</span><br><span class="line">    print (&apos;\n&apos; + &quot;-------------------------------------------------------&quot; + &apos;\n&apos;)</span><br><span class="line"></span><br><span class="line">for i in learning_rates:</span><br><span class="line">    plt.plot(np.squeeze(models[str(i)][&quot;costs&quot;]), label = str(models[str(i)][&quot;learning_rate&quot;]))</span><br><span class="line"></span><br><span class="line">plt.ylabel(&apos;cost&apos;)</span><br><span class="line">plt.xlabel(&apos;iterations (hundreds)&apos;)</span><br><span class="line"></span><br><span class="line">legend = plt.legend(loc=&apos;upper center&apos;, shadow=True)</span><br><span class="line">frame = legend.get_frame()</span><br><span class="line">frame.set_facecolor(&apos;0.90&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="åº”ç”¨è®­ç»ƒç»“æœè¿›è¡Œé¢„æµ‹"><a href="#åº”ç”¨è®­ç»ƒç»“æœè¿›è¡Œé¢„æµ‹" class="headerlink" title="åº”ç”¨è®­ç»ƒç»“æœè¿›è¡Œé¢„æµ‹"></a>åº”ç”¨è®­ç»ƒç»“æœè¿›è¡Œé¢„æµ‹</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">my_image = &quot;my_image2.jpg&quot;   # change this to the name of your image file </span><br><span class="line"></span><br><span class="line">fname = &quot;images/&quot; + my_image</span><br><span class="line">image = np.array(plt.imread(fname))</span><br><span class="line">image = image/255.</span><br><span class="line">my_image = np.array(Image.fromarray(np.uint8(image)).resize((num_px,num_px))).reshape((1, num_px*num_px*3)).T // æ‘Šå¹³æ•°æ®(12288, 1)</span><br><span class="line">#my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).T</span><br><span class="line">my_predicted_image = predict(d[&quot;w&quot;], d[&quot;b&quot;], my_image)</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br><span class="line">print(&quot;y = &quot; + str(np.squeeze(my_predicted_image)) + &quot;, your algorithm predicts a \&quot;&quot; + classes[int(np.squeeze(my_predicted_image)),].decode(&quot;utf-8&quot;) +  &quot;\&quot; picture.&quot;)</span><br></pre></td></tr></table></figure><p><a href="https://dennybritz.com/posts/wildml/implementing-a-neural-network-from-scratch/" target="_blank" rel="noopener">äºŒåˆ†ç±»é—®é¢˜çš„å®è·µ</a><br><a href="https://scikit-learn.org/stable/" target="_blank" rel="noopener">scikitæ¡†æ¶</a></p><h2 id="ä½¿ç”¨éšè—å±‚å®ç°å¯¹éçº¿æ€§æ•°æ®çš„åˆ†ç±»"><a href="#ä½¿ç”¨éšè—å±‚å®ç°å¯¹éçº¿æ€§æ•°æ®çš„åˆ†ç±»" class="headerlink" title="ä½¿ç”¨éšè—å±‚å®ç°å¯¹éçº¿æ€§æ•°æ®çš„åˆ†ç±»"></a>ä½¿ç”¨éšè—å±‚å®ç°å¯¹éçº¿æ€§æ•°æ®çš„åˆ†ç±»</h2><p>é¢˜ç›®<br>æˆ‘ä»¬ç°åœ¨æœ‰ä¸€å †æ•°æ®åˆ†å¸ƒæˆèŠ±æœµçš„å½¢çŠ¶ï¼Œéçº¿æ€§ï¼Œå¦‚ä¸‹ï¼Œ<br><img src="/image/deepLearning/37.png" alt><br>å¯ä»¥çœ‹åˆ°ä¸Šé¢çš„æ•°æ®æœ‰çš„æ˜¯çº¢è‰²ï¼Œæœ‰çš„æ˜¯è“è‰²ï¼Œå‡è®¾çº¢è‰²ä»£è¡¨æ”¯æŒç‰¹æœ—æ™®ï¼Œè“è‰²ä»£è¡¨æ”¯æŒæ‹œç™»<br>æˆ‘ä»¬å¸Œæœ›ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å¯¹è¿™äº›æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œ<br>åˆ†ç±»ç»“æœå°±æ˜¯è¾“å…¥æ•°æ®å¯ä»¥ç›´æ¥å¾—åˆ°æ•°æ®æ˜¯çº¢è‰²è¿˜æ˜¯è“è‰²çš„æ ‡ç­¾<br>è§£å†³æ€è·¯å°±æƒ³åŠæ³•å¯¹çº¢è‰²å’Œè“è‰²çš„æ•°æ®é›†ä¸­åœ°åŒºè¿›è¡Œåˆ†å—åˆ’åˆ†ï¼Œ<br>å¦‚æœæˆ‘ä»¬è¿˜æ˜¯ç”¨sigmoid å‡½æ•°ï¼Œé‚£ä¹ˆå°±ä¼šå˜æˆçº¿æ€§çš„ï¼Œä¸ä¼šå¾—åˆ°æ­£ç¡®çš„åŒºå—åˆ’åˆ†<br><img src="/image/deepLearning/38.png" alt><br>æˆ‘ä»¬å¸Œæœ›ç”¨ä¸€ä¸ªéçº¿æ€§å‡½æ•°æŠŠæ•°æ®è¿›è¡Œç²¾ç¡®åº¦æ›´å¥½çš„åˆ’åˆ†</p><blockquote><p>The general methodology to build a Neural Network is to: </p><ol><li>Define the neural network structure ( # of input units, # of hidden units, etc). </li><li>Initialize the modelâ€™s parameters </li><li>Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent)</li></ol><p>You often build helper functions to compute steps 1-3 and then merge them into one function we call nn_model().<br>Once youâ€™ve built nn_model() and learnt the right parameters, you can make predictions on new data.</p></blockquote><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><p><img src="/image/deepLearning/39.png" alt></p><h3 id="æ¶‰åŠæ–¹ç¨‹"><a href="#æ¶‰åŠæ–¹ç¨‹" class="headerlink" title="æ¶‰åŠæ–¹ç¨‹"></a>æ¶‰åŠæ–¹ç¨‹</h3><p>å‘å‰ä¼ æ’­<br><img src="/image/deepLearning/40.png" alt><br>åå‘ä¼ æ’­<br><img src="/image/deepLearning/41.png" alt></p><h3 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>é‡ç‚¹å…³æ³¨æ¨¡å‹ç»„è£…å¥½åï¼Œå¦‚ä½•ä½¿ç”¨ï¼Œå¦‚ä½•é¢„æµ‹ï¼Œç²¾ç¡®åº¦è®¡ç®—ï¼Œè¶…å‚æ•°å¦‚ä½•è®­ç»ƒï¼Œ<a href="https://yoohannah.github.io/post/machineLearning/MachineLearningDevelopmentProcess.html">è¿ç§»å­¦ä¹ </a>æ€ä¹ˆåš</p><p><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/NeuralNetworkModel/index.py" target="_blank" rel="noopener">éçº¿æ€§é€»è¾‘å›å½’å®ç°ä»£ç </a></p><h2 id="Lå±‚ç¥ç»ç½‘ç»œå®ç°"><a href="#Lå±‚ç¥ç»ç½‘ç»œå®ç°" class="headerlink" title="Lå±‚ç¥ç»ç½‘ç»œå®ç°"></a>Lå±‚ç¥ç»ç½‘ç»œå®ç°</h2><p>æ•´ä½“æ¶æ„<br><img src="/image/deepLearning/LModel.png" alt></p><ol><li>å‘å‰ä¼ æ’­çš„æ—¶å€™ï¼Œå‰L-1å±‚éƒ½æ˜¯å…ˆçº¿æ€§ç„¶åç”¨relu å‡½æ•°æ¿€æ´»ï¼Œæœ€åä¸€å±‚æ˜¯çº¿æ€§ç„¶åç”¨sigmoid å‡½æ•°æ¿€æ´»<blockquote><p>The modelâ€™s structure is: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.<br><img src="/image/deepLearning/forward.png" alt></p></blockquote></li><li>è®¡ç®—æŸå¤±å‡½æ•°<br><img src="/image/deepLearning/cost.png" alt></li><li>åå‘ä¼ æ’­çš„æ—¶å€™ï¼Œä¸å‘å‰ä¼ æ’­ç›¸åï¼Œé™¤ç¬¬ä¸€å±‚æ˜¯çº¿æ€§ç„¶åç”¨sigmoid å‡½æ•°æ¿€æ´»ï¼Œåé¢l-1å±‚æ˜¯çº¿æ€§ç„¶åç”¨relu å‡½æ•°æ¿€æ´»ï¼Œå‰é¢çš„æ¯ä¸€å±‚éƒ½æ˜¯çº¿æ€§ç„¶åç”¨relu å‡½æ•°æ¿€æ´»<blockquote><p>The modelâ€™s structure is: SIGMOID -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; â€¦ -&gt; SIGMOID.<br>for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backpropagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps.<br><img src="/image/deepLearning/backforward.png" alt><br>ä½¿ç”¨é“¾å¼æ³•åˆ™, å¯¹ä¸‹é¢çš„çº¿æ€§å‡½æ•°æ±‚å¯¼dw, db, dA<br><img src="/image/deepLearning/dao1.png" alt><br>å¾—åˆ°åå‘ä¼ æ’­è®¡ç®—å…¬å¼<br><img src="/image/deepLearning/dao2.png" alt></p></blockquote></li></ol><p>æ³¨æ„è¾“å‡ºå±‚çš„sigmoid å‡½æ•°æ±‚å¯¼<br><img src="/image/deepLearning/dao3.png" alt></p><p><a href="https://github.com/YooHannah/algorithm/blob/master/deeplearning/DeepNeuralNetwork/index.py" target="_blank" rel="noopener">Lå±‚ç¥ç»ç½‘ç»œå®ç°ä»£ç </a></p><h2 id="è¿è¡Œå¼‚å¸¸"><a href="#è¿è¡Œå¼‚å¸¸" class="headerlink" title="è¿è¡Œå¼‚å¸¸"></a>è¿è¡Œå¼‚å¸¸</h2><ol><li>å‚æ•°åˆå§‹åŒ–é—®é¢˜</li></ol><table><thead><tr><th>è¯­å¥</th><th>åˆå§‹åŒ–æ–¹å¼</th><th>ä¼˜ç¼ºç‚¹</th></tr></thead><tbody><tr><td><code>np.random.randn(layer_dims[l], layer_dims[l - 1])</code></td><td>æ ‡å‡†æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–</td><td>ç®€å•ï¼Œä½†å¯èƒ½å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤±ï¼Œå°¤å…¶æ˜¯åœ¨æ·±å±‚ç½‘ç»œä¸­ã€‚</td></tr><tr><td><code>np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])</code></td><td>Xavieråˆå§‹åŒ–çš„å˜ä½“ï¼Œ<code>np.sqrt(layer_dims[l-1])</code>æ˜¯ä¸Šä¸€å±‚ç¥ç»å…ƒä¸ªæ•°</td><td>æä¾›æ›´ç¨³å®šçš„æ¢¯åº¦å’Œæ¿€æ´»å€¼ï¼Œé€‚åˆå¯¹ç§°æ¿€æ´»å‡½æ•°ï¼ˆå¦‚Sigmoidã€Tanhï¼‰ã€‚å‡å°‘æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</td></tr></tbody></table><p>å¦‚æœä½¿ç”¨ ReLU æˆ– Leaky ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥é‡‡ç”¨ He åˆå§‹åŒ–ï¼š<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameters[&apos;W&apos; + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2 / layer_dims[l-1])</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;çŸ©é˜µç»´åº¦&quot;&gt;&lt;a href=&quot;#çŸ©é˜µç»´åº¦&quot; class=&quot;headerlink&quot; title=&quot;çŸ©é˜µç»´åº¦&quot;&gt;&lt;/a&gt;çŸ©é˜µç»´åº¦&lt;/h1&gt;&lt;p&gt;ä¸ºæ–¹ä¾¿é‡å¤è®¡ç®—ï¼Œå‡å°‘forå¾ªç¯çš„ä½¿ç”¨ï¼Œåœ¨ç¥ç»ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œå°½å¯èƒ½çš„å°†æ•°æ®è½¬æˆå‘é‡è¿›è¡Œè®¡ç®—&lt;br&gt;åˆ©ç”¨å‘é‡çš„å¹¿æ’­èƒ½åŠ›è¿›è¡Œå¿«
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>ä¸€äº›åŸºç¡€çŸ¥è¯†</title>
    <link href="http://yoohannah.github.io/post/deepLearning/basicKnowledge.html"/>
    <id>http://yoohannah.github.io/post/deepLearning/basicKnowledge.html</id>
    <published>2024-11-27T09:10:37.000Z</published>
    <updated>2025-01-23T07:24:14.397Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·"><a href="#æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·" class="headerlink" title="æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·"></a>æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·</h1><p>éšç€ æ•°æ®é‡çš„å¢å¤šï¼Œè®¡ç®—èƒ½åŠ›çš„æé«˜ä»¥åŠç®—æ³•çš„è¿›æ­¥ï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ çš„è®­ç»ƒå‘¨æœŸå˜çŸ­ï¼Œå¯ä»¥å¿«é€Ÿè¿›è¡Œè¿­ä»£æ›´æ–°ä¼˜åŒ–<br>ä»è€Œç”¨äºå·¥ä¸šç”Ÿæˆ</p><p>ä¸‹é¢ä»¥äºŒåˆ†ç±»é—®é¢˜ä¸ºä¾‹ï¼Œå¤ä¹ ä¸€ä¸‹ç›¸å…³çš„æ•°å­¦çŸ¥è¯†å’Œæ¦‚å¿µ</p><h1 id="æŸå¤±å‡½æ•°å’Œæˆæœ¬å‡½æ•°"><a href="#æŸå¤±å‡½æ•°å’Œæˆæœ¬å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°å’Œæˆæœ¬å‡½æ•°"></a>æŸå¤±å‡½æ•°å’Œæˆæœ¬å‡½æ•°</h1><p>é‡æ–°ç†è§£ä¸€ä¸‹<br>æŸå¤±å‡½æ•°æ˜¯ä¸€ä¸ªè®­ç»ƒæ•°æ®çš„é¢„æµ‹ç»“æœå’Œå®é™…å€¼çš„å·®<br>æˆæœ¬å‡½æ•°æ˜¯æ‰€æœ‰è®­ç»ƒæ•°æ®çš„æŸå¤±å‡½æ•°çš„å¹³å‡å€¼<br><img src="/image/deepLearning/1.png" alt></p><h1 id="å¸¸è§æ±‚å¯¼å…¬å¼"><a href="#å¸¸è§æ±‚å¯¼å…¬å¼" class="headerlink" title="å¸¸è§æ±‚å¯¼å…¬å¼"></a>å¸¸è§æ±‚å¯¼å…¬å¼</h1><p>1.Câ€™=0(Cä¸ºå¸¸æ•°)ï¼›<br>2.(Xn)â€™=nX(n-1) (nâˆˆR)ï¼›<br>3.(sinX)â€™=cosXï¼›<br>4.(cosX)â€™=-sinXï¼›<br>5.(aX)â€™=aXIna ï¼ˆlnä¸ºè‡ªç„¶å¯¹æ•°ï¼‰ï¼›<br>6.(logaX)â€™=1/(Xlna) (a&gt;0ï¼Œä¸”aâ‰ 1)ï¼›<br>7.(tanX)â€™=1/(cosX)2=(secX)2<br>8.(cotX)â€™=-1/(sinX)2=-(cscX)2<br>9.(secX)â€™=tanX secXï¼›<br>10.(cscX)â€™=-cotX cscXï¼›</p><h1 id="è®¡ç®—å›¾"><a href="#è®¡ç®—å›¾" class="headerlink" title="è®¡ç®—å›¾"></a>è®¡ç®—å›¾</h1><h2 id="å‘å‰ä¼ æ’­"><a href="#å‘å‰ä¼ æ’­" class="headerlink" title="å‘å‰ä¼ æ’­"></a>å‘å‰ä¼ æ’­</h2><p>è®¡ç®—æˆæœ¬å‡½æ•°<br><img src="/image/deepLearning/2.png" alt></p><h2 id="å‘åä¼ æ’­"><a href="#å‘åä¼ æ’­" class="headerlink" title="å‘åä¼ æ’­"></a>å‘åä¼ æ’­</h2><p>é€šè¿‡é“¾å¼æ±‚å¯¼å¾—åˆ°æ¯ä¸€è½®è®¡ç®—ä¸­å‚æ•°çš„å¯¼æ•°ï¼Œä»è€Œç”¨äºè¿›è¡Œæ¢¯åº¦ä¸‹é™è®¡ç®—<br><img src="/image/deepLearning/3.png" alt></p><h1 id="æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹"><a href="#æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹" class="headerlink" title="æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹"></a>æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹</h1><p><img src="/image/deepLearning/4.png" alt><br><img src="/image/deepLearning/5.png" alt><br><img src="/image/deepLearning/6.png" alt><br><img src="/image/deepLearning/7.png" alt><br>Neural network programming guideline<br>Whenever possible, avoid explicit for-loops.<br>é¿å…for-loopså¾ªç¯è®¡ç®—å¸¦æ¥çš„ç®—åŠ›æŸè€—ï¼Œä½¿ç”¨å‘é‡å¯¹ä¸Šé¢ä¸¤æ¬¡å¾ªç¯(è®­ç»ƒæ•°è¿­ä»£å’Œå‚æ•°è¿­ä»£)è¿›è¡Œä¼˜åŒ–ï¼Œæœ€ç»ˆåªå‰©è®­ç»ƒæ¬¡æ•°ä¸€æ¬¡loop å¾ªç¯<br><img src="/image/deepLearning/8.png" alt></p><h2 id="å¹¿æ’­"><a href="#å¹¿æ’­" class="headerlink" title="å¹¿æ’­"></a>å¹¿æ’­</h2><p>é€šè¿‡ä½¿ç”¨å‘é‡çš„å¹¿æ’­è®¡ç®—ï¼Œå¯ä»¥å¤§å¹…åº¦å‡å°‘forå¾ªç¯çš„è®¡ç®—æˆæœ¬<br>å¹¿æ’­å¸¸è§çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹</p><p><img src="/image/deepLearning/9.png" alt><br><img src="/image/deepLearning/10.png" alt></p><h3 id="ç»ƒä¹ "><a href="#ç»ƒä¹ " class="headerlink" title="ç»ƒä¹ "></a>ç»ƒä¹ </h3><p>ä½¿ç”¨å¹¿æ’­çš„è¿ç®—æ¦‚å¿µï¼Œå®ç°ä¸‹é¢çš„softmax å‡½æ•°<br><img src="/image/deepLearning/36.png" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">def softmax(x):</span><br><span class="line">    &quot;&quot;&quot;Calculates the softmax for each row of the input x.</span><br><span class="line"></span><br><span class="line">    Your code should work for a row vector and also for matrices of shape (m,n).</span><br><span class="line"></span><br><span class="line">    Argument:</span><br><span class="line">    x -- A numpy matrix of shape (m,n)</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">    s -- A numpy matrix equal to the softmax of x, of shape (m,n)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # Apply exp() element-wise to x. Use np.exp(...).</span><br><span class="line">    x_exp = np.exp(x)</span><br><span class="line"></span><br><span class="line">    # Create a vector x_sum that sums each row of x_exp. Use np.sum(..., axis = 1, keepdims = True).</span><br><span class="line">    x_sum = np.sum(x_exp, axis=1, keepdims=True)</span><br><span class="line">    </span><br><span class="line">    # Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting.</span><br><span class="line">    s = x_exp / x_sum</span><br><span class="line">    </span><br><span class="line">    return s</span><br><span class="line"></span><br><span class="line">x = np.array([</span><br><span class="line">    [9, 2, 5, 0, 0],</span><br><span class="line">    [7, 5, 0, 0 ,0]])</span><br><span class="line">print(&quot;softmax(x) = &quot; + str(softmax(x)))</span><br><span class="line">==&gt;</span><br><span class="line">softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04</span><br><span class="line">  1.21052389e-04]</span><br><span class="line"> [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04</span><br><span class="line">  8.01252314e-04]]</span><br></pre></td></tr></table></figure></p><p><a href="https://github.com/GeeeekExplorer/AndrewNg-Deep-Learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%202/Python%20Basics%20with%20Numpy/Python%20Basics%20With%20Numpy%20Solution.ipynb" target="_blank" rel="noopener">github å®éªŒç»ƒä¹ </a></p><p><a href="https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html" target="_blank" rel="noopener">numpy å®˜ç½‘</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·&quot;&gt;&lt;a href=&quot;#æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·&quot; class=&quot;headerlink&quot; title=&quot;æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·&quot;&gt;&lt;/a&gt;æ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆä¼šå´›èµ·&lt;/h1&gt;&lt;p&gt;éšç€ æ•°æ®é‡çš„å¢å¤šï¼Œè®¡ç®—èƒ½åŠ›çš„æé«˜ä»¥åŠç®—æ³•çš„è¿›æ­¥ï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ çš„è®­ç»ƒå‘¨æœŸå˜çŸ­
      
    
    </summary>
    
    
      <category term="deepLearning" scheme="http://yoohannah.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>æ•°æ®æ¸…æ´—å’Œè½¬æ¢</title>
    <link href="http://yoohannah.github.io/post/machineLearning/dataWash.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/dataWash.html</id>
    <published>2024-10-15T12:14:37.000Z</published>
    <updated>2024-10-18T08:42:02.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å¸¸è§æ•°æ®é”™è¯¯å½¢å¼"><a href="#å¸¸è§æ•°æ®é”™è¯¯å½¢å¼" class="headerlink" title="å¸¸è§æ•°æ®é”™è¯¯å½¢å¼"></a>å¸¸è§æ•°æ®é”™è¯¯å½¢å¼</h1><ol><li>è¶…å‡ºæ­£å¸¸æ•°æ®èŒƒå›´ï¼Œå€¼æˆ–è€…å¤ªå¤§æˆ–è€…å¤ªå°</li><li>ä¸ç¬¦åˆç›¸å…³æ ¡éªŒè§„åˆ™ï¼Œæ¯”å¦‚æ•°å€¼ç±»å‹åªèƒ½æ˜¯æ•´å½¢ï¼Œè´§å¸å•ä½åº”è¯¥æ˜¯ç¾å…ƒï¼Œä½†æ˜¯å‡ºç°äº†è‹±é•‘</li><li>å½¢å¼é”™è¯¯ï¼Œæ¯”å¦‚æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œç”µè¯å·ç æ ¼å¼é”™è¯¯ï¼Œä¸ç¬¦åˆç›¸å…³è¯­æ³•è¯­ä¹‰è§„èŒƒ</li></ol><p><img src="/image/LLM/236.png" alt></p><p>å¯¹äºè¿™æ ·çš„æ•°æ®è¦è¿›è¡Œå»é™¤æ¸…æ´—å¤„ç†</p><h1 id="æ•°æ®è½¬æ¢"><a href="#æ•°æ®è½¬æ¢" class="headerlink" title="æ•°æ®è½¬æ¢"></a>æ•°æ®è½¬æ¢</h1><p>é’ˆå¯¹æ•°å€¼ï¼Œå›¾ç‰‡ï¼Œè§†é¢‘ï¼Œæ–‡å­—ä¸åŒè¾“å…¥ç±»å‹ï¼Œæœ‰ä¸åŒè½¬æ¢æ–¹å¼<br><img src="/image/LLM/237.png" alt><br><img src="/image/LLM/238.png" alt><br><img src="/image/LLM/239.png" alt><br><img src="/image/LLM/240.png" alt><br><img src="/image/LLM/241.png" alt><br>å°ç»“</p><ol><li>æ•°å€¼ç±»å‹è½¬æ¢å°±é‡‡ç”¨å„ç§å½’ä¸€åŒ–çš„è®¡ç®—å…¬å¼è¿›è¡Œè½¬æ¢</li><li>å›¾ç‰‡ï¼Œå¯ä»¥é‡‡ç”¨è£å‰ªå°ºå¯¸ï¼Œä¸‹é‡‡æ ·ï¼Œå‹ç¼©ï¼Œç™½åŒ–å¤„ç†</li><li>è§†é¢‘ï¼Œå¯ä»¥é‡‡ç”¨æˆªå–å…³é”®ç‰‡æ®µï¼Œé‡‡æ ·å…³é”®é’ˆé™ä½æ•°æ®å¤„ç†é™ˆæœ¬</li><li>æ–‡å­—ï¼Œå¯ä»¥è¿›è¡Œè¯å¹²æå–ï¼Œè¯å½¢è¿˜åŸä»¥åŠtokenåŒ–å¤„ç†<br><img src="/image/LLM/242.png" alt></li></ol><h1 id="mL-å¸¸è§ç®—æ³•ç±»å‹"><a href="#mL-å¸¸è§ç®—æ³•ç±»å‹" class="headerlink" title="mL å¸¸è§ç®—æ³•ç±»å‹"></a>mL å¸¸è§ç®—æ³•ç±»å‹</h1><p>ç›‘ç£ï¼Œè‡ªç›‘ç£ï¼ŒåŠç›‘ç£ï¼Œæ— ç›‘ç£ï¼Œå¼ºåŒ–å­¦ä¹ <br><img src="/image/LLM/243.png" alt><br><img src="/image/LLM/244.png" alt></p><h2 id="è‡ªç›‘ç£ç›¸å…³æ¦‚å¿µ"><a href="#è‡ªç›‘ç£ç›¸å…³æ¦‚å¿µ" class="headerlink" title="è‡ªç›‘ç£ç›¸å…³æ¦‚å¿µ"></a>è‡ªç›‘ç£ç›¸å…³æ¦‚å¿µ</h2><p><img src="/image/LLM/245.png" alt></p><h2 id="å†³ç­–æ ‘ç›¸å…³æ³¨æ„ç‚¹"><a href="#å†³ç­–æ ‘ç›¸å…³æ³¨æ„ç‚¹" class="headerlink" title="å†³ç­–æ ‘ç›¸å…³æ³¨æ„ç‚¹"></a>å†³ç­–æ ‘ç›¸å…³æ³¨æ„ç‚¹</h2><p><img src="/image/LLM/246.png" alt><br><img src="/image/LLM/247.png" alt><br><img src="/image/LLM/248.png" alt></p><h2 id="äºŒåˆ†ç±»è¯„ä»·æŒ‡æ ‡"><a href="#äºŒåˆ†ç±»è¯„ä»·æŒ‡æ ‡" class="headerlink" title="äºŒåˆ†ç±»è¯„ä»·æŒ‡æ ‡"></a>äºŒåˆ†ç±»è¯„ä»·æŒ‡æ ‡</h2><p><img src="/image/LLM/249.png" alt></p><h2 id="å¤æ‚åº¦è§£é‡Šorè§£é‡Š"><a href="#å¤æ‚åº¦è§£é‡Šorè§£é‡Š" class="headerlink" title="å¤æ‚åº¦è§£é‡Šorè§£é‡Š"></a>å¤æ‚åº¦è§£é‡Šorè§£é‡Š</h2><p><img src="/image/LLM/250.png" alt><br><img src="/image/LLM/251.png" alt><br><img src="/image/LLM/252.png" alt><br><img src="/image/LLM/253.png" alt><br><img src="/image/LLM/254.png" alt></p><p><a href="https://c.d2l.ai/stanford-cs329p/syllabus.html#data-i" target="_blank" rel="noopener">ææ²æœºå™¨å­¦ä¹ ppt</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;å¸¸è§æ•°æ®é”™è¯¯å½¢å¼&quot;&gt;&lt;a href=&quot;#å¸¸è§æ•°æ®é”™è¯¯å½¢å¼&quot; class=&quot;headerlink&quot; title=&quot;å¸¸è§æ•°æ®é”™è¯¯å½¢å¼&quot;&gt;&lt;/a&gt;å¸¸è§æ•°æ®é”™è¯¯å½¢å¼&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;è¶…å‡ºæ­£å¸¸æ•°æ®èŒƒå›´ï¼Œå€¼æˆ–è€…å¤ªå¤§æˆ–è€…å¤ªå°&lt;/li&gt;
&lt;li&gt;ä¸ç¬¦åˆç›¸å…³æ ¡éªŒè§„åˆ™ï¼Œæ¯”å¦‚
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>æ•°æ®æ ‡æ³¨</title>
    <link href="http://yoohannah.github.io/post/machineLearning/datalabel.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/datalabel.html</id>
    <published>2024-10-14T13:05:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<p>æ ¹æ®æ ‡æ³¨æ•°æ®çš„ç›®çš„(æ•°æ®ä¼˜åŒ–è¿˜æ˜¯è®­ç»ƒæ¨¡å‹)ï¼Œæ•°æ®å½“å‰çš„æ ‡æ³¨æƒ…å†µä»¥åŠé¢„ç®—æƒ…å†µ<br>å¯ä»¥æ ¹æ®ä¸‹é¢çš„æµç¨‹è¿›è¡Œæ•°æ®æ ‡æ³¨<br><img src="/image/LLM/226.png" alt></p><h1 id="åŠç›‘ç£å­¦ä¹ "><a href="#åŠç›‘ç£å­¦ä¹ " class="headerlink" title="åŠç›‘ç£å­¦ä¹ "></a>åŠç›‘ç£å­¦ä¹ </h1><p>å¦‚æœä¸€å¼€å§‹æœ‰ä¸€éƒ¨åˆ†æ•°æ®å¯ä»¥è¿›è¡Œç›‘ç£å­¦ä¹ è®­ç»ƒï¼Œç„¶åç”¨æœªæ ‡è®°çš„æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œæ‹¿åˆ°æµ‹è¯•ç»“æœï¼Œ<br>æ ¹æ®æµ‹è¯•ç»“æœå‡†ç¡®æ€§åˆ¤æ–­æ˜¯å¦å°†å½“å‰æœªæ ‡è®°æ•°æ®å½“åšæ ‡è®°æ•°æ®æ·»åŠ åˆ°ä¸‹ä¸€è½®çš„è®­ç»ƒä¸­<br><img src="/image/LLM/227.png" alt><br><img src="/image/LLM/228.png" alt><br>ç”±äºè¿™é‡Œçš„å·¥ä½œæ˜¯è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨è¾ƒæ·±çš„ç¥ç»ç½‘ç»œæˆ–è€…è¾ƒè´µçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒ<br>ä»¥ä¿è¯å¾—åˆ°æ›´å‡†ç¡®çš„æ ‡æ³¨ç»“æœ</p><h1 id="ä¼—åŒ…æ ‡æ³¨"><a href="#ä¼—åŒ…æ ‡æ³¨" class="headerlink" title="ä¼—åŒ…æ ‡æ³¨"></a>ä¼—åŒ…æ ‡æ³¨</h1><p>å¦‚æœæœ‰è¶³å¤Ÿçš„èµ„é‡‘é¢„ç®—ï¼Œå¯ä»¥å°†æ•°æ®äº¤ç»™ç¬¬ä¸‰æ–¹è¿›è¡Œæ ‡æ³¨ï¼Œç„¶åå°†æ ‡æ³¨ç»“æœè¿›è¡Œæ±‡æ€»<br><img src="/image/LLM/229.png" alt><br>ä½†è¦é¢ä¸´å¦‚ä½•é™ä½æ ‡æ³¨é—¨æ§›ï¼Œæ ‡æ³¨è´¨é‡ï¼Œä»·æ ¼æ˜‚è´µï¼Œæ ‡æ³¨äººå‘˜ä¸ç¨³å®šç­‰é—®é¢˜<br><img src="/image/LLM/230.png" alt></p><h2 id="ä¸»åŠ¨å­¦ä¹ "><a href="#ä¸»åŠ¨å­¦ä¹ " class="headerlink" title="ä¸»åŠ¨å­¦ä¹ "></a>ä¸»åŠ¨å­¦ä¹ </h2><p>åªå°†è®­ç»ƒç»“æœæœ€ä¸ç¡®å®šçš„æ•°æ®ï¼Œæˆ–è€…æœ€éš¾æ ‡è®°çš„æ•°æ®è¿›è¡Œäººå·¥æ ‡æ³¨ï¼Œç„¶åç”¨å¤šä¸ªæ¨¡å‹æŠ•ç¥¨ä¿è¯æ ‡è®°å‡†ç¡®åº¦<br><img src="/image/LLM/231.png" alt><br>é€šå¸¸ä¸åŠç›‘ç£å­¦ä¹ ç»“åˆä½¿ç”¨<br><img src="/image/LLM/232.png" alt></p><h2 id="è´¨é‡æ§åˆ¶"><a href="#è´¨é‡æ§åˆ¶" class="headerlink" title="è´¨é‡æ§åˆ¶"></a>è´¨é‡æ§åˆ¶</h2><p>é˜²æ­¢æ ‡é”™æˆ–è€…èŒƒå›´æœ‰é—®é¢˜ï¼Œå¯ä»¥é€‰æ‹©å°†ä¸€ä¸ªæ•°æ®å‘ç»™å¤šä¸ªæ ‡æ³¨äººå‘˜è¿›è¡Œæ ‡æ³¨ï¼Œç„¶åæ ¹æ®æ ‡æ³¨ç»“æœè¿›è¡ŒæŠ•ç¥¨<br>ä½†è¿™æ ·åšä¼šå¯¼è‡´æ ‡æ³¨æˆæœ¬å¢åŠ <br>é™ä½æˆæœ¬çš„æ–¹æ³•å¯ä»¥æ˜¯ï¼Œ<br>ä¸€æ˜¯ä»ç»“æœè§’åº¦æ€è€ƒï¼Œå…ˆè®©æ¨¡å‹è¿›è¡Œæ¨æµ‹ï¼Œå¦‚æœäººå·¥æ ‡æ³¨ä¸æ¨¡å‹æ¨æµ‹ç»“æœç›¸å·®è¾ƒå¤§ï¼Œåˆ™å°†æ•°æ®å‘ç»™å¤šä¸ªæ ‡æ³¨äººå‘˜è¿›è¡Œæ ‡æ³¨<br>å¦åˆ™åœæ­¢ä»»åŠ¡å‘é€ï¼Œå‡å°‘æˆæœ¬ï¼›æˆ–è€…å‘é€çš„å‰å‡ ä¸ªäººæ ‡è®°ç»“æœéƒ½ä¸€æ ·ï¼Œå°±åœæ­¢å‘é€æ›´å¤šäººè¿›è¡Œæ ‡è®°<br>äºŒæ˜¯ä»äººçš„è§’åº¦æ€è€ƒï¼Œå…ˆç»™ä¸€äº›æœ‰ç¡®å®šæ ‡æ³¨çš„æ•°æ®ç»™æ ‡è®°äººå‘˜è¿›è¡Œæ ‡æ³¨ï¼Œå¦‚æœæ ‡æ³¨ç»“æœä¸ç¡®å®šæ ‡æ³¨ç›¸å·®ç»“æœè¾ƒå¤§ï¼Œè¯´æ˜æ ‡æ³¨äººå‘˜èƒ½åŠ›æœ‰é—®é¢˜ï¼Œè¿›è¡Œäººå‘˜æ›´æ¢<br><img src="/image/LLM/233.png" alt></p><h2 id="å¼±ç›‘ç£å­¦ä¹ "><a href="#å¼±ç›‘ç£å­¦ä¹ " class="headerlink" title="å¼±ç›‘ç£å­¦ä¹ "></a>å¼±ç›‘ç£å­¦ä¹ </h2><p>ä½¿ç”¨å¯å‘å¼è§„åˆ™é€šè¿‡æ•°æ®ç¼–ç¨‹å¾—åˆ°ä¸€äº›æœ‰å™ªéŸ³çš„æ ‡æ³¨<br>é€šè¿‡åŠè‡ªåŠ¨åŒ–çš„æ–¹å¼ç”Ÿæˆå‡†ç¡®åº¦å¼±äºäººå·¥æ ‡è®°ï¼Œä½†è¶³ä»¥è¿›è¡Œæ¨¡å‹è®­ç»ƒçš„æ ‡æ³¨<br>é€šè¿‡æ ¹æ®æ•°æ®ç‰¹å¾çš„ä¸€ç³»åˆ—åˆ¤æ–­(å¯å‘å¼è§„åˆ™)è¿›è¡ŒæŠ•ç¥¨ï¼Œç„¶åå°†æŠ•ç¥¨ç»“æœè¿›è¡Œé˜ˆå€¼æ¯”è¾ƒï¼Œä»è€Œåˆ¤æ–­å±äºå“ªä¸ªåˆ†ç±»æ ‡ç­¾<br><img src="/image/LLM/233.png" alt></p><h1 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h1><p>ä¸‰ç§å¸¸è§æ•°æ®æ ‡æ³¨æ–¹å¼</p><ol><li>åŠç›‘ç£å­¦ä¹ </li><li>ä¼—åŒ…æ ‡æ³¨</li><li>å¼±ç›‘ç£å­¦ä¹ <br>å¯¹äºæ²¡æœ‰æ ‡è®°çš„æ•°æ®ä¹Ÿå¯ä»¥ç”¨æ— ç›‘ç£æˆ–è€…è‡ªç›‘ç£å­¦ä¹ è¿›è¡Œè®­ç»ƒ<br><img src="/image/LLM/233.png" alt></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;æ ¹æ®æ ‡æ³¨æ•°æ®çš„ç›®çš„(æ•°æ®ä¼˜åŒ–è¿˜æ˜¯è®­ç»ƒæ¨¡å‹)ï¼Œæ•°æ®å½“å‰çš„æ ‡æ³¨æƒ…å†µä»¥åŠé¢„ç®—æƒ…å†µ&lt;br&gt;å¯ä»¥æ ¹æ®ä¸‹é¢çš„æµç¨‹è¿›è¡Œæ•°æ®æ ‡æ³¨&lt;br&gt;&lt;img src=&quot;/image/LLM/226.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=&quot;åŠç›‘ç£å­¦ä¹ &quot;&gt;&lt;a href=&quot;#åŠç›‘ç£å­¦ä¹ &quot; class=
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>å¼ºåŒ–å­¦ä¹ </title>
    <link href="http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/ReinforcementLearning.html</id>
    <published>2024-10-07T06:34:37.000Z</published>
    <updated>2024-10-17T03:41:22.957Z</updated>
    
    <content type="html"><![CDATA[<p>å¼ºåŒ–å­¦ä¹ çš„ä¸»è¦æ€æƒ³ä¸æ˜¯å‘Šè¯‰ç®—æ³•æ¯ä¸ªè¾“å…¥çš„æ­£ç¡®è¾“å‡ºæ˜¯ä»€ä¹ˆ<br>è€Œæ˜¯æŒ‡å®šä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œå‘Šè¯‰å®ƒä»€ä¹ˆæ—¶å€™åšçš„å¥½ï¼Œä»€ä¹ˆæ—¶å€™åšçš„ä¸å¥½<br>ç®—æ³•çš„å·¥ä½œæ˜¯è‡ªåŠ¨æ‰¾å‡ºå¦‚ä½•é€‰æ‹©å¥½çš„åŠ¨ä½œ</p><p><img src="/image/LLM/202.png" alt></p><h1 id="ä¸€äº›æ¦‚å¿µ"><a href="#ä¸€äº›æ¦‚å¿µ" class="headerlink" title="ä¸€äº›æ¦‚å¿µ"></a>ä¸€äº›æ¦‚å¿µ</h1><p>ä»¥ç«æ˜Ÿæ¢æµ‹å™¨ä¸ºä¾‹ï¼Œåœ¨å…¶å†³å®šè·¯çº¿çš„è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å‡ ä¸ªæ¦‚å¿µ</p><ol><li>S ï¼š å½“å‰çŠ¶æ€</li><li>a : åŠ¨ä½œ</li><li>Sâ€™ : ä¸‹ä¸€ä¸ªçŠ¶æ€</li><li>R : å¥–åŠ±å‡½æ•°</li><li><p>teminal state : ç»ˆæ­¢çŠ¶æ€<br><img src="/image/LLM/203.png" alt><br>æ¯ç§è·¯çº¿å›æŠ¥é€šè¿‡è®¡ç®—è·¯ä¸Šæ¯ä¸€æ­¥å¥–åŠ±ä¹˜ä»¥æŠ˜ç°ç³»æ•°åŠ å’Œå¾—åˆ°<br><img src="/image/LLM/204.png" alt></p></li><li><p>policy : ç­–ç•¥å‡½æ•°ï¼Œæ ¹æ®å½“å‰çš„çŠ¶æ€é€‰æ‹©å¯ä»¥è·å¾—æœ€å¤§æ”¶ç›Šçš„åŠ¨ä½œ</p></li></ol><p>A policy is a function Ï€ï¼ˆsï¼‰= a  mapping from states to actions, that tells you what action a to take in a given state s.</p><p>The goal of reinforcement learning ===&gt;<br>Find a policy 5 that tells you what action (a = 5(s)) to take in every state (s) so as to maximize the return.</p><p><img src="/image/LLM/205.png" alt></p><h1 id="é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹"><a href="#é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹" class="headerlink" title="é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹"></a>é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹</h1><p>æœªæ¥åªå–å†³äºå½“å‰çš„åç§°ï¼Œè€Œä¸æ˜¯åˆ°è¾¾å½“å‰çŠ¶æ€ä¹‹å‰å¯èƒ½å‘ç”Ÿçš„ä»»ä½•äº‹æƒ…</p><p><img src="/image/LLM/206.png" alt></p><h1 id="çŠ¶æ€åŠ¨ä½œå›æŠ¥å‡½æ•°-Q"><a href="#çŠ¶æ€åŠ¨ä½œå›æŠ¥å‡½æ•°-Q" class="headerlink" title="çŠ¶æ€åŠ¨ä½œå›æŠ¥å‡½æ•° Q"></a>çŠ¶æ€åŠ¨ä½œå›æŠ¥å‡½æ•° Q</h1><p>å½“å‰çŠ¶æ€ä¸‹æ‰§è¡Œä¸€æ¬¡å‡½æ•°èƒ½å¤Ÿå¾—åˆ°çš„æœ€å¤§å›æŠ¥å€¼<br>å¦‚æœèƒ½å¤Ÿæ‰¾åˆ°æœ€å¤§å›æŠ¥å€¼ä¹Ÿå°±èƒ½çŸ¥é“æ¥ä¸‹æ¥åº”è¯¥ç”¨ä»€ä¹ˆåŠ¨ä½œ</p><p><img src="/image/LLM/207.png" alt></p><p><img src="/image/LLM/208.png" alt></p><h1 id="è´å°”æ›¼å…¬å¼"><a href="#è´å°”æ›¼å…¬å¼" class="headerlink" title="è´å°”æ›¼å…¬å¼"></a>è´å°”æ›¼å…¬å¼</h1><p><img src="/image/LLM/209.png" alt><br><img src="/image/LLM/210.png" alt><br><img src="/image/LLM/211.png" alt></p><h2 id="ä¼˜åŒ–"><a href="#ä¼˜åŒ–" class="headerlink" title="ä¼˜åŒ–"></a>ä¼˜åŒ–</h2><p>é¢å¯¹ç¯å¢ƒéšæœºçš„æƒ…å†µï¼ŒåŠ¨ä½œå®é™…æ‰§è¡Œè¿‡ç¨‹å¯èƒ½å­˜åœ¨å¤šä¸ªå¯èƒ½è·¯çº¿ï¼Œå¯¼è‡´æ¯æ¬¡å¾—åˆ°çš„æœ€å¤§å›æŠ¥å€¼ä¸åŒï¼Œå› æ­¤è®¡ç®—å½“å‰çŠ¶æ€æœ€å¤§æ”¶ç›Šæ—¶å–æ‰€æœ‰è·¯çº¿æƒ…å†µçš„å¹³å‡å€¼è¿›è¡Œè®¡ç®—<br>å³ä½¿ç”¨æœŸæœ›å›æŠ¥å€¼è¿›è¡Œè®¡ç®—<br><img src="/image/LLM/212.png" alt><br><img src="/image/LLM/213.png" alt></p><h1 id="DQN-ç®—æ³•"><a href="#DQN-ç®—æ³•" class="headerlink" title="DQN ç®—æ³•"></a>DQN ç®—æ³•</h1><p>D: deep learning<br>Q: Q function<br>N: Network</p><p>å¯¹äºè¿ç»­çŠ¶æ€å€¼çš„æƒ…å†µï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè®­ç»ƒQå‡½æ•°è¿›è¡Œæ·±åº¦å¼ºåŒ–å­¦ä¹ <br><img src="/image/LLM/214.png" alt><br><img src="/image/LLM/215.png" alt><br><img src="/image/LLM/216.png" alt><br>By using experience replay we avoid problematic correlations, oscillations and instabilities. In addition, experience replay also allows the agent to potentially use the same experience in multiple weight updates, which increases data efficiency.<br>é€šè¿‡ä½¿ç”¨ç»éªŒé‡æ”¾ï¼Œæˆ‘ä»¬å¯ä»¥é¿å…æœ‰é—®é¢˜çš„ç›¸å…³æ€§ã€æŒ¯è¡å’Œä¸ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œç»éªŒé‡æ”¾è¿˜å…è®¸ä»£ç†åœ¨å¤šæ¬¡æƒé‡æ›´æ–°ä¸­ä½¿ç”¨ç›¸åŒçš„ç»éªŒï¼Œä»è€Œæé«˜æ•°æ®æ•ˆç‡ã€‚</p><h2 id="ä¼˜åŒ–-1"><a href="#ä¼˜åŒ–-1" class="headerlink" title="ä¼˜åŒ–"></a>ä¼˜åŒ–</h2><h3 id="ä¼˜åŒ–ç¥ç»ç½‘ç»œç»“æ„"><a href="#ä¼˜åŒ–ç¥ç»ç½‘ç»œç»“æ„" class="headerlink" title="ä¼˜åŒ–ç¥ç»ç½‘ç»œç»“æ„"></a>ä¼˜åŒ–ç¥ç»ç½‘ç»œç»“æ„</h3><p>ä¸Šé¢å°†så’Œaä½œä¸ºX åŒæ—¶å‚ä¸è®­ç»ƒï¼Œæœ€ç»ˆåªä¼šå¾—åˆ°ä¸€ä¸ªåŠ¨ä½œaæœ€å¤§å›æŠ¥å‡½æ•°å€¼,éœ€è¦è¿›è¡Œå¤šæ¬¡è¿ç®—<br>å¦‚æœä»…å°†sä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºå±‚äº§ç”Ÿå¤šä¸ªaçš„å›æŠ¥å€¼ï¼Œå°±å¯ä»¥æ ¹æ®å›æŠ¥å€¼å¤§å°é€‰æ‹©ç›¸åº”çš„åŠ¨ä½œ</p><p><img src="/image/LLM/217.png" alt><br><img src="/image/LLM/218.png" alt></p><h3 id="epsilon-greedy-policy"><a href="#epsilon-greedy-policy" class="headerlink" title="epsilon-greedy policy"></a>epsilon-greedy policy</h3><p>é€‰æ‹©action è¿‡ç¨‹ä¸­ï¼Œå¦‚æœä¸€ç›´æŒ‰Qå€¼æœ€å¤§åŸåˆ™é€‰æ‹©action,ä¸‡ä¸€åˆå§‹å€¼ç‰¹åˆ«å°æ— æ³•å¼€å¯æˆ‘ä»¬æƒ³è¦çš„ç¬¬ä¸€æ­¥ç¨‹åºï¼Œå°±ä¼šå¯¼è‡´æ— æ³•è¿›è¡Œåç»­çš„action<br>epsilon-greedy policy æ–¹æ¡ˆå°±æ˜¯æ‰¾ä¸€ä¸ªåˆé€‚çš„é˜ˆå€¼epsilonï¼Œæ¯”å¦‚è¯´0.05,<br>95%çš„æ—¶é—´é€‰æ‹©æœ€å¤§Qå€¼action (è´ªå©ªå‰¥å‰Šç­–ç•¥)<br>5%çš„æ—¶é—´é€‰æ‹©éšæœºé€‰æ‹©actionï¼ˆæ¢ç´¢ç­–ç•¥ï¼‰<br>è¿™æ ·å°±å¯ä»¥é¿å…é€‰åˆ°å›ºå®šä¸ç¬¦åˆé¢„æœŸçš„action,å¼€æ”¾ä¸€å®šçš„çª—å£æœ‰å¯èƒ½é€‰åˆ°å…¶ä»–çš„action<br>epsilon å¤§å° ç±»ä¼¼äºæ¢¯åº¦ï¼Œéšè®­ç»ƒè¿‡ç¨‹è¿›è¡Œä¼šé€æ¸å˜å°ï¼Œå˜å°çš„è¿‡ç¨‹ï¼Œæ¨¡å‹ä¹Ÿå°±å­¦ä¼šäº†å¦‚ä½•é€‰æ‹©æ›´æœ‰å¯èƒ½é€‰æ‹©ç¬¦åˆé¢„æœŸçš„action</p><p><img src="/image/LLM/219.png" alt></p><h3 id="å°æ‰¹é‡"><a href="#å°æ‰¹é‡" class="headerlink" title="å°æ‰¹é‡"></a>å°æ‰¹é‡</h3><p>è®­ç»ƒæ•°æ®å¦‚æœéå¸¸åºå¤§ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šé€ æˆæ—¶é—´æ¶ˆè€—ï¼Œä¸ºäº†æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œå¯ä»¥é‡‡ç”¨å°æ‰¹é‡çš„æ–¹å¼è¿›è¡Œ<br>å°†è®­ç»ƒæ•°æ®åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ¬¡è¿­ä»£ç”¨ä¸åŒæ‰¹æ¬¡æ•°æ®ï¼Œè™½ç„¶æ¢¯åº¦ä¼šæ¯”è¾ƒå˜ˆæ‚ï¼Œä½†è¿˜æ˜¯ä¼šæœç€æ¢¯åº¦ä¸‹é™çš„æ–¹å‘è¿›è¡Œ<br><img src="/image/LLM/220.png" alt><br><img src="/image/LLM/221.png" alt><br><img src="/image/LLM/222.png" alt><br><img src="/image/LLM/223.png" alt></p><h3 id="è½¯æ›´æ–°"><a href="#è½¯æ›´æ–°" class="headerlink" title="è½¯æ›´æ–°"></a>è½¯æ›´æ–°</h3><p>åœ¨æ›´æ–°å‚æ•°è¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡æŒ‰æ¯”ä¾‹æ›´æ–°å‚æ•°ï¼Œæ¯æ¬¡ä»…æ›´æ–°éƒ¨åˆ†æ¯”ä¾‹çš„å‚æ•°ï¼Œå¯ä»¥ä½¿å¼ºåŒ–å­¦ä¹ æ›´å¥½çš„æ”¶æ•›<br><img src="/image/LLM/224.png" alt></p><h1 id="å¼ºåŒ–å­¦ä¹ çš„ä¸€äº›é™åˆ¶"><a href="#å¼ºåŒ–å­¦ä¹ çš„ä¸€äº›é™åˆ¶" class="headerlink" title="å¼ºåŒ–å­¦ä¹ çš„ä¸€äº›é™åˆ¶"></a>å¼ºåŒ–å­¦ä¹ çš„ä¸€äº›é™åˆ¶</h1><p><img src="/image/LLM/225.png" alt></p><p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Unsupervised%20learning%20recommenders%20reinforcement%20learning/week3/Practice%20Lab-Reinforcement%20Learning/C3_W3_A1_Assignment.ipynb" target="_blank" rel="noopener">å®éªŒç»ƒä¹ </a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;å¼ºåŒ–å­¦ä¹ çš„ä¸»è¦æ€æƒ³ä¸æ˜¯å‘Šè¯‰ç®—æ³•æ¯ä¸ªè¾“å…¥çš„æ­£ç¡®è¾“å‡ºæ˜¯ä»€ä¹ˆ&lt;br&gt;è€Œæ˜¯æŒ‡å®šä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œå‘Šè¯‰å®ƒä»€ä¹ˆæ—¶å€™åšçš„å¥½ï¼Œä»€ä¹ˆæ—¶å€™åšçš„ä¸å¥½&lt;br&gt;ç®—æ³•çš„å·¥ä½œæ˜¯è‡ªåŠ¨æ‰¾å‡ºå¦‚ä½•é€‰æ‹©å¥½çš„åŠ¨ä½œ&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/LLM/202.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>æ¨èç³»ç»Ÿ</title>
    <link href="http://yoohannah.github.io/post/machineLearning/RecommenderSystem.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/RecommenderSystem.html</id>
    <published>2024-10-05T23:10:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<p>ä¸‹é¢ä»¥æ ¹æ®ç”µå½±è¯„åˆ†æ¨èç”µå½±ä¸ºä¾‹ï¼Œä»‹ç»æ¨èç³»ç»Ÿçš„å¼€å‘è¿‡ç¨‹</p><h1 id="æ€è·¯æ•´ç†"><a href="#æ€è·¯æ•´ç†" class="headerlink" title="æ€è·¯æ•´ç†"></a>æ€è·¯æ•´ç†</h1><p>æ ¹æ®ç”µå½±çš„ç‰¹å¾ï¼Œç”¨æˆ·å¯¹æ¯ä¸ªç”µå½±éƒ½ä¼šæœ‰ä¸€ä¸ªè¯„åˆ†(0-5åˆ†)ï¼Œæ¯”å¦‚ç”µå½±Açš„è¯„åˆ†æ˜¯5åˆ†ï¼Œç”µå½±Bçš„è¯„åˆ†æ˜¯4åˆ†ï¼Œç”µå½±Cçš„è¯„åˆ†æ˜¯3åˆ†<br>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¯¹æŸç”µå½±è¯„åˆ†è¶Šé«˜ï¼Œè¯´æ˜åç»­å¯¹è¯¥ç±»å‹ç”µå½±çš„é’çåº¦è¶Šé«˜ï¼Œå¯¹äºç³»ç»Ÿæ¥è¯´è¶Šå€¼å¾—æ¨èç»™ç”¨æˆ·<br>å³ç³»ç»Ÿéœ€è¦é¢„æµ‹ç”¨æˆ·å¯¹æŸä¸ªç”µå½±Xçš„è¯„åˆ†ï¼Œä»è€Œå†³å®šæ˜¯å¦æ¨èç»™ç”¨æˆ·<br>ç³»ç»Ÿéœ€è¦ä¾èµ–çš„æ•°æ®æ˜¯ç”µå½±çš„ç‰¹å¾æ•°æ®ï¼ˆXï¼‰å’Œä»¥å¾€ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†æ•°æ®(Y)<br>æ ¹æ®äºŒè€…çš„å…³ç³»ï¼Œè®¡ç®—å‡ºç›¸å…³çš„ç®—æ³•å‚æ•°<br>å½“æœ‰éœ€è¦é¢„æµ‹ä¸€ä¸ªç”µå½±è¯„åˆ†çš„æ—¶å€™ï¼Œè¾“å…¥å¾…è¯„åˆ†ç”µå½±ç‰¹å¾å³å¯å¾—åˆ°è¯„åˆ†ï¼Œç„¶åæ ¹æ®é˜ˆå€¼åˆ¤æ–­æ˜¯å¦æ¨èç»™ç”¨æˆ·<br>ä¸‹é¢æ˜¯å¯¹ä¸€ä¸ªè§‚ä¼—çš„ç”µå½±è¯„åˆ†é¢„æµ‹è¿‡ç¨‹<br><img src="/image/LLM/179.png" alt><br>å¯¹åº”çš„æˆæœ¬å‡½æ•°<br><img src="/image/LLM/180.png" alt><br>å¦‚æœè®­ç»ƒé›†æœ‰å¤šä¸ªç”¨æˆ·çš„è¯„åˆ†æ•°æ®ï¼Œæ‹¿åˆ°æ‰€æœ‰ç”¨æˆ·çš„å‚æ•°ååŠ åˆï¼Œå°±å¯ä»¥é¢„æµ‹å¤§ä¼—ç”¨æˆ·å¯¹æŸä¸ªç”µå½±çš„æ•´ä½“è¯„åˆ†æƒ…å†µ<br><img src="/image/LLM/181.png" alt></p><h1 id="ååŒè¿‡æ»¤ç®—æ³•"><a href="#ååŒè¿‡æ»¤ç®—æ³•" class="headerlink" title="ååŒè¿‡æ»¤ç®—æ³•"></a>ååŒè¿‡æ»¤ç®—æ³•</h1><p>å¯¹äºç”µå½±çš„è¯„åˆ†ï¼Œä¸€å¼€å§‹ä¸èƒ½ç¡®å®šä½¿ç”¨ç”µå½±çš„å“ªäº›ç‰¹å¾ï¼ŒååŒè¿‡æ»¤ç®—æ³•å°†è¾“å…¥ï¼Œç”µå½±çš„ç‰¹å¾Xï¼Œ ä¹Ÿçœ‹åšæ˜¯ä¸€ä¸ªå‚æ•°å‚ä¸æˆæœ¬å‡½æ•°çš„è®¡ç®—<br>ä»è€Œåˆ©ç”¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹æ‰¾åˆ°åˆé€‚çš„å‚æ•°å’Œç‰¹å¾å€¼</p><h2 id="æ¨å¯¼è¿‡ç¨‹"><a href="#æ¨å¯¼è¿‡ç¨‹" class="headerlink" title="æ¨å¯¼è¿‡ç¨‹"></a>æ¨å¯¼è¿‡ç¨‹</h2><ol><li>å·²çŸ¥å¤šä¸ªäººå¯¹ä¸€éƒ¨ç”µå½±çš„è¯„åˆ†å’Œç›¸å…³å‚æ•°ï¼Œå¯ä»¥åæ¨å‡ºX çš„ æƒ…å†µ<br><img src="/image/LLM/182.png" alt></li><li>å¦‚æœç°åœ¨å·²çŸ¥å¤šä¸ªäººå¯¹ä¸€éƒ¨ç”µå½±çš„è¯„åˆ†å’Œç›¸å…³å‚æ•°ï¼Œå¯ä»¥å¯¹ç”µå½±ç‰¹å¾Xè¿›è¡Œæˆæœ¬å‡½æ•°è®¡ç®—<br>åŠ å’Œä¹‹åå¯ä»¥å¯¹å¤šä¸ªç”µå½±çš„ç‰¹å¾è¿›è¡Œé¢„æµ‹<br><img src="/image/LLM/183.png" alt></li><li>è§‚å¯Ÿæˆæœ¬å‡½æ•°çš„å…¬å¼ï¼Œç°åœ¨åŠ å’Œå‚æ•°å’Œç‰¹å¾çš„æˆæœ¬å‡½æ•°ï¼Œ<br><img src="/image/LLM/185.png" alt><br><img src="/image/LLM/184.png" alt></li><li>å¯ä»¥å‘ç°ï¼Œ æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ï¼Œå¯ä»¥åŒæ—¶æ‰¾å‡ºå¤šä¸ªäººå¯¹ç”µå½±è¯„åˆ†å‚æ•°å’Œå¯¹å¤šéƒ¨ç”µå½±çš„ç‰¹å¾å€¼æ¨æµ‹<br><img src="/image/LLM/186.png" alt></li></ol><p>ååŒåœ¨è¿™é‡Œçš„ä½“ç°åœ¨äºå¤šä¸ªç”¨æˆ·å¯¹ä¸€éƒ¨ç”µå½±è¿›è¡Œäº†è¯„ä»·ï¼Œé€šè¿‡åˆä½œå¾—åˆ°äº†å¯¹ç”µå½±çš„æ•´ä½“è¯„ä»·ï¼ŒåŒæ—¶å¯ä»¥é¢„æµ‹å‡ºèƒ½å¤Ÿä»£è¡¨è¿™éƒ¨ç”µå½±çš„ç‰¹å¾å€¼<br>åè¿‡æ¥ï¼Œå¯ä»¥é¢„æµ‹å°šæœªå¯¹åŒä¸€éƒ¨ç”µå½±è¿›è¡Œè¯„åˆ†çš„å…¶ä»–ç”¨æˆ·çš„è¯„åˆ†<br>å³ä»å¤šä¸ªç”¨æˆ·æ”¶é›†æ•°æ®ï¼Œç„¶åé¢„æµ‹å…¶ä»–ç”¨æˆ·çš„è¯„åˆ†</p><h1 id="çº¿æ€§å›å½’è½¬å‘äºŒè¿›åˆ¶åˆ†ç±»"><a href="#çº¿æ€§å›å½’è½¬å‘äºŒè¿›åˆ¶åˆ†ç±»" class="headerlink" title="çº¿æ€§å›å½’è½¬å‘äºŒè¿›åˆ¶åˆ†ç±»"></a>çº¿æ€§å›å½’è½¬å‘äºŒè¿›åˆ¶åˆ†ç±»</h1><p>åŸºäºçº¿æ€§å›å½’çš„æ¨èç³»ç»Ÿé€‚åˆäºä¸Šé¢è¯„åˆ†æœ‰è¿ç»­å€¼çš„æ¨æµ‹ï¼ŒåŸºäºä¸Šè¿°æ€è·¯ï¼Œå°†è¯„åˆ†ç»“æœé€šè¿‡é€»è¾‘å‡½æ•°è½¬æˆäºŒè¿›åˆ¶ç»“æœ<br>å³å¯å®ç°äºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜çš„é¢„æµ‹<br><img src="/image/LLM/187.png" alt><br><img src="/image/LLM/188.png" alt><br><img src="/image/LLM/189.png" alt></p><h1 id="ä¼˜åŒ–"><a href="#ä¼˜åŒ–" class="headerlink" title="ä¼˜åŒ–"></a>ä¼˜åŒ–</h1><h2 id="å‡å€¼å½’ä¸€åŒ–"><a href="#å‡å€¼å½’ä¸€åŒ–" class="headerlink" title="å‡å€¼å½’ä¸€åŒ–"></a>å‡å€¼å½’ä¸€åŒ–</h2><p>å¯¹äºå°šæœªå¯¹ç”µå½±ä½œä¸ºä»»ä½•è¯„ä»·çš„ç”¨æˆ·ï¼Œå¦‚æœå‚æ•°ä¸º0ï¼Œé‚£ä¹ˆé¢„æµ‹çš„è¯„åˆ†ç»“æœä¸º0ï¼Œä¼šæå¤§å½±å“æ¨èçš„å‡†ç¡®æ€§<br>å› æ­¤ï¼Œå…ˆå¯¹å¤šç”¨æˆ·è¯„åˆ†è®¡ç®—å‡å€¼ï¼Œç„¶åå¯¹æ‰€æœ‰ç”¨æˆ·çš„è¯„åˆ†å‡å»å‡å€¼ï¼Œå¾—åˆ°æ–°çš„è¯„åˆ†ï¼Œåœ¨æ–°çš„è¯„åˆ†ä¸Šè¿›è¡Œå‚æ•°è·å–<br>è¿›è¡Œè¯„åˆ†é¢„æµ‹çš„æ—¶å€™å†æŠŠå‡å€¼åŠ å›æ¥ï¼Œè¿™æ ·å³ä½¿å‚æ•°ä¸º0ï¼Œé¢„æµ‹çš„è¯„åˆ†å€¼ä¹Ÿæ˜¯ä¹‹å‰è¯„åˆ†çš„å‡å€¼ï¼Œå¯¹æ•´ä½“è¯„åˆ†meianå€¼ä¸ä¼šæœ‰å½±å“<br><img src="/image/LLM/190.png" alt></p><h2 id="å¦‚ä½•æ‰¾åˆ°ç›¸ä¼¼çš„æ¨è"><a href="#å¦‚ä½•æ‰¾åˆ°ç›¸ä¼¼çš„æ¨è" class="headerlink" title="å¦‚ä½•æ‰¾åˆ°ç›¸ä¼¼çš„æ¨è"></a>å¦‚ä½•æ‰¾åˆ°ç›¸ä¼¼çš„æ¨è</h2><p>æ‰¾åˆ°ä¸å½“å‰item è·ç¦»æœ€è¿‘çš„å…¶ä»–item<br><img src="/image/LLM/191.png" alt></p><h2 id="ååŒè¿‡æ»¤çš„é™åˆ¶"><a href="#ååŒè¿‡æ»¤çš„é™åˆ¶" class="headerlink" title="ååŒè¿‡æ»¤çš„é™åˆ¶"></a>ååŒè¿‡æ»¤çš„é™åˆ¶</h2><ol><li>å¯¹å†·å¯åŠ¨é—®é¢˜ä¸å‹å¥½</li><li>ä¸èƒ½ç›´æ¥è·å–åˆ°æœ‰ä»·å€¼çš„ç‰¹å¾æ•°æ®ï¼Œå¯èƒ½æ˜¯å…³äºè§‚ä¼—æˆ–è€…ç”µå½±çš„ç‰‡é¢çš„ä¿¡æ¯ï¼Œåªèƒ½ä»è¿™äº›ä¿¡æ¯ä¸Šæ¨æµ‹ç”¨æˆ·çš„çˆ±å¥½<br><img src="/image/LLM/192.png" alt></li></ol><h1 id="åŸºäºå†…å®¹çš„æ¨èç®—æ³•"><a href="#åŸºäºå†…å®¹çš„æ¨èç®—æ³•" class="headerlink" title="åŸºäºå†…å®¹çš„æ¨èç®—æ³•"></a>åŸºäºå†…å®¹çš„æ¨èç®—æ³•</h1><p>å¯¹æ¯”åŸºäºååŒè¿‡æ»¤çš„æ¨èç®—æ³•(æ ¹æ®ç”¨æˆ·å¯¹ç›¸ä¼¼itemçš„è¯„åˆ†è¿›è¡Œæ¨è)<br>åŸºäºå†…å®¹çš„æ¨èç®—æ³•åŒæ—¶åŸºäºç”¨æˆ·å’Œitemçš„ç‰¹å¾ï¼Œé€šè¿‡è®¡ç®—item å’Œç”¨æˆ·çš„åŒ¹é…åº¦ï¼Œæ¥åˆ¤æ–­ç”¨æˆ·æ˜¯å¦å¯¹è¯¥itemæ„Ÿå…´è¶£<br><img src="/image/LLM/193.png" alt></p><h2 id="ä¸»è¦æ€è·¯"><a href="#ä¸»è¦æ€è·¯" class="headerlink" title="ä¸»è¦æ€è·¯"></a>ä¸»è¦æ€è·¯</h2><p>åˆ©ç”¨ç¥ç»ç½‘ç»œä»ç”¨æˆ·ç‰¹å¾å’Œitem ç‰¹å¾ä¸­æå–n ä¸ªç‰¹å¾ï¼Œè®¡ç®—äºŒè€…çš„ç‚¹ç§¯ä»è€Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¦å¯¹itemæ„Ÿå…´è¶£ï¼Œæ˜¯å¦è¦æ¨èç»™ç”¨æˆ·<br><img src="/image/LLM/194.png" alt><br><img src="/image/LLM/195.png" alt><br><img src="/image/LLM/196.png" alt><br><img src="/image/LLM/197.png" alt><br><img src="/image/LLM/198.png" alt></p><h1 id="ä»å¤§ç›®å½•ä¸­è¿›è¡Œæ¨è"><a href="#ä»å¤§ç›®å½•ä¸­è¿›è¡Œæ¨è" class="headerlink" title="ä»å¤§ç›®å½•ä¸­è¿›è¡Œæ¨è"></a>ä»å¤§ç›®å½•ä¸­è¿›è¡Œæ¨è</h1><ol><li><p>è¿›è¡Œæ£€ç´¢ï¼Œæ‰¾å‡ºå€™é€‰åˆ—è¡¨<br>ä½†æ˜¯æ£€ç´¢è¿‡ç¨‹éœ€è¦æ³¨æ„ï¼Œé€šè¿‡å¯¹æ›´å¤šçš„é¡¹ç›®è¿›è¡Œæ£€ç´¢å¯ä»¥å¾—åˆ°æ›´å¥½çš„ç»“æœä½†æ˜¯æ£€ç´¢çš„é€Ÿåº¦å›å˜æ…¢ï¼Œ<br>ä¸ºäº†åˆ†æä¼˜åŒ–æƒè¡¡äºŒè€…ï¼Œå¯ä»¥å®æ–½ç¦»çº¿å®éªŒè§‚å¯Ÿæ–°å¢çš„æ£€ç´¢é¡¹æ˜¯å¦å¢åŠ äº†æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§</p></li><li><p>å¯¹å€™é€‰åˆ—è¡¨è¿›è¡Œfine-tuneæ’åºæ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„itemç»™ç”¨æˆ·</p></li></ol><p><img src="/image/LLM/199.png" alt><br><img src="/image/LLM/200.png" alt><br><img src="/image/LLM/201.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ä¸‹é¢ä»¥æ ¹æ®ç”µå½±è¯„åˆ†æ¨èç”µå½±ä¸ºä¾‹ï¼Œä»‹ç»æ¨èç³»ç»Ÿçš„å¼€å‘è¿‡ç¨‹&lt;/p&gt;
&lt;h1 id=&quot;æ€è·¯æ•´ç†&quot;&gt;&lt;a href=&quot;#æ€è·¯æ•´ç†&quot; class=&quot;headerlink&quot; title=&quot;æ€è·¯æ•´ç†&quot;&gt;&lt;/a&gt;æ€è·¯æ•´ç†&lt;/h1&gt;&lt;p&gt;æ ¹æ®ç”µå½±çš„ç‰¹å¾ï¼Œç”¨æˆ·å¯¹æ¯ä¸ªç”µå½±éƒ½ä¼šæœ‰ä¸€ä¸ªè¯„åˆ†(0-5åˆ†
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>å¼‚å¸¸æ£€æµ‹</title>
    <link href="http://yoohannah.github.io/post/machineLearning/abnormalTest.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/abnormalTest.html</id>
    <published>2024-10-05T10:50:37.000Z</published>
    <updated>2024-10-17T03:41:25.828Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å¼‚å¸¸æ£€æµ‹"><a href="#å¼‚å¸¸æ£€æµ‹" class="headerlink" title="å¼‚å¸¸æ£€æµ‹"></a>å¼‚å¸¸æ£€æµ‹</h1><p>å¼‚å¸¸æ£€æµ‹æ˜¯æœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µï¼Œå®ƒæ˜¯æŒ‡åœ¨æ•°æ®ä¸­æ£€æµ‹å‡ºä¸ç¬¦åˆé¢„æœŸçš„æ•°æ®ç‚¹ï¼Œä»¥ä¾¿åŠæ—¶å‘ç°å’Œå¤„ç†å¼‚å¸¸æƒ…å†µã€‚</p><h2 id="æ£€æµ‹æ–¹æ³•ï¼šå¯†åº¦ä¼°è®¡"><a href="#æ£€æµ‹æ–¹æ³•ï¼šå¯†åº¦ä¼°è®¡" class="headerlink" title="æ£€æµ‹æ–¹æ³•ï¼šå¯†åº¦ä¼°è®¡"></a>æ£€æµ‹æ–¹æ³•ï¼šå¯†åº¦ä¼°è®¡</h2><p>å¯†åº¦ä¼°è®¡æ˜¯å¼‚å¸¸æ£€æµ‹ä¸­çš„ä¸€ç§æ–¹æ³•ï¼Œå®ƒé€šè¿‡è®¡ç®—æ•°æ®çš„å¯†åº¦åˆ†å¸ƒæ¥è¯†åˆ«å¼‚å¸¸æ•°æ®ç‚¹ã€‚<br>é€šè¿‡å°†ç‰¹å¾å€¼çš„å¯èƒ½æ€§è¿›è¡Œä¹˜ç§¯è®¡ç®—ï¼Œå¾—åˆ°æ•°æ®çš„å¯†åº¦ï¼Œç„¶åè·Ÿé˜ˆå€¼è¿›è¡Œæ¯”è¾ƒï¼Œåˆ¤æ–­å½“å‰æ•°æ®æ˜¯å¦æ­£å¸¸ã€‚<br><img src="/image/LLM/164.png" alt><br><img src="/image/LLM/169.png" alt><br><img src="/image/LLM/165.png" alt></p><h1 id="é«˜æ–¯åˆ†å¸ƒ"><a href="#é«˜æ–¯åˆ†å¸ƒ" class="headerlink" title="é«˜æ–¯åˆ†å¸ƒ"></a>é«˜æ–¯åˆ†å¸ƒ</h1><p>é«˜æ–¯åˆ†å¸ƒçš„ä½ç½®å—æ•°æ®é›†çš„å¹³å‡å€¼ğœ‡å’Œæ–¹å·®ğœ^2 å†³å®š<br><img src="/image/LLM/166.png" alt><br>ğœ‡ å†³å®šé’Ÿå½¢æœ€é«˜ç‚¹åœ¨xè½´ä¸Šçš„ä½ç½®<br>ğœ^2 å†³å®šé’Ÿå½¢çš„å®½åº¦ï¼Œå› ä¸ºæ•´ä¸ªé’Ÿå½¢é¢ç§¯ä¸º1ï¼Œæ‰€ä»¥ï¼Œå¦‚æœğœ^2 å˜å°ï¼Œé‚£ä¸ªæ•´ä¸ªé’Ÿå½¢ä¼šå˜å¾—å¾ˆé«˜<br><img src="/image/LLM/167.png" alt></p><p><img src="/image/LLM/168.png" alt></p><h1 id="å¼‚å¸¸æ£€æµ‹ç®—æ³•æ­¥éª¤"><a href="#å¼‚å¸¸æ£€æµ‹ç®—æ³•æ­¥éª¤" class="headerlink" title="å¼‚å¸¸æ£€æµ‹ç®—æ³•æ­¥éª¤"></a>å¼‚å¸¸æ£€æµ‹ç®—æ³•æ­¥éª¤</h1><ol><li>åœ¨è®­ç»ƒæ•°æ®ä¸­é€‰æ‹©ä½ è®¤ä¸ºå¯èƒ½ä¼šå¼•èµ·å¼‚å¸¸çš„æ•°æ®çš„nä¸ªç‰¹å¾å€¼</li><li>è®¡ç®—å„ä¸ªç‰¹å¾å€¼çš„å¹³å‡å€¼ğœ‡å’Œæ–¹å·®ğœ^2</li><li>è®¡ç®—æ¯ä¸ªç‰¹å¾å€¼çš„å¯†åº¦ï¼Œå¦‚æœå¯†åº¦å°äºé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºæ˜¯å¼‚å¸¸æ•°æ®</li></ol><p><img src="/image/LLM/170.png" alt></p><h1 id="å¼€å‘è¿‡ç¨‹ä¸­å¦‚ä½•è¯„ä¼°å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"><a href="#å¼€å‘è¿‡ç¨‹ä¸­å¦‚ä½•è¯„ä¼°å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ" class="headerlink" title="å¼€å‘è¿‡ç¨‹ä¸­å¦‚ä½•è¯„ä¼°å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"></a>å¼€å‘è¿‡ç¨‹ä¸­å¦‚ä½•è¯„ä¼°å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ</h1><p>é€šå¸¸é‡‡ç”¨å®æ•°è¯„ä¼°æ–¹æ¡ˆï¼Œå°±æ˜¯å¯ä»¥ç”¨ä¸€ä¸ªå…·ä½“çš„æ•°å€¼å°å°æ¥è¡¡é‡ç®—æ³•çš„å¥½å<br>å‡è®¾è®­ç»ƒæ•°æ®ä¸­çš„æ•°æ®éƒ½æ˜¯æ­£å¸¸çš„ï¼Œå­˜åœ¨æ ‡ç­¾0<br>åœ¨äº¤å‰éªŒè¯å’Œæµ‹è¯•æ•°æ®ä¸­ï¼Œå­˜åœ¨å°‘é‡å¼‚å¸¸æ•°æ®ï¼Œæ ‡ç­¾ä¸º1<br>æµ‹è¯•ç®—æ³•å¥½åçš„æ ‡å‡†å°±æ˜¯èƒ½å¦å°†å¼‚å¸¸æ•°æ®è¯†åˆ«å‡ºæ¥<br>å¦‚æœæ˜¯ç‰¹åˆ«å°‘é‡çš„å¼‚å¸¸æ•°æ®ï¼Œå¯ä»¥ä»…é€šè¿‡äº¤å‰éªŒè¯æ¥è¯„ä¼°æµ‹è¯•å¥½å<br>ä»è€Œå†³å®šåˆé€‚çš„é˜ˆå€¼å¤§å°<br><img src="/image/LLM/171.png" alt><br><img src="/image/LLM/172.png" alt><br>å¦å¤–çš„è¯„ä¼°æ–¹æ³•å¯å‚è€ƒ<a href>äºŒåˆ†ç±»é”™è¯¯åº¦é‡</a><br>ç›¸å…³çš„è¡¡é‡æŒ‡æ ‡ï¼ŒçœŸå‡å€¼ï¼Œç²¾ç¡®ç‡ï¼Œå¬å›ç‡ï¼ŒF1 scoreç­‰<br><img src="/image/LLM/173.png" alt></p><h1 id="å¦‚ä½•é€‰æ‹©å¼‚å¸¸æ£€æµ‹ç®—æ³•å’Œç›‘ç£å­¦ä¹ "><a href="#å¦‚ä½•é€‰æ‹©å¼‚å¸¸æ£€æµ‹ç®—æ³•å’Œç›‘ç£å­¦ä¹ " class="headerlink" title="å¦‚ä½•é€‰æ‹©å¼‚å¸¸æ£€æµ‹ç®—æ³•å’Œç›‘ç£å­¦ä¹ "></a>å¦‚ä½•é€‰æ‹©å¼‚å¸¸æ£€æµ‹ç®—æ³•å’Œç›‘ç£å­¦ä¹ </h1><p>å¼‚å¸¸æ£€æµ‹ç®—æ³•é€‚ç”¨äº</p><ol><li>æ­£å¸¸æ•°æ®å°‘é‡ä½†æ˜¯æœ‰å¤§é‡å¼‚å¸¸æ•°æ®</li><li>å¼‚å¸¸çš„ç‰¹å¾å€¼æ˜¯æœªçŸ¥çš„ï¼Œä¸”æ˜¯å¤šæ ·çš„</li></ol><p>ç›‘ç£å­¦ä¹ ç®—æ³•é€‚ç”¨äº</p><ol><li>å­˜åœ¨å¤§é‡å¼‚å¸¸å’Œæ­£å¸¸æ•°æ®</li><li>æœ‰è¶³å¤Ÿæ•°æ®å‘Šè¯‰ç®—æ³•ä»€ä¹ˆæ˜¯æ­£å¸¸çš„æ•°æ®ï¼Œä»€ä¹ˆæ˜¯å¼‚å¸¸çš„æ•°æ®<br>å°†æ¥å‡ºç°çš„å¼‚å¸¸æ•°æ®å¾ˆå¯èƒ½æ˜¯ä¹‹å‰è®­ç»ƒé›†ä¸­å‡ºç°è¿‡çš„å¼‚å¸¸æ•°æ®</li></ol><p><img src="/image/LLM/174.png" alt></p><p><img src="/image/LLM/175.png" alt></p><h1 id="å¦‚ä½•é€‰æ‹©è¦ä½¿ç”¨çš„ç‰¹å¾"><a href="#å¦‚ä½•é€‰æ‹©è¦ä½¿ç”¨çš„ç‰¹å¾" class="headerlink" title="å¦‚ä½•é€‰æ‹©è¦ä½¿ç”¨çš„ç‰¹å¾"></a>å¦‚ä½•é€‰æ‹©è¦ä½¿ç”¨çš„ç‰¹å¾</h1><ol><li><p>é€‰æ‹©ç¬¦åˆé«˜æ–¯åˆ†å¸ƒçš„ç‰¹å¾ï¼Œå¦‚æœä¸èƒ½æ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒï¼Œå¯ä»¥é€šè¿‡å–å¯¹æ•°ï¼Œå¼€æ–¹ç­‰æ–¹å¼è¿›è¡Œç‰¹æ®Šå¤„ç†åè¿›è¡Œæ‹Ÿåˆ<br>ä½†è¦æ³¨æ„ï¼Œè®­ç»ƒæ•°æ®å¦‚æœæœ‰å¯¹ç‰¹å¾å€¼è¿›è¡Œç‰¹æ®Šå¤„ç†ï¼Œé‚£ä¹ˆäº¤å‰éªŒè¯é›†åˆæµ‹è¯•é›†ä¹Ÿè¦è¿›è¡Œç›¸åŒçš„å¤„ç†<br><img src="/image/LLM/176.png" alt></p></li><li><p>å¯¹äºè¯¯åˆ¤çš„å¼‚å¸¸æ•°æ®ï¼Œå¯ä»¥é€šè¿‡å¢åŠ ç‰¹å¾å€¼æ¥è¿›è¡Œå¼¥è¡¥ï¼Œä¿è¯æ•°æ®åœ¨æ–°åŠ çš„ç‰¹å¾å€¼ä¸Šå­˜åœ¨å¼‚å¸¸å¤§æˆ–è€…å¼‚å¸¸å°çš„æ•°æ®</p></li></ol><p><img src="/image/LLM/177.png" alt></p><ol start="3"><li>å¯ä»¥åœ¨å·²æœ‰çš„åŸå§‹ç‰¹å¾å€¼åŸºç¡€ä¸Šåˆ›é€ æ–°çš„ç‰¹å¾å€¼å‚ä¸è¿ç®—<br><img src="/image/LLM/178.png" alt></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;å¼‚å¸¸æ£€æµ‹&quot;&gt;&lt;a href=&quot;#å¼‚å¸¸æ£€æµ‹&quot; class=&quot;headerlink&quot; title=&quot;å¼‚å¸¸æ£€æµ‹&quot;&gt;&lt;/a&gt;å¼‚å¸¸æ£€æµ‹&lt;/h1&gt;&lt;p&gt;å¼‚å¸¸æ£€æµ‹æ˜¯æœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µï¼Œå®ƒæ˜¯æŒ‡åœ¨æ•°æ®ä¸­æ£€æµ‹å‡ºä¸ç¬¦åˆé¢„æœŸçš„æ•°æ®ç‚¹ï¼Œä»¥ä¾¿åŠæ—¶å‘ç°å’Œå¤„ç†å¼‚å¸¸æƒ…å†µã€‚&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>Kmeans èšç±»ç®—æ³•</title>
    <link href="http://yoohannah.github.io/post/machineLearning/Kmeans.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/Kmeans.html</id>
    <published>2024-10-02T16:37:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<p>æ— ç›‘ç£å­¦ä¹ ç®—æ³•ä¸€</p><h1 id="ä»€ä¹ˆæ˜¯èšç±»"><a href="#ä»€ä¹ˆæ˜¯èšç±»" class="headerlink" title="ä»€ä¹ˆæ˜¯èšç±»"></a>ä»€ä¹ˆæ˜¯èšç±»</h1><p>å°†è¾“å…¥æ•°æ®åˆ†æˆå¤šä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«åŒ…å«ä¸€ç»„ç›¸ä¼¼çš„æ•°æ®ç‚¹çš„è¿‡ç¨‹å°±æ˜¯èšç±»ï¼Œåˆ†å¥½çš„ç±»è¢«ç§°ä¸ºcluster</p><h1 id="èšç±»ç®—æ³•k-meanså¤„ç†è¿‡ç¨‹"><a href="#èšç±»ç®—æ³•k-meanså¤„ç†è¿‡ç¨‹" class="headerlink" title="èšç±»ç®—æ³•k-meanså¤„ç†è¿‡ç¨‹"></a>èšç±»ç®—æ³•k-meanså¤„ç†è¿‡ç¨‹</h1><ol><li>éšæœºé€‰æ‹©kä¸ªç‚¹ä½œä¸ºåˆå§‹çš„ä¸­å¿ƒç‚¹, è®¡ç®—æ¯ä¸ªç‚¹åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»ï¼Œå°†æ¯ä¸ªç‚¹åˆ†é…åˆ°è·ç¦»æœ€è¿‘çš„ä¸­å¿ƒç‚¹æ‰€å±çš„ç±»åˆ«ä¸­</li><li>è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ä¸­å¿ƒç‚¹(å¹³å‡å€¼)ï¼Œå¹¶æ›´æ–°ä¸­å¿ƒç‚¹ï¼Œé‡å¤æ­¥éª¤1</li><li>ç›´åˆ°ä¸­å¿ƒç‚¹ä¸å†å˜åŒ–ï¼Œæˆ–è€…è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°</li></ol><h2 id="å…·ä½“å®ç°-ä¼ªä»£ç "><a href="#å…·ä½“å®ç°-ä¼ªä»£ç " class="headerlink" title="å…·ä½“å®ç°(ä¼ªä»£ç )"></a>å…·ä½“å®ç°(ä¼ªä»£ç )</h2><p><img src="/image/LLM/157.png" alt><br><img src="/image/LLM/158.png" alt></p><h2 id="æˆæœ¬å‡½æ•°"><a href="#æˆæœ¬å‡½æ•°" class="headerlink" title="æˆæœ¬å‡½æ•°"></a>æˆæœ¬å‡½æ•°</h2><p><img src="/image/LLM/159.png" alt><br><img src="/image/LLM/160.png" alt></p><h2 id="å¦‚ä½•åˆå§‹åŒ–ä¸­å¿ƒç‚¹"><a href="#å¦‚ä½•åˆå§‹åŒ–ä¸­å¿ƒç‚¹" class="headerlink" title="å¦‚ä½•åˆå§‹åŒ–ä¸­å¿ƒç‚¹"></a>å¦‚ä½•åˆå§‹åŒ–ä¸­å¿ƒç‚¹</h2><p>éšæœºé€‰æ‹©kä¸ªç‚¹ä½œä¸ºåˆå§‹çš„ä¸­å¿ƒç‚¹ï¼ˆkå°äºmï¼‰ï¼Œè®¡ç®—æœ€ç»ˆä¸­å¿ƒç‚¹å’ŒæŸå¤±å‡½æ•°<br>é‡å¤Næ¬¡ï¼Œé€‰æ‹©æŸå¤±å‡½æ•°æœ€å°çš„ä¸­å¿ƒç‚¹ä½œä¸ºæœ€ç»ˆçš„ä¸­å¿ƒç‚¹<br><img src="/image/LLM/161.png" alt></p><h2 id="å¦‚ä½•é€‰æ‹©Kçš„æ•°é‡"><a href="#å¦‚ä½•é€‰æ‹©Kçš„æ•°é‡" class="headerlink" title="å¦‚ä½•é€‰æ‹©Kçš„æ•°é‡"></a>å¦‚ä½•é€‰æ‹©Kçš„æ•°é‡</h2><p>å–å†³åç»­å¦‚ä½•ä½¿ç”¨åˆ†ç±»å¥½çš„é›†ç¾¤æ•°æ®<br><img src="/image/LLM/163.png" alt><br><img src="/image/LLM/162.png" alt></p><p><a href="https://github.com/kaieye/2022-Machine-Learning-Specialization/blob/main/Unsupervised%20learning%20recommenders%20reinforcement%20learning/week1/2%20Practice%20Lab1/C3_W1_KMeans_Assignment.ipynb" target="_blank" rel="noopener">å‹ç¼©å›¾åƒåº”ç”¨</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;æ— ç›‘ç£å­¦ä¹ ç®—æ³•ä¸€&lt;/p&gt;
&lt;h1 id=&quot;ä»€ä¹ˆæ˜¯èšç±»&quot;&gt;&lt;a href=&quot;#ä»€ä¹ˆæ˜¯èšç±»&quot; class=&quot;headerlink&quot; title=&quot;ä»€ä¹ˆæ˜¯èšç±»&quot;&gt;&lt;/a&gt;ä»€ä¹ˆæ˜¯èšç±»&lt;/h1&gt;&lt;p&gt;å°†è¾“å…¥æ•°æ®åˆ†æˆå¤šä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«åŒ…å«ä¸€ç»„ç›¸ä¼¼çš„æ•°æ®ç‚¹çš„è¿‡ç¨‹å°±æ˜¯èšç±»ï¼Œåˆ†å¥½çš„ç±»è¢«ç§°ä¸ºc
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>å†³ç­–æ ‘æ¨¡å‹</title>
    <link href="http://yoohannah.github.io/post/machineLearning/decisionTreeModel.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/decisionTreeModel.html</id>
    <published>2024-09-30T07:31:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<p>å†³ç­–æ ‘æ¨¡å‹æ˜¯é€šè¿‡è®¡ç®—ç‰¹å¾çº¯åº¦åï¼Œé€‰å–æœ€å¤§çº¯åº¦å€¼çš„ç‰¹å¾ä½œä¸ºå†³ç­–èŠ‚ç‚¹ï¼Œ<br>å°†æ•°æ®æ ¹æ®æ˜¯å¦ç¬¦åˆå½“å‰ç‰¹å¾èŠ‚ç‚¹ä¸€ä»½ä¸ºäºŒï¼Œå†æ ¹æ®ç‰¹å¾çº¯åº¦ï¼Œç»§ç»­åˆ’åˆ†ï¼Œ<br>æœ€åæ ¹æ®åœæ­¢åˆ’åˆ†è§„åˆ™è¿›è¡Œæ•°æ®åˆ†ç±»æˆ–æ¨æµ‹çš„æ¨¡å‹</p><p><img src="/image/LLM/136.png" alt></p><h1 id="åˆ›å»ºè¿‡ç¨‹"><a href="#åˆ›å»ºè¿‡ç¨‹" class="headerlink" title="åˆ›å»ºè¿‡ç¨‹"></a>åˆ›å»ºè¿‡ç¨‹</h1><p>å†³ç­–æ ‘åˆ›å»ºè¿‡ç¨‹éœ€è¦è€ƒè™‘ä¸¤ä»¶äº‹</p><ol><li><p>åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå¦‚æœé€‰æ‹©æ ¹æ®ä»€ä¹ˆç‰¹å¾è¿›è¡Œæ•°æ®åˆ†ç±»<br>Maximize purity<br>å¦‚æœä¸€ä¸ªç‰¹å¾åœ¨æŠŠæ•°æ®åˆ†æˆä¸¤ç»„ä¹‹åï¼Œä½¿åˆ†ç»„åçš„æ•°æ®èƒ½å¤Ÿæœ€å¤§ç¨‹åº¦çš„è¶‹äºåŒä¸€ç±»ï¼Œé‚£ä¹ˆè¿™ä¸ªç‰¹å¾å°±æ˜¯çº¯åº¦é«˜çš„ç‰¹å¾,<br>å³ å¦‚æœè¿™ä¸ªç‰¹å¾èƒ½å¤Ÿç›´æ¥å†³å®šæ•°æ®å±äºå“ªä¸ªåˆ†ç±»çš„ç¨‹åº¦è¶Šé«˜ï¼Œçº¯åº¦å°±è¶Šé«˜<br>æ¯”å¦‚ç”¨DNAç‰¹å¾åˆ¤æ–­çŒ«ç‹—åˆ†ç±»æ¯”ç”¨è€³æœµæ˜¯å°–çš„è¿˜æ˜¯è½¯çš„æ›´ç›´æ¥ï¼ŒDNAç‰¹å¾å°±æ˜¯æœ€å¤§çº¯åº¦çš„ç‰¹å¾<br><img src="/image/LLM/137.png" alt></p></li><li><p>ä»€ä¹ˆæ—¶å€™åœæ­¢æ•°æ®åˆ†ç±»<br>a. å½“ä¸€ä¸ªèŠ‚ç‚¹é‡Œé¢çš„æ•°æ®éƒ½å±äºåŒä¸€ç±»çš„æ—¶å€™<br>b. åˆ°è¾¾æ ‘çš„æ·±åº¦æœ€å¤§å€¼çš„æ—¶å€™ï¼Œæ ‘è¶Šæ·±ï¼Œè¿‡æ‹Ÿåˆè¶Šæœ‰å¯èƒ½ï¼Œè®¡ç®—æˆæœ¬è¶Šé«˜<br>c. å½“ç‰¹å¾çº¯åº¦(ç†µ)ä½äºæŸä¸ªé˜ˆå€¼çš„æ—¶å€™<br>d. å½“èŠ‚ç‚¹é‡Œçš„æ•°æ®ä¸ªæ•°ä½äºæŸä¸ªé˜ˆå€¼çš„æ—¶å€™</p></li></ol><p><img src="/image/LLM/138.png" alt></p><h2 id="ç†µ"><a href="#ç†µ" class="headerlink" title="ç†µ"></a>ç†µ</h2><p>å¯ä»¥ç†è§£ä¸ºæ•°æ®çš„æ··ä¹±ç¨‹åº¦ï¼Œå¦‚æœæ•°æ®ç‰¹åˆ«æ··ä¹±ï¼Œåˆ™å€¼è¶Šå¤§ï¼Œè¿”å›æ•°æ®å¦‚æœç§ç±»å•ä¸€ï¼Œåˆ™å€¼è¶Šå°ï¼Œè¶‹è¿‘0<br>è¿™é‡Œç”¨ç†µæ¥è®¡ç®—ç‰¹å¾çš„éçº¯åº¦æˆ–è€…è¾ƒæ‚è´¨ç¨‹åº¦ï¼Œ<br>å¦‚æœæ ¹æ®æŸä¸ªç‰¹å¾åˆ†ç±»åçš„æ•°æ®çš„ç†µ è¶Šå°ï¼Œè¯´æ•°æ®è¶Šå¹²å‡€ï¼Œæ‚è´¨è¶Šå°‘<br>åä¹‹ï¼Œå¦‚æœå¾—åˆ°çš„ç†µè¶Šå¤§ï¼Œè¯´æ•°æ®è¶Šæ··ä¹±ï¼Œä¸åŒç±»çš„æ•°æ®è¶Šå¤š<br>å¦‚ä¸‹é¢åˆ¤æ–­æ˜¯å¦æ˜¯çŒ«çš„é—®é¢˜<br>p1 ä»£è¡¨æ˜¯æ¯ç»„æ•°æ®ä¸­çŒ«çš„æ¯”ä¾‹ï¼Œéƒ½æ˜¯çŒ«æˆ–ç‹—çš„è¯ç†µ æ˜¯0ï¼Œ5:5 çš„æ—¶å€™ç†µ æœ€å¤§å€¼ä¸º1ï¼Œæ•°æ®æœ€æ··ä¹±<br><img src="/image/LLM/139.png" alt><br>å…·ä½“ç†µ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹<br><img src="/image/LLM/140.png" alt></p><h2 id="ä¿¡æ¯å¢ç›Š"><a href="#ä¿¡æ¯å¢ç›Š" class="headerlink" title="ä¿¡æ¯å¢ç›Š"></a>ä¿¡æ¯å¢ç›Š</h2><p>åœ¨äº†è§£ç†µçš„å«ä¹‰åï¼Œç”¨ä¸‹é¢çš„è®¡ç®—è¿‡ç¨‹é€‰æ‹©èŠ‚ç‚¹çš„åˆ¤æ–­ç‰¹å¾<br>æ ¹èŠ‚ç‚¹çš„ç†µå‡å»åˆ†ç±»åä¸¤ä¸ªèŠ‚ç‚¹ç†µçš„åŠ æƒå¹³å‡å€¼ï¼Œå€¼è¶Šå¤§è¯´æ˜åˆ†ç±»åæ•°æ®è¶Šçº¯äº†<br><img src="/image/LLM/141.png" alt><br>è¿™ä¸ªè®¡ç®—æ–¹å¼å¾—åˆ°çš„å€¼å°±å«ä¿¡æ¯å¢ç›Š<br>å³ç‰¹å¾ä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œåœ¨åˆ†ç±»è¿‡ç¨‹ä¸­ï¼Œèƒ½å¤ŸæŠŠæ•°æ®åˆ†çš„è¶Šçº¯<br><img src="/image/LLM/142.png" alt></p><h2 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h2><p>å†³ç­–æ ‘å­¦ä¹ è¿‡ç¨‹<br><img src="/image/LLM/143.png" alt><br>å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œéƒ½è¦åƒå¯¹å¾…æ ¹èŠ‚ç‚¹ä¸€æ ·<br>æ ¹æ®æ‹¿åˆ°çš„æ•°æ®å…ˆæ‰¾åˆ°æœ€å¤§ä¿¡æ¯å¢ç›Šçš„ç‰¹å¾ç„¶åè¿›è¡Œåˆ†ç±»<br>æ•´ä¸ªè¿‡ç¨‹å°±æ˜¯ä¸€ä¸ªé€’å½’çš„è¿‡ç¨‹ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢åˆ†ç±»çš„è§„åˆ™ä¸ºæ­¢<br><img src="/image/LLM/144.png" alt></p><h1 id="å¤šç‰¹å¾å€¼å¤„ç†åŠæ³•"><a href="#å¤šç‰¹å¾å€¼å¤„ç†åŠæ³•" class="headerlink" title="å¤šç‰¹å¾å€¼å¤„ç†åŠæ³•"></a>å¤šç‰¹å¾å€¼å¤„ç†åŠæ³•</h1><h2 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h2><p>If a categorical feature can take on ğ‘˜ values, create ğ‘˜ binary features (0 or 1 valued).<br>å¦‚æœä¸€ä¸ªç‰¹å¾æœ‰å¤§äº2ä¸ªä»¥ä¸Šçš„Nå¯æšä¸¾å€¼ï¼Œé‚£ä¹ˆå°†å½“å‰ç‰¹å¾æ‹†åˆ†æˆNä¸ªæ–°çš„ä»£è¡¨ç›¸åº”æšä¸¾å€¼çš„ç‰¹å¾å³å¯<br><img src="/image/LLM/145.png" alt></p><h2 id="è¿ç»­å€¼"><a href="#è¿ç»­å€¼" class="headerlink" title="è¿ç»­å€¼"></a>è¿ç»­å€¼</h2><p>å¦‚æœä¸€ä¸ªç‰¹è´¨çš„å€¼æ˜¯è¿ç»­å€¼ï¼Œä¸å¯æšä¸¾ï¼Œé‚£ä¹ˆéœ€è¦è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œå¤§äºè¯¥é˜ˆå€¼ä¸€ç±»ï¼Œå°äºåˆ™æ˜¯å¦ä¸€ç±»ï¼Œä»è€Œå®ç°å¯¹è¯¥ç‰¹å¾çš„äºŒåˆ†ç±»<br>é˜ˆå€¼çš„é€‰å–è¿˜æ˜¯é€šè¿‡è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œé€‰å–èƒ½å¤Ÿä½¿ä¿¡æ¯å¢ç›Šå€¼æœ€å¤§çš„é˜ˆå€¼å‚ä¸åˆ†ç±»<br>ä¸€èˆ¬æƒ…å†µä¸‹å…ˆå¯¹æ‰€æœ‰æ•°æ®æŒ‰è¿™ä¸ªç‰¹å¾å€¼æ’åºï¼Œç„¶åé€‰å–æ’åºåˆ—è¡¨ä¸­ä¸¤ä¸ªæ•°æ®é—´çš„ä¸­ç‚¹åšé˜ˆå€¼è¿›è¡Œä¿¡æ¯å¢ç›Šè®¡ç®—ï¼Œ<br>å¤šè½®è®¡ç®—åå†ä»ä¸­é€‰å–ä¿¡æ¯å¢ç›Šæœ€å¤§çš„é˜ˆå€¼<br><img src="/image/LLM/146.png" alt></p><h1 id="å›å½’æ ‘"><a href="#å›å½’æ ‘" class="headerlink" title="å›å½’æ ‘"></a>å›å½’æ ‘</h1><p>ä¸Šé¢æ˜¯ä½¿ç”¨å†³ç­–æ ‘è¿›è¡Œåˆ†ç±»è®¡ç®—<br>æ¥ä¸‹æ¥ä½¿ç”¨æ–¹å·®å¯¹è¿ç»­æ•°æ®è¿›è¡Œæ¨æµ‹ï¼Œå°±æ˜¯å›å½’æ ‘<br>å¦‚ä¸‹å›¾ï¼Œæ ¹æ®å‰ä¸‰ä¸ªç‰¹å¾ï¼Œæ¨æµ‹weight çš„å€¼ï¼Œweight æ˜¯ä¸ªè¿ç»­çš„å€¼ï¼Œä¸èƒ½æšä¸¾çš„<br><img src="/image/LLM/147.png" alt></p><p><img src="/image/LLM/148.png" alt></p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week4/7.Practice%20lab%20decision%20trees/C2_W4_Decision_Tree_with_Markdown.ipynb#scrollTo=5MIhOlYfSm26" target="_blank" rel="noopener">å†³ç­–æ ‘ç»ƒä¹ </a></p><h1 id="å¤šä¸ªå†³ç­–æ ‘"><a href="#å¤šä¸ªå†³ç­–æ ‘" class="headerlink" title="å¤šä¸ªå†³ç­–æ ‘"></a>å¤šä¸ªå†³ç­–æ ‘</h1><p>å•ä¸ªå†³ç­–æ ‘å¯¹è®­ç»ƒæ•°æ®éå¸¸æ•æ„Ÿï¼Œåªè¦æ›´æ”¹ä¸€ä¸ªè®­ç»ƒæ•°æ®ï¼Œå°±æœ‰å¯èƒ½æ›´æ”¹ä¿¡æ¯å¢ç›Šæ’åºï¼Œ<br>ä»è€Œå½±å“èŠ‚ç‚¹ç‰¹å¾é€‰æ‹©ï¼Œè¿›è€Œå¯¼è‡´æ•´æ£µæ ‘å‘ç”Ÿå˜åŒ–ï¼Œä½¿å¾—ç®—æ³•å¤±å»å¥å£®æ€§<br>è§£å†³åŠæ³•å°±æ˜¯æ„å»ºå¤šä¸ªæ ‘ï¼Œè®©ä»–ä»¬æŠ•ç¥¨æœ€ç»ˆçš„é¢„æµ‹ç»“æœï¼Œä½¿æ•´ä½“çš„ç®—æ³•å¯¹ä»»ä½•å•ä¸ªæ ‘å¯èƒ½åœ¨åšä»€ä¹ˆä¸é‚£ä¹ˆæ•æ„Ÿ<br><img src="/image/LLM/149.png" alt></p><h2 id="æ”¾å›æŠ½æ ·"><a href="#æ”¾å›æŠ½æ ·" class="headerlink" title="æ”¾å›æŠ½æ ·"></a>æ”¾å›æŠ½æ ·</h2><p>ä¸€å…±æœ‰mä¸ªè®­ç»ƒæ•°æ®ï¼Œæ¯æ¬¡ä»mä¸ªæ•°æ®ä¸­éšæœºæŠ½å–1ä¸ªæ•°æ®ï¼Œç›´åˆ°æŠ½å–åˆ°mä¸ªæ•°æ®ï¼ŒæŠ½å–åˆ°çš„æ•°æ®å¯èƒ½æ˜¯é‡å¤çš„<br><img src="/image/LLM/150.png" alt></p><h2 id="éšæœºæ£®æ—ç®—æ³•"><a href="#éšæœºæ£®æ—ç®—æ³•" class="headerlink" title="éšæœºæ£®æ—ç®—æ³•"></a>éšæœºæ£®æ—ç®—æ³•</h2><p>ä½¿ç”¨æ”¾å›æŠ½æ ·çš„æ•°æ®é€‰å–æ–¹æ³•ï¼Œæ¯æ¬¡æ‹¿åˆ°mä¸ªè®­ç»ƒæ•°æ®ï¼Œç”¨è¿™ä¸ªmä¸ªè®­ç»ƒæ•°æ®è®­ç»ƒå†³ç­–æ ‘ï¼Œé‡å¤ B(å°äº100)æ¬¡,<br>å¾—åˆ°Bæ£µå†³ç­–æ ‘ï¼Œä»è€Œå½¢æˆå†³ç­–æ ‘æ£®æ—å¯¹é¢„æµ‹ç»“æœè¿›è¡ŒæŠ•ç¥¨ï¼Œè¿™ç§ç®—æ³•å°±æ˜¯éšæœºæ£®æ—ç®—æ³•<br><img src="/image/LLM/151.png" alt><br>B å¦‚æœå¤§äº100 ä¸€ä¸ªæ˜¯è®­ç»ƒæ•ˆæœä¼šä¸‹é™ï¼Œæ¨æµ‹å‡†ç¡®æ€§é™ä½ï¼Œå¦å¤–ä¸€ä¸ªå°±æ˜¯ä¼šå¢åŠ è®¡ç®—æˆæœ¬ï¼Œä½¿ç®—æ³•å˜å¾—å¤æ‚ï¼Œå¾—ä¸å¿å¤±</p><h3 id="éšæœºç‰¹å¾é€‰å–"><a href="#éšæœºç‰¹å¾é€‰å–" class="headerlink" title="éšæœºç‰¹å¾é€‰å–"></a>éšæœºç‰¹å¾é€‰å–</h3><p>å¯¹äºå…·å¤‡Nä¸ªç‰¹å¾çš„æ•°æ®ï¼Œé€šå¸¸é€‰æ‹©Nçš„Kä¸ªç‰¹å¾å­é›†è¿›è¡Œè®­ç»ƒï¼Œå¦‚æœNç‰¹åˆ«å¤§ï¼ŒKä¸€èˆ¬ç­‰äºNçš„å¹³æ–¹æ ¹<br><img src="/image/LLM/152.png" alt></p><h2 id="XGBoost-éšæœºæ£®æ—å¢å¼ºç®—æ³•"><a href="#XGBoost-éšæœºæ£®æ—å¢å¼ºç®—æ³•" class="headerlink" title="XGBoost éšæœºæ£®æ—å¢å¼ºç®—æ³•"></a>XGBoost éšæœºæ£®æ—å¢å¼ºç®—æ³•</h2><p>é™¤äº†ç¬¬ä¸€æ¬¡ç­‰æ¦‚ç‡çš„ä»mä¸ªè®­ç»ƒæ•°æ®ä¸­æŠ½æ ·new dataSet å¤–ï¼Œåç»­çš„æ¯ä¸€è½®æŠ½æ ·ï¼Œéƒ½å°†å‰ä¸€è½®æ¨æµ‹å¤±è´¥çš„è®­ç»ƒæ•°æ®çš„æƒé‡åŠ å¤§ï¼Œ<br>ä½¿è¢«æŠ½å–åˆ°çš„æ¦‚ç‡å˜é«˜ï¼Œå°½å¯èƒ½çš„å°†æ¨æµ‹å¤±è´¥çš„æ•°æ®å‚ä¸åˆ°åç»­çš„è®­ç»ƒä¸­ï¼Œä»è€Œæ¨åŠ¨ç®—æ³•æ›´å¿«çš„å­¦ä¹ ï¼Œå¹¶å­¦ä¹ çš„æ›´å¥½ï¼Œæé«˜ç®—æ³•çš„å‡†ç¡®æ€§<br><img src="/image/LLM/153.png" alt></p><p>è¿™ç§ç®—æ³•åˆç§°ä¸ºXGBoost ç®—æ³•ï¼Œæ˜¯éšæœºæ£®æ—ç®—æ³•çš„æ”¹è¿›ç‰ˆï¼Œä¼˜ç‚¹å¦‚ä¸‹<br><img src="/image/LLM/154.png" alt><br><img src="/image/LLM/155.png" alt></p><h1 id="å†³ç­–æ ‘-VS-ç¥ç»ç½‘ç»œ"><a href="#å†³ç­–æ ‘-VS-ç¥ç»ç½‘ç»œ" class="headerlink" title="å†³ç­–æ ‘ VS ç¥ç»ç½‘ç»œ"></a>å†³ç­–æ ‘ VS ç¥ç»ç½‘ç»œ</h1><p><img src="/image/LLM/156.png" alt></p><h2 id="å†³ç­–æ ‘-amp-å†³ç­–æ£®æ—"><a href="#å†³ç­–æ ‘-amp-å†³ç­–æ£®æ—" class="headerlink" title="å†³ç­–æ ‘&amp; å†³ç­–æ£®æ—"></a>å†³ç­–æ ‘&amp; å†³ç­–æ£®æ—</h2><p>é€‚åˆç»“æ„åŒ–æ•°æ®(å¯ä»¥ç”¨è¡¨æ ¼è¡¨ç¤ºçš„æ•°æ®)<br>ä¸é€‚åˆéç»“æ„åŒ–æ•°æ®ï¼ˆéŸ³è§†é¢‘ï¼Œå›¾åƒï¼‰<br>å°çš„å†³ç­–æ ‘å¯ä»¥è¢«äººç±»è§£é‡Šæ¨æµ‹è¿‡ç¨‹<br>è®­ç»ƒé€Ÿåº¦å¿«ï¼Œç¼©çŸ­ç®—æ³•è¿­ä»£å¾ªç¯å‘¨æœŸï¼Œæ›´å¿«çš„æé«˜ç®—æ³•æ€§èƒ½</p><h2 id="ç¥ç»ç½‘ç»œ"><a href="#ç¥ç»ç½‘ç»œ" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h2><p>å¯¹äºæ‰€æœ‰æ•°æ®ç±»å‹éƒ½å¾ˆå‹å¥½ï¼ŒåŒ…æ‹¬ç»“æ„åŒ–å’Œéç»“æ„åŒ–<br>è®­ç»ƒé€Ÿåº¦æ¯”å†³ç­–æ ‘è¦æ…¢<br>ä½†å¯ä»¥è½»æ¾å®ç°è¿ç§»å­¦ä¹ ï¼Œä½†æ˜¯å†³ç­–æ ‘æ¯æ¬¡è®­ç»ƒåªèƒ½ç‰¹å®šçš„ç‰¹å¾ï¼Œå¾—åˆ°ç‰¹å®šçš„å†³ç­–æ ‘<br>æ–¹ä¾¿æ„å»ºå¤šæ¨¡å‹ç³»ç»Ÿï¼Œç¥ç»ç½‘ç»œé—´ä¸²è”æ–¹ä¾¿</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;å†³ç­–æ ‘æ¨¡å‹æ˜¯é€šè¿‡è®¡ç®—ç‰¹å¾çº¯åº¦åï¼Œé€‰å–æœ€å¤§çº¯åº¦å€¼çš„ç‰¹å¾ä½œä¸ºå†³ç­–èŠ‚ç‚¹ï¼Œ&lt;br&gt;å°†æ•°æ®æ ¹æ®æ˜¯å¦ç¬¦åˆå½“å‰ç‰¹å¾èŠ‚ç‚¹ä¸€ä»½ä¸ºäºŒï¼Œå†æ ¹æ®ç‰¹å¾çº¯åº¦ï¼Œç»§ç»­åˆ’åˆ†ï¼Œ&lt;br&gt;æœ€åæ ¹æ®åœæ­¢åˆ’åˆ†è§„åˆ™è¿›è¡Œæ•°æ®åˆ†ç±»æˆ–æ¨æµ‹çš„æ¨¡å‹&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/image/LLM/136.png&quot; alt
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¹ å¼€å‘è¿‡ç¨‹</title>
    <link href="http://yoohannah.github.io/post/machineLearning/MachineLearningDevelopmentProcess.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/MachineLearningDevelopmentProcess.html</id>
    <published>2024-09-29T08:39:37.000Z</published>
    <updated>2024-10-17T03:41:22.952Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/LLM/123.png" alt></p><p>æ•´ä¸ªå¼€å‘è¿‡ç¨‹æ˜¯ä¸€ä¸ªé€‰æ‹©æ¡†æ¶ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œè¯Šæ–­æ¨¡å‹å¾ªç¯çš„è¿‡ç¨‹</p><h1 id="é”™è¯¯åˆ†æ"><a href="#é”™è¯¯åˆ†æ" class="headerlink" title="é”™è¯¯åˆ†æ"></a>é”™è¯¯åˆ†æ</h1><p>é™¤äº†ä»é«˜åå·®é«˜è¯¯å·®è§’åº¦å¯¹æ¨¡å‹è¿›è¡Œåˆ†æå¤–ï¼Œè¿˜å¯ä»¥å¯¹mcv äº§ç”Ÿé”™è¯¯åˆ†ç±»çš„è§’åº¦å¯¹æ¨¡å‹è¿›è¡Œåˆ†æ<br><img src="/image/LLM/125.png" alt></p><p>å¯ä»¥ä»äº¤å‰éªŒè¯é›†æµ‹è¯•äº§ç”Ÿçš„é”™è¯¯ä¸­è¿›è¡Œåˆ†æ<br>é€šè¿‡å°†é”™è¯¯è¿›è¡Œå½’ç±»ç»Ÿè®¡ï¼Œæ‰¾å‡ºå¯¹æ¨¡å‹å½±å“æ¯”ä¾‹è¾ƒå¤§çš„é”™è¯¯å’Œæ¯”ä¾‹è¾ƒå°çš„é”™è¯¯<br>ä»è€Œè°ƒæ•´æ¨¡å‹è®­ç»ƒçš„æ–¹å‘ï¼Œå·²è§£å†³ä¸Šé¢é‡åˆ°çš„é—®é¢˜<br><img src="/image/LLM/124.png" alt></p><p>å¦‚æœäº¤å‰éªŒè¯é›†äº§ç”Ÿé”™è¯¯çš„æ•°æ®æ¯”è¾ƒåºå¤§ï¼Œå¯ä»¥é€‰æ‹©è¿›è¡ŒéšæœºæŠ½å–ä¸€å®šå°æ‰¹é‡çš„æ•°æ®è¿›è¡Œé”™è¯¯åˆ†ç±»ï¼Œä»¥èŠ‚çœäººåŠ›</p><h1 id="æ·»åŠ æ•°æ®"><a href="#æ·»åŠ æ•°æ®" class="headerlink" title="æ·»åŠ æ•°æ®"></a>æ·»åŠ æ•°æ®</h1><p>é€šè¿‡å¼•å…¥æ›´å¤šæ•°æ®å®Œå–„æ¨¡å‹çš„åˆ¤æ–­ï¼Œæ›´å…³æ³¨é€šè¿‡æ³¨å…¥çš„æ•°æ®å¼•å‘çš„å¯¹æ¨¡å‹çš„è®­ç»ƒç»“æœçš„å½±å“</p><h2 id="æ•°æ®å¢å¼º"><a href="#æ•°æ®å¢å¼º" class="headerlink" title="æ•°æ®å¢å¼º"></a>æ•°æ®å¢å¼º</h2><p>Augmentation: modifying an existing training example to create a new training example.<br>åœ¨åŸæœ‰æ•°æ®åŸºç¡€ä¸Šï¼Œé€šè¿‡æ·»åŠ ç‰¹å®šç§ç±»çš„å™ªå£°ï¼Œå½¢æˆæ–°çš„æµ‹è¯•æ•°æ®ï¼Œä»è€Œå®Œå–„ç‰¹å®šç§ç±»çš„é”™è¯¯åˆ¤æ–­<br>å¯¹äºå›¾ç‰‡å’ŒéŸ³é¢‘æ•°æ®éƒ½é€‚ç”¨<br><img src="/image/LLM/126.png" alt><br>ä½†æ˜¯å¯¹æ·»åŠ éšæœºæˆ–è€…æ— æ„ä¹‰å™ªå£°äº§ç”Ÿçš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¯¹äºæ¨¡å‹è®­ç»ƒä¸ä¼šæœ‰å¤šå¤§å¸®åŠ©</p><h2 id="æ•°æ®åˆæˆ"><a href="#æ•°æ®åˆæˆ" class="headerlink" title="æ•°æ®åˆæˆ"></a>æ•°æ®åˆæˆ</h2><p>Synthesis: using artificial data inputs to create a new training example.<br>ç›´æ¥ç”±è®¡ç®—æœºåˆæˆè®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®ï¼Œé€šå¸¸ç”¨äºè®¡ç®—æœºè§†è§‰è®­ç»ƒçš„åœºæ™¯<br><img src="/image/LLM/127.png" alt></p><h1 id="è¿ç§»å­¦ä¹ "><a href="#è¿ç§»å­¦ä¹ " class="headerlink" title="è¿ç§»å­¦ä¹ "></a>è¿ç§»å­¦ä¹ </h1><p>åœ¨å·²æœ‰å¤§æ¨¡å‹è®­ç»ƒç»“æœåŸºç¡€ä¸Šï¼Œé€šè¿‡ä¿®æ”¹è¾“å‡ºå±‚ç»“æœä½¿ä¹‹ç¬¦åˆè‡ªå·±ä½¿ç”¨åœºæ™¯çš„è®­ç»ƒæ–¹æ³•<br>å¥½å¤„æ˜¯ï¼Œåœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨è¾“å‡ºå±‚ä¹‹å‰çš„å‚æ•°å¼€å§‹è®­ç»ƒï¼Œå‡å°‘è‡ªå·±ä»å¤´å¼€å§‹è®­ç»ƒçš„å·¥ä½œ</p><p>ä¾‹å¦‚ä¸‹é¢è¿™ä¸ªä½¿ç”¨1000+åˆ†ç±»çš„è®­ç»ƒè¯†åˆ«æ•°å­—0-9çš„æ¨¡å‹ï¼Œåªæ˜¯åœ¨è¾“å‡ºå±‚å°†1000+ è¾“å‡ºæ”¹æˆ10ç§è¾“å‡ºï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå¼€å§‹è®­ç»ƒ<br><img src="/image/LLM/128.png" alt><br>ä¸€èˆ¬è®­ç»ƒæ­¥éª¤ä¸ºä¸‹è½½ç›¸åŒè¾“å…¥(æ–‡æœ¬çš„ä¸‹è½½æ–‡æœ¬çš„ï¼ŒéŸ³è§†é¢‘çš„ä¸‹è½½éŸ³è§†é¢‘çš„)çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åç”¨è‡ªå·±çš„æ•°æ®è¿›è¡Œè®­ç»ƒ(fine tuning)<br><img src="/image/LLM/129.png" alt></p><h1 id="å®Œæ•´å¼€å‘æµç¨‹"><a href="#å®Œæ•´å¼€å‘æµç¨‹" class="headerlink" title="å®Œæ•´å¼€å‘æµç¨‹"></a>å®Œæ•´å¼€å‘æµç¨‹</h1><p><img src="/image/LLM/130.png" alt></p><h2 id="éƒ¨ç½²é˜¶æ®µ"><a href="#éƒ¨ç½²é˜¶æ®µ" class="headerlink" title="éƒ¨ç½²é˜¶æ®µ"></a>éƒ¨ç½²é˜¶æ®µ</h2><p>é€šå¸¸åº”ç”¨å±‚è·Ÿæ¨¡å‹é€šè¿‡Api è¿›è¡Œé€šä¿¡ï¼Œç”¨æˆ·è¾“å…¥xï¼Œ æ¨¡å‹è¿”å›é¢„æµ‹å€¼y^<br>è½¯ä»¶å·¥ç¨‹å¸ˆéœ€è¦æ³¨æ„</p><ol><li>å°½å¯èƒ½çš„ä¿éšœä½æˆæœ¬çš„è®¡ç®—å‡ºå…·æœ‰å¯é æ€§å’Œæœ‰æ•ˆæ€§çš„é¢„æµ‹ç»“æœ</li><li>å¯ä»¥è¿›è¡Œå¤§è§„æ¨¡ç”¨æˆ·æ‰©å±•ä½¿ç”¨</li><li>åœ¨ç”¨æˆ·éšç§å…è®¸åŒæ„çš„æƒ…å†µä¸‹è¿›è¡Œæ—¥å¿—è®°å½•è¾“å…¥å’Œè¾“å‡º</li><li>å¯¹æ¨¡å‹è¿›è¡Œç³»ç»Ÿç›‘æ§ï¼Œæ¯”å¦‚æ ¹æ®ä¸Šé¢æ—¥å¿—çš„è®°å½•ï¼Œè®¡ç®—å‡ºå› ä¸ºå½“å‰æ•°æ®å˜åŒ–å¯¼è‡´è®¡ç®—ç»“æœä¸å‡†æ—¶ï¼Œåˆ¤æ–­æ˜¯å¦è®©æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–</li><li>ä¿éšœæ¨¡å‹æ›´æ–°ï¼Œåœ¨ä¸Šä¸€æ­¥è¿›è¡Œæ¨¡å‹ä¼˜åŒ–åè¦ä¿è¯èƒ½å¤Ÿå°†è€çš„æ¨¡å‹æ›¿æ¢æˆæ–°æ¨¡å‹</li></ol><p><img src="/image/LLM/131.png" alt></p><h1 id="é¿å…é“å¾·åè§ä¼¦ç†é—®é¢˜"><a href="#é¿å…é“å¾·åè§ä¼¦ç†é—®é¢˜" class="headerlink" title="é¿å…é“å¾·åè§ä¼¦ç†é—®é¢˜"></a>é¿å…é“å¾·åè§ä¼¦ç†é—®é¢˜</h1><ol><li>å»ºè®®å¤šå…ƒåŒ–(å¤šèƒŒæ™¯ï¼Œå¤šç§æ—)å›¢é˜Ÿï¼Œä¸Šçº¿å‰è¿›è¡Œå¤´è„‘é£æš´ï¼Œæ¢ç´¢å¯èƒ½å¯¹å¼±åŠ¿ç¾¤ä½“é€ æˆä¼¤å®³çš„å¯èƒ½</li><li>å‚è€ƒè¡Œä¸šæ ‡å‡†</li><li>ä¸Šçº¿å‰é€šè¿‡æŠ€æœ¯è¯Šæ–­äº§ç”Ÿçš„ä¼¤å®³å¯èƒ½æ€§ï¼Œä»è€Œå†³ç­–æ˜¯å¦å¯ä»¥ä¸Šçº¿</li><li>åˆ¶å®šå»¶ç¼“è®¡åˆ’ï¼Œä¸Šçº¿åè§‚æµ‹å¯èƒ½äº§ç”Ÿçš„ä¼¤å®³ï¼ŒåŠæ—¶è¿›è¡Œå›æ»šå¤„ç†<br><img src="/image/LLM/132.png" alt></li></ol><h1 id="äºŒåˆ†ç±»é”™è¯¯åº¦é‡"><a href="#äºŒåˆ†ç±»é”™è¯¯åº¦é‡" class="headerlink" title="äºŒåˆ†ç±»é”™è¯¯åº¦é‡"></a>äºŒåˆ†ç±»é”™è¯¯åº¦é‡</h1><p>åœ¨å¯¹å€¾æ–œæ•°æ®é›†(y=1 å’Œy = 0 æ‰€å æ¯”ä¾‹ä¸æ˜¯5:5)è¿›è¡Œè®­ç»ƒæ—¶ï¼Œ<br>åˆ¤æ–­æ¨¡å‹é¢„æµ‹ç»“æœå¥½åé€šå¸¸äº¤å‰éªŒè¯é›†çš„æ•°æ®è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¸¤ä¸ªæŒ‡æ ‡è¡¡é‡<br><img src="/image/LLM/133.png" alt><br>å¦‚æœäºŒè€…éƒ½è¶‹è¿‘0æˆ–1æ—¶ï¼Œè¯´æ˜å½“å‰çš„æ¨¡å‹ä¸æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ¨¡å‹ï¼Œä¸€ç›´åœ¨æ‰“å°0æˆ–1<br>åªæœ‰äºŒè€…å€¼éƒ½å¾ˆå¤§æ—¶ï¼Œæ‰è¯´æ˜ç®—æ³•æ˜¯æœ‰ç”¨çš„</p><p>ç²¾ç¡®ç‡è¡¨ç¤ºå®é™…ä¸Šy = 1çš„å¯èƒ½æ€§<br>å¬å›ç‡è¡¨ç¤ºæ¨¡å‹è®¡ç®—å‡ºy = 1 çš„å¯èƒ½æ€§</p><h2 id="å¯¹äºç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è¡¡é‡"><a href="#å¯¹äºç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è¡¡é‡" class="headerlink" title="å¯¹äºç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è¡¡é‡"></a>å¯¹äºç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è¡¡é‡</h2><p>ä¸€ç§æ˜¯é€šè¿‡è®¾ç½®é˜ˆå€¼å¤§å°å»æƒè¡¡äºŒè€…ï¼Œä»è€Œè¿›è¡Œå–èˆ<br>æé«˜é˜ˆå€¼ï¼Œä¼šå¢åŠ ç²¾åº¦ï¼Œé™ä½å¬å›ç‡<br>é™ä½é˜ˆå€¼ï¼Œä¼šé™ä½ç²¾åº¦ï¼Œæé«˜å¬å›ç‡<br><img src="/image/LLM/134.png" alt><br>å¦å¤–ä¸€ç§æ˜¯ä½¿ç”¨F1 scoreåˆ†æ•°(è°ƒå’Œå¹³å‡æ•°)ï¼Œè‡ªåŠ¨è®¡ç®—å‡ºæœ€ä½³çš„ç²¾åº¦å’Œå¬å›ç‡ï¼Œä»è€Œé€‰æ‹©å¯¹åº”çš„ç®—æ³•<br><img src="/image/LLM/135.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/image/LLM/123.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;æ•´ä¸ªå¼€å‘è¿‡ç¨‹æ˜¯ä¸€ä¸ªé€‰æ‹©æ¡†æ¶ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œè¯Šæ–­æ¨¡å‹å¾ªç¯çš„è¿‡ç¨‹&lt;/p&gt;
&lt;h1 id=&quot;é”™è¯¯åˆ†æ&quot;&gt;&lt;a href=&quot;#é”™è¯¯åˆ†æ&quot; class=&quot;headerlink&quot; title=&quot;é”™è¯¯åˆ†æ&quot;&gt;
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>é«˜åå·®å’Œé«˜æ–¹å·®</title>
    <link href="http://yoohannah.github.io/post/machineLearning/biasVariance.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/biasVariance.html</id>
    <published>2024-09-27T09:39:37.000Z</published>
    <updated>2024-10-17T03:41:22.952Z</updated>
    
    <content type="html"><![CDATA[<p>é€šè¿‡åˆ¤æ–­é«˜æ–¹å·®å’Œé«˜åå·®çš„å¤§å°å¯ä»¥åˆ¤æ–­æ¨¡å‹çš„æ€§èƒ½é—®é¢˜<br>ä¸€èˆ¬æœ‰ä»¥ä¸‹ä¸¤ä¸ªæ€§èƒ½é—®é¢˜<br>é«˜åå·®æ„å‘³ç€æ¨¡å‹æ¬ æ‹Ÿåˆ<br>é«˜æ–¹å·®æ„å‘³ç€æ¨¡å‹è¿‡æ‹Ÿåˆ</p><p>é«˜åå·®çš„æƒ…å†µä¸‹ï¼Œ<br>Jtrain å€¼ä¼šæ¯”è¾ƒå¤§ï¼Œä¸”Jtrainå’ŒJcv å€¼ç›¸è¿‘<br>ä¹Ÿå°±æ˜¯è¯´Jtrain è¾ƒé«˜å¯¹åº”çš„è®­ç»ƒæ•°æ®çš„æ‹Ÿåˆåº¦æœ¬èº«å°±ä¸å¤Ÿ</p><p>é«˜æ–¹å·®çš„æƒ…å†µä¸‹ï¼Œ<br>Jcv ä¼šè¿œå¤§äºJtrain, Jtrain å€¼å¯èƒ½æ¯”è¾ƒå°<br>å°±æ˜¯è¯´æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®å¾ˆæ‹Ÿåˆï¼Œä½†æ˜¯å¯¹äº¤å‰éªŒè¯æ•°æ®ä¸å¤Ÿæ‹Ÿåˆ</p><p>ä¹Ÿæœ‰é«˜æ–¹å·®å’Œé«˜åå·®ä¸¤ä¸ªé—®é¢˜åŒæ—¶å­˜åœ¨çš„æƒ…å†µ<br>Jtrain å€¼ä¼šæ¯”è¾ƒå¤§ï¼Œä¸”Jcv è¿œå¤§äºJtrain,<br>è¿™ç§æƒ…å†µæ„å‘³ç€æ¨¡å‹å¯èƒ½å¯¹ä¸€äº›æ•°æ®è¿‡æ‹Ÿåˆï¼Œå¯¹ä¸€äº›æ•°æ®åˆå­˜åœ¨æ¬ æ‹Ÿåˆ</p><p><img src="/image/LLM/109.png" alt></p><h1 id="æ­£åˆ™åŒ–å‚æ•°ğœ†-å¯¹æ¨¡å‹çš„å½±å“"><a href="#æ­£åˆ™åŒ–å‚æ•°ğœ†-å¯¹æ¨¡å‹çš„å½±å“" class="headerlink" title="æ­£åˆ™åŒ–å‚æ•°ğœ† å¯¹æ¨¡å‹çš„å½±å“"></a>æ­£åˆ™åŒ–å‚æ•°ğœ† å¯¹æ¨¡å‹çš„å½±å“</h1><p>å¦‚æœğœ†åå¤§ä¼šå¯¼è‡´Jtrain åå¤§ï¼Œå‡ºç°æ¬ æ‹Ÿåˆ<br>(æƒ³è±¡ğœ†ç°åœ¨æ˜¯ä¸€ä¸ªéå¸¸å¤§çš„æ•°å€¼ï¼Œä¸ºä½¿Jtrain æœ€å°ï¼Œå°±ä¼šè®©wå€¼é€æ¸è¶‹è¿‘0, æœ€ç»ˆæ¨¡å‹æ— é™æ¥è¿‘b)<br>å¦‚æœğœ†åå°ä¼šå¯¼è‡´Jtrain åå°ï¼Œä½†æ˜¯Jcv åå¤§ï¼Œå‡ºç°è¿‡æ‹Ÿåˆ<br>(æƒ³è±¡ğœ†ç°åœ¨æ— é™è¶‹è¿‘äº0ï¼Œæˆ–è€…ç›´æ¥ç­‰äº0ï¼Œ é‚£ä¹ˆè¦ä½¿Jtrain æœ€å°ï¼Œwå–å€¼å°±å¾—å˜å¤§ï¼Œå¤šé¡¹å¼å°±ä¼šè¢«ä¿ç•™ï¼Œæœ€ç»ˆæ¨¡å‹å‡ºç°è¿‡æ‹Ÿåˆ)<br>å¦‚æœğœ†å–å€¼é€‚ä¸­å°±å¯ä»¥å®ç°Jtrainå’ŒJcv å€¼éƒ½åä½ï¼Œæ¨¡å‹é€‚å½“æ‹Ÿåˆçš„æ•ˆæœ<br><img src="/image/LLM/110.png" alt></p><h2 id="ğœ†-å¦‚ä½•å–å€¼"><a href="#ğœ†-å¦‚ä½•å–å€¼" class="headerlink" title="ğœ† å¦‚ä½•å–å€¼"></a>ğœ† å¦‚ä½•å–å€¼</h2><p>é€šè¿‡é€‰å–ä¸åŒ ğœ† å¸¦å…¥è®¡ç®—æœ€å°æŸå¤±å‡½æ•°ï¼Œç”¨å¾—åˆ°çš„(w,b)å€¼è®¡ç®—Jcv, é€‰å–å¤šç»„Jcv ä¸­ æœ€å°å€¼çš„(w,b)è¿›è¡ŒJtest è®¡ç®—ï¼Œ<br><img src="/image/LLM/111.png" alt></p><h2 id="ğœ†-è¶‹åŠ¿å›¾"><a href="#ğœ†-è¶‹åŠ¿å›¾" class="headerlink" title="ğœ† è¶‹åŠ¿å›¾"></a>ğœ† è¶‹åŠ¿å›¾</h2><p>ğœ† å¯¹äºè¯¯å·®çš„å½±å“è¶‹åŠ¿å’Œå¤šé¡¹å¼å¯¹è¯¯å·®çš„å½±å“è¶‹åŠ¿å‘ˆé•œåƒå…³ç³»<br>ğœ† å€¼ä»å°åˆ°å¤§ï¼ŒJtrain ä»å°åˆ°å¤§ï¼Œæ¨¡å‹ä»è¿‡æ‹Ÿåˆåˆ°æ¬ æ‹Ÿåˆ<br>å¤šé¡¹å¼å¹³æ–¹æ•°ä»å°åˆ°å¤§ï¼ŒJtrain ä»å¤§åˆ°å°ï¼Œ æ¨¡å‹ä»æ¬ æ‹Ÿåˆåˆ°è¿‡æ‹Ÿåˆ<br><img src="/image/LLM/112.png" alt></p><h1 id="å»ºç«‹æ€§èƒ½åŸºå‡†çº¿æ¥åˆ¤æ–­æ¨¡å‹æ€§èƒ½"><a href="#å»ºç«‹æ€§èƒ½åŸºå‡†çº¿æ¥åˆ¤æ–­æ¨¡å‹æ€§èƒ½" class="headerlink" title="å»ºç«‹æ€§èƒ½åŸºå‡†çº¿æ¥åˆ¤æ–­æ¨¡å‹æ€§èƒ½"></a>å»ºç«‹æ€§èƒ½åŸºå‡†çº¿æ¥åˆ¤æ–­æ¨¡å‹æ€§èƒ½</h1><p>è®¡ç®—åŸºå‡†çº¿ä¸Jtrain çš„å·®Aï¼Œ A å¦‚æœåå¤§è¯´æ˜æ¨¡å‹å­˜åœ¨é«˜åå·®æ¬ æ‹Ÿåˆé—®é¢˜<br>è®¡ç®—Jtrain ä¸ Jcv çš„å·®Bï¼ŒB å¦‚æœåå¤§è¯´æ˜å­˜åœ¨é«˜æ–¹å·®è¿‡æ‹Ÿåˆé—®é¢˜<br>å¦‚æœA å¤§äºB è¯´æ˜å­˜åœ¨é«˜åå·®ï¼Œæ¬ æ‹Ÿåˆ<br>å¦‚æœA å°äºB è¯´æ˜å­˜åœ¨é«˜æ–¹å·®ï¼Œè¿‡æ‹Ÿåˆ<br>å¦‚æœA å’Œ B æ•°å€¼æ¥è¿‘ï¼Œè¯´æ˜ é«˜åå·®å’Œé«˜æ–¹å·®åŒæ—¶å­˜åœ¨<br><img src="/image/LLM/115.png" alt><br>åŸºå‡†çº¿å¯ä»¥æ¥è‡ª<br>äººç±»çš„æµ‹è¯•æ°´å¹³<br>ç«äº‰ç®—æ³•çš„æ€§èƒ½æ°´å¹³<br>åŸºäºè¿‡ç¨‹ç»éªŒåˆ¤æ–­çš„æ°´å¹³<br><img src="/image/LLM/114.png" alt><br>ä»¥ è¯­éŸ³è¯†åˆ«ä¸ºä¾‹<br><img src="/image/LLM/113.png" alt></p><h1 id="å­¦ä¹ æ›²çº¿"><a href="#å­¦ä¹ æ›²çº¿" class="headerlink" title="å­¦ä¹ æ›²çº¿"></a>å­¦ä¹ æ›²çº¿</h1><p>Jtrain å’ŒJcv éš è®­ç»ƒé›†å¤§å°må˜åŒ–çš„è¶‹åŠ¿æ›²çº¿è¢«ç§°ä¸ºå­¦ä¹ æ›²çº¿</p><p>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ<br>Jtrain ä¼šéšm å˜å¤§é€æ¸å˜å¤§ï¼Œå› ä¸ºä¸ºäº†æ‹Ÿåˆæ›´å¤šæ•°æ®ï¼Œæ•°æ®æ¯”ä¸€å®šä¼šæ•£è½åœ¨æ›²çº¿ä¸Šï¼Œè¯¯å·®ç´¯åŠ èµ·æ¥æ•°å€¼ä¼šå˜å¤§<br>Jcv ä¼šéšm å˜å¤§é€æ¸å˜å°ï¼Œå› ä¸ºæ›´å¤šçš„æ•°æ®å¯ä»¥å±•ç¤ºæ›´å¤šçš„æƒ…å†µï¼Œæ˜¯æ¨¡å‹æ‹Ÿåˆåº¦æ›´é«˜ï¼Œå¯¹äºJcv è®¡ç®—å°±æ˜¯è¶Šå°<br><img src="/image/LLM/116.png" alt></p><p>ä½†æ˜¯å¯¹äºå­˜åœ¨é«˜åå·®çš„æ¨¡å‹ï¼Œå¢åŠ æ ·æœ¬æ•°é‡å¹¶ä¸ä¸€å®šèƒ½å¯¹æ¨¡å‹æ‹Ÿåˆäº§ç”Ÿå¤šå¤§å¸®åŠ©ï¼Œ<br>å› ä¸ºé«˜åå·®æ¨¡å‹å…·å¤‡æ¬ æ‹Ÿåˆç‰¹ç‚¹ï¼Œéšæ ·æœ¬æ•°å¢åŠ æŸå¤±å‡½æ•°ä¹Ÿä¼šå¢åŠ ï¼Œä¸”ç›¸å¯¹åŸºæœ¬çº¿è¯¯å·®ä¾ç„¶å­˜åœ¨<br><img src="/image/LLM/117.png" alt></p><p>å¯¹äºå­˜åœ¨é«˜æ–¹å·®çš„æ¨¡å‹ï¼Œå¢åŠ æ ·æœ¬æ•°é‡å¯ä»¥èµ·åˆ°ä¸€å®šå¸®åŠ©<br>å› ä¸ºé«˜æ–¹å·®æ¨¡å‹å…·ä½“è¿‡æ‹Ÿåˆç‰¹ç‚¹ï¼Œä¼šå°†å¢åŠ çš„æ ·æœ¬ç»§ç»­æ‹Ÿåˆåˆ°è‡ªå·±çš„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œç›¸å½“å®¹çº³è¿‘äº†æ›´å¤šçš„æ•°æ®æƒ…å†µ<br>å¯ä»¥æ›´å¥½çš„æ‹Ÿåˆå®é™…çš„æƒ…å†µ<br><img src="/image/LLM/118.png" alt></p><h1 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h1><p>é«˜åå·®å’Œé«˜æ–¹å·®çš„ä¸€äº›è§£å†³æ–¹æ¡ˆ<br><img src="/image/LLM/119.png" alt></p><h1 id="ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨"><a href="#ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨" class="headerlink" title="ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨"></a>ç¥ç»ç½‘ç»œä¸­çš„åº”ç”¨</h1><p>ç¥ç»ç½‘ç»œæ˜¯ä½åå·®çš„æ¨¡å‹ï¼Œ<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚æœJtrain è¿‡å¤§å¯ä»¥ä½¿ç”¨æ›´å¤§çš„ç¥ç»ç½‘ç»œï¼Œç¼ºç‚¹å°±æ˜¯è¿ç®—é€Ÿåº¦ä¼šå˜ä½ä¸”ä¼šå¢åŠ ç ”å‘æˆæœ¬<br>åœ¨Jtrain åŸºæœ¬ä¸åŸºå‡†çº¿ç›¸å·®ä¸å¤§æ—¶è®¡ç®—Jvcï¼Œå¦‚æœJvc è¿‡å¤§å¯ä»¥å¢åŠ æ•°æ®æ ·æœ¬é‡æ–°å›åˆ°æ¨¡å‹è®¡ç®—<br>ç»è¿‡ä¸Šé¢ä¸æ–­é‡å¤çš„è¿‡ç¨‹ï¼Œæœ€ç»ˆå¾—åˆ°åˆé€‚çš„æ¨¡å‹å‚æ•°<br><img src="/image/LLM/120.png" alt><br>åªè¦æ•°æ®è§„åˆ™åŒ–åšçš„åˆé€‚ï¼Œå¤§å‹ç¥ç»ç½‘ç»œæ€»æ˜¯ä¼šæ¯”å°å‹ç¥ç»ç½‘ç»œè¡¨ç°å¥½ä¸€äº›<br><img src="/image/LLM/121.png" alt><br>åœ¨tensorFlow ä¸­ï¼Œå¯ä»¥åœ¨æ„å»ºlayer æ—¶ä¼ å…¥è§„åˆ™åŒ–å‚æ•°<br><img src="/image/LLM/122.png" alt></p><h1 id="ç»ƒä¹ "><a href="#ç»ƒä¹ " class="headerlink" title="ç»ƒä¹ "></a>ç»ƒä¹ </h1><p>ç»ƒä¹ å¤šé¡¹å¼ï¼Œæ­£åˆ™åŒ–å‚æ•°ğœ†ï¼Œè®­ç»ƒæ•°æ®ä¸ªæ•°m, ç¥ç»ç½‘ç»œå±‚æ•°<br><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week3/8.Practice%20Lab%20Advice%20for%20applying%20machine%20learning/C2_W3_Assignment.ipynb#scrollTo=3tnHtCF35uzg" target="_blank" rel="noopener">é“¾æ¥</a></p><p>The simple model is a bit better in the training set than the regularized model but it worse in the cross validation set.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;é€šè¿‡åˆ¤æ–­é«˜æ–¹å·®å’Œé«˜åå·®çš„å¤§å°å¯ä»¥åˆ¤æ–­æ¨¡å‹çš„æ€§èƒ½é—®é¢˜&lt;br&gt;ä¸€èˆ¬æœ‰ä»¥ä¸‹ä¸¤ä¸ªæ€§èƒ½é—®é¢˜&lt;br&gt;é«˜åå·®æ„å‘³ç€æ¨¡å‹æ¬ æ‹Ÿåˆ&lt;br&gt;é«˜æ–¹å·®æ„å‘³ç€æ¨¡å‹è¿‡æ‹Ÿåˆ&lt;/p&gt;
&lt;p&gt;é«˜åå·®çš„æƒ…å†µä¸‹ï¼Œ&lt;br&gt;Jtrain å€¼ä¼šæ¯”è¾ƒå¤§ï¼Œä¸”Jtrainå’ŒJcv å€¼ç›¸è¿‘&lt;br&gt;ä¹Ÿå°±æ˜¯è¯´Jtrain è¾ƒé«˜å¯¹åº”
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>ä¸€äº›å…¶ä»–çš„æ¦‚å¿µ</title>
    <link href="http://yoohannah.github.io/post/machineLearning/advanceOpt.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/advanceOpt.html</id>
    <published>2024-09-25T08:27:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Adam-Algorithm"><a href="#Adam-Algorithm" class="headerlink" title="Adam Algorithm"></a>Adam Algorithm</h1><p>ä¸€ç§åŠ å¿«æ¨¡å‹å­¦ä¹ çš„ä¼˜åŒ–ç®—æ³•<br> å¯ä»¥è‡ªåŠ¨è°ƒèŠ‚å­¦ä¹ ç‡çš„å¤§å°ï¼Œä½¿æ¨¡å‹æ›´å¿«çš„æœæ¢¯åº¦ä¸‹é™çš„æ–¹å‘å­¦ä¹ <br> <img src="/image/LLM/96.png" alt><br> <img src="/image/LLM/97.png" alt><br> <img src="/image/LLM/98.png" alt></p><h1 id="å·ç§¯å±‚"><a href="#å·ç§¯å±‚" class="headerlink" title="å·ç§¯å±‚"></a>å·ç§¯å±‚</h1><p> ä¹‹å‰è®¨è®ºçš„ç¥ç»ç½‘ç»œä¸­çš„ä¸­é—´å±‚ï¼Œéƒ½ä¾èµ–ä¸Šä¸€å±‚æ‰€æœ‰çš„è¾“å‡ºè¿›è¡Œè®¡ç®—<br> Each neuron output is a function of<br> all the activation outputs of the previous layer.<br> æœ‰ä¸€ç§è®¡ç®—æ–¹æ¡ˆæ˜¯åªé€‰å–ä¸Šä¸€å±‚çš„éƒ¨åˆ†æ•°æ®è®¡ç®—æœ¬å±‚çš„è¾“å‡º<br> è¿™ç§layer è¢«ç§°ä¸ºå·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰<br> ä¼˜ç‚¹æœ‰ä¸¤ä¸ª<br> ä¸€ä¸ªæ˜¯å¯ä»¥åŠ å¿«è®¡ç®—ï¼Œ<br> å¦å¤–ä¸€ä¸ªæ˜¯å¯ä»¥å‡å°‘éœ€è¦çš„è®­ç»ƒæ•°æ®</p><p>  <img src="/image/LLM/99.png" alt></p><h1 id="é™ä½é¢„æµ‹ç»“æœé”™è¯¯ç‡"><a href="#é™ä½é¢„æµ‹ç»“æœé”™è¯¯ç‡" class="headerlink" title="é™ä½é¢„æµ‹ç»“æœé”™è¯¯ç‡"></a>é™ä½é¢„æµ‹ç»“æœé”™è¯¯ç‡</h1><p>æ‹¿åˆ°è®­ç»ƒæ¨¡å‹åï¼Œå¦‚æœé‡åˆ°ä¸€ä¸ªä¸å¯æ¥å—çš„é”™è¯¯è¾“å‡ºï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œé‡æ–°è°ƒæ•´<br><img src="/image/LLM/100.png" alt></p><p>æ›´å¸¸è§çš„æ–¹å¼æ˜¯ç”¨è¯Šæ–­çš„æ–¹å¼è¯„ä¼°æ¨¡å‹å¥½å<br>åœ¨è®­ç»ƒå‰å°†æ•°æ®åˆ†æˆä¸¤ç»„ï¼Œ<br>ä¸€ç»„ç”¨äºæ¨¡å‹è®­ç»ƒï¼Œç§°ä¸ºè®­ç»ƒç»„<br>å¦ä¸€ç»„ç”¨äºæµ‹è¯•è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ï¼Œç§°ä¸ºæµ‹è¯•ç»„</p><p>æ¯”å¦‚å¯¹äºè¿‡æ‹Ÿåˆçš„æƒ…å†µ<br>å°†æ•°æ®åˆ†æˆä¸¤ç»„<br><img src="/image/LLM/101.png" alt><br>åˆ†åˆ«è®¡ç®—è®­ç»ƒç»„å’Œæµ‹è¯•ç»„çš„æŸå¤±å‡½æ•°<br><img src="/image/LLM/102.png" alt><br>å¯¹äºè®­ç»ƒç»„æ•°æ®çš„æŸå¤±å‡½æ•°è‚¯å®šä¼šæ›´å°<br>è¦å…³æ³¨çš„æ˜¯æµ‹è¯•æ•°æ®çš„æŸå¤±å‡½æ•°ï¼Œå€¼è¶Šå°ï¼Œè¯´æ˜è¶Šè¿‘çœŸå®çš„å€¼ï¼Œè¯´æ˜æ¨¡å‹è¶Šå¥½<br>ä¸Šé¢æ˜¯çº¿æ€§å›å½’æ¨¡å‹ï¼Œä¸‹é¢æ˜¯å¯¹äºåˆ†ç±»é—®é¢˜çš„æŸå¤±å‡½æ•°è®¡ç®—<br><img src="/image/LLM/103.png" alt></p><p><img src="/image/LLM/104.png" alt></p><p>å¦‚æœéœ€è¦åœ¨å¤šä¸ªæ¨¡å‹é—´è¿›è¡Œé€‰æ‹©ï¼Œå¯ä»¥åœ¨ä¸€å¼€å§‹çš„æ—¶å€™å°†æ•°æ®åˆ†æˆä¸‰ç»„<br>è®­ç»ƒç»„ï¼Œäº¤å‰éªŒè¯ç»„ï¼Œæµ‹è¯•ç»„</p><p>åŒæ ·è®¡ç®—åŸºäºäº¤å‰éªŒè¯ç»„æ•°æ®çš„æŸå¤±å‡½æ•°ï¼Œå€¼è¶Šå°è¯´æ˜è¶Šç¬¦åˆå®é™…æ•°æ®<br>ä¸»è¦ä½œç”¨æ˜¯ç”¨äºé€‰æ‹©æ¨¡å‹ï¼Œæ¯”å¦‚æŒ‘å‡ºæœ€åˆé€‚çš„å¤šé¡¹å¼</p><p>ç„¶åå†ä½¿ç”¨æµ‹è¯•ç»„æ•°æ®è¿›è¡Œæ³›åŒ–é”™è¯¯çš„æµ‹è¯•</p><p><img src="/image/LLM/105.png" alt><br><img src="/image/LLM/106.png" alt><br><img src="/image/LLM/107.png" alt><br><img src="/image/LLM/108.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Adam-Algorithm&quot;&gt;&lt;a href=&quot;#Adam-Algorithm&quot; class=&quot;headerlink&quot; title=&quot;Adam Algorithm&quot;&gt;&lt;/a&gt;Adam Algorithm&lt;/h1&gt;&lt;p&gt;ä¸€ç§åŠ å¿«æ¨¡å‹å­¦ä¹ çš„ä¼˜åŒ–ç®—æ³•&lt;br&gt; å¯ä»¥è‡ªåŠ¨
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>å¤šåˆ†ç±»é—®é¢˜</title>
    <link href="http://yoohannah.github.io/post/machineLearning/softMax.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/softMax.html</id>
    <published>2024-09-25T08:27:37.000Z</published>
    <updated>2024-10-17T03:41:22.950Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h1><p>ä¹‹å‰çš„äºŒåˆ†ç±»é—®é¢˜ç”¨logic regression å¯ä»¥è§£å†³ï¼Œ<br>ä½†æ˜¯å¯¹äºå¤šåˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šï¼Œéµå¾ªæ‰€æœ‰å¯èƒ½æ€§åŠ å’Œä¸º1çš„åŸåˆ™<br>è¿›è¡Œæ‰©å±•</p><p>å‡å¦‚ç°åœ¨éœ€è¦åˆ¤æ–­4ç§å¯èƒ½æ€§çš„æ¦‚ç‡<br>é‚£æˆ‘ä»¬éœ€è¦å››æ¡åˆ†ç•Œçº¿ï¼ˆå¦‚ä¸‹å›¾åœ¨z1-z4ï¼‰<br>ç„¶åé€šè¿‡é€šè¿‡ä¸‹é¢è¿™ä¸ªå…¬å¼<br><img src="/image/LLM/87.png" alt><br>è®¡ç®—å¾—åˆ°a1 - a4<br>å°±å¯ä»¥å¾—åˆ°4ç§å¯èƒ½æ€§çš„æ¦‚ç‡</p><p>è¿™ç§ç®—æ³•å°±æ˜¯ Softmax regression<br><img src="/image/LLM/86.png" alt></p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>å‚ç…§é€»è¾‘å›å½’å‡½æ•°çš„æŸå¤±å‡½æ•°<br>å‡å¦‚y = 1, é‚£ä¹ˆæŸå¤±å‡½æ•°å°±æ˜¯<br><img src="/image/LLM/88.png" alt><br>y = 0 çš„è¯æŸå¤±å‡½æ•°å°±æ˜¯<br><img src="/image/LLM/89.png" alt></p><p>å½’çº³ä¸€ä¸‹å°±æ˜¯ï¼Œå½“y = anæ—¶<br>æŸå¤±å‡½æ•°å°±æ˜¯Loss = -log(an)<br>å› ä¸º y åªèƒ½å¯èƒ½æ˜¯a1-an N ç§å¯èƒ½æ€§ä¸­çš„ä¸€ç§<br>ä¸‹é¢çš„Lossè¶‹åŠ¿å›¾è¯´æ˜ï¼Œå½“an å€¼è¶Šæ¥è¿‘1 çš„æ—¶å€™ æŸå¤±å‡½æ•°è¶Šå°<br>ä¹Ÿå°±æ˜¯è¯´a1 - an è¿™äº›æ¦‚ç‡å€¼è¶Šæ¥è¿‘1 æŸå¤±å‡½æ•°è¶Šå°<br>ç›¸å½“äºæ¦‚ç‡å€¼å¯¹åº”çš„å¯èƒ½æ€§è¶Šå¯èƒ½æ¥è¿‘çœŸå®yå€¼ï¼Œè¶Šå‡†<br><img src="/image/LLM/90.png" alt></p><h2 id="åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨"><a href="#åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨" class="headerlink" title="åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨"></a>åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨</h2><p>ä¹‹å‰çš„äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œåœ¨ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚ä½¿ç”¨sigmoid å‡½æ•°ä½œä¸ºè¾“å‡ºå‡½æ•°ï¼ˆæˆ–è€…æ¿€æ´»å‡½æ•°ï¼‰å¯ä»¥è¯†åˆ«å›¾ç‰‡ä¸­çš„ 0 å’Œ 1<br>ç°åœ¨å¦‚æœè¦è¯†åˆ«å›¾ç‰‡ä¸­çš„æ•°å­—æ˜¯0-9 10ç§åˆ†ç±»ä¸­çš„å“ªä¸€ç§ï¼Œ<br>è¦åšçš„å°±æ˜¯å°†è¾“å‡ºå±‚æ¿€æ´»å‡½æ•°æ¢æˆsoftmax å‡½æ•°ï¼Œå¹¶ä¸”æ˜¯10ä¸ªèŠ‚ç‚¹å°±å¯ä»¥å®ç°<br>æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ç§å¯èƒ½ï¼Œå€¼æœ€å¤§çš„å°±æ˜¯å¯èƒ½æ€§æœ€å¤§çš„å€¼</p><p><img src="/image/LLM/91.png" alt></p><h2 id="tensorFlow-ä¸­å®ç°"><a href="#tensorFlow-ä¸­å®ç°" class="headerlink" title="tensorFlow ä¸­å®ç°"></a>tensorFlow ä¸­å®ç°</h2><p>æ–¹æ¡ˆ1<br><img src="/image/LLM/92.png" alt><br>ä¸æ¨èï¼Œç”¨æ–¹æ¡ˆ2ä¼˜åŒ–</p><p>æ–¹æ¡ˆ2<br><img src="/image/LLM/93.png" alt></p><p>åŸå› æ˜¯åœ¨tensorFlow ä¸­ä½¿ç”¨ä¸­é—´æ­¥éª¤è®¡ç®—æ•°å€¼å’Œç›´æ¥å°†å¼å­å¸¦å…¥è®¡ç®—æœ€ç»ˆå€¼çš„å¤„ç†è¿‡ç¨‹ä¸åŒï¼Œtensorflow ä¼šå¯¹åè€…é‡æ–°æ’åˆ—è¡¨è¾¾å¼ä¸­çš„æœ¯è¯­<br>å¹¶æƒ³å‡ºä¸€ç§æ›´å‡†ç¡®çš„è®¡ç®—æ–¹å¼å»è®¡ç®—ï¼Œæ–¹æ¡ˆäºŒåœ¨æ–¹æ¡ˆä¸€åŸºç¡€ä¸Šåšçš„ä¿®æ”¹å°±æ˜¯åœ¨å°†å¼å­å¸¦å…¥è®¡ç®—ï¼Œè€Œä¸æ˜¯å…ˆè®¡ç®—ä¸­é—´å€¼ï¼Œå†å¸¦å…¥</p><h1 id="åŒºåˆ«å¤šæ ‡ç­¾å¤šåˆ†ç±»é—®é¢˜"><a href="#åŒºåˆ«å¤šæ ‡ç­¾å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="åŒºåˆ«å¤šæ ‡ç­¾å¤šåˆ†ç±»é—®é¢˜"></a>åŒºåˆ«å¤šæ ‡ç­¾å¤šåˆ†ç±»é—®é¢˜</h1><p>ä¸Šé¢è®¨è®ºçš„æ˜¯å¤šåˆ†ç±»é—®é¢˜ï¼Œä¸€ä¸ªé—®é¢˜å¤šä¸ªå¯èƒ½æ€§<br> å¤šæ ‡ç­¾å¤šåˆ†ç±»é—®é¢˜æ˜¯æŒ‡åŒæ—¶æ¨æµ‹å¤šä¸ªé—®é¢˜çš„å¤šä¸ªå¯èƒ½æ€§<br><img src="/image/LLM/94.png" alt><br> è®¡ç®—æ–¹å¼å¯ä»¥æ˜¯åˆ†åˆ«çœ‹æˆå•ä¸ªç¥ç»ç½‘ç»œè®¡ç®—ï¼Œä¸€ä¸ªç¥ç»ç½‘ç»œå¤„ç†ä¸€ä¸ªé—®é¢˜çš„å¤šç§å¯èƒ½<br> ä¹Ÿå¯ä»¥åŒæ—¶è®¡ç®—ï¼Œè¾“å‡ºå¤šä¸ªé—®é¢˜å¯¹åº”çš„å¤šä¸ªå¯èƒ½<br> <img src="/image/LLM/95.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Softmax-regression&quot;&gt;&lt;a href=&quot;#Softmax-regression&quot; class=&quot;headerlink&quot; title=&quot;Softmax regression&quot;&gt;&lt;/a&gt;Softmax regression&lt;/h1&gt;&lt;p&gt;ä¹‹å‰çš„äºŒåˆ†ç±»
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>ç¥ç»ç½‘ç»œ</title>
    <link href="http://yoohannah.github.io/post/machineLearning/neuralNetworks.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/neuralNetworks.html</id>
    <published>2024-09-20T09:27:37.000Z</published>
    <updated>2024-10-17T03:41:22.952Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ"><a href="#ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ" class="headerlink" title="ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ"></a>ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ</h1><p>ç±»ä¼¼äºå¤§è„‘ä¸­çš„ç¥ç»å…ƒä¼ é€’ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œå°†å¤šä¸ªè¾“å…¥é€šè¿‡å¤šå±‚æ¨¡å‹å¤„ç†åå¾—åˆ°ç»“æœè¾“å‡ºçš„æ¶æ„ï¼Œå°±æ˜¯ç¥ç»ç½‘ç»œ</p><p><img src="/image/LLM/67.png" alt><br><img src="/image/LLM/68.png" alt><br><img src="/image/LLM/69.png" alt></p><p>å¤æ‚ç¥ç»ç½‘ç»œçš„è¡¨ç¤º<br><img src="/image/LLM/70.png" alt><br>ä»é¢„æµ‹æ‰‹å†™æ•°æ®0å’Œ1 çš„è¿‡ç¨‹ï¼Œç†è§£ç¥ç»ç½‘ç»œå‘å‰ä¼ æ’­çš„è®¡ç®—åŸç†<br><img src="/image/LLM/71.png" alt></p><p>The parameters have dimensions that are sized for a neural network with  25  units in layer 1,  15  units in layer 2 and  1  output unit in layer 3.<br>the dimensions of these parameters are determined as follows:<br>If network has  ğ‘ ğ‘–ğ‘›  units in a layer and  ğ‘ ğ‘œğ‘¢ğ‘¡  units in the next layer, then<br>ğ‘Š  will be of dimension  ğ‘ ğ‘–ğ‘›Ã—ğ‘ ğ‘œğ‘¢ğ‘¡ .<br>ğ‘  will a vector with  ğ‘ ğ‘œğ‘¢ğ‘¡  elements<br>Therefore, the shapes of W, and b, are<br>layer1: The shape of W1 is (400, 25) and the shape of b1 is (25,)<br>layer2: The shape of W2 is (25, 15) and the shape of b2 is: (15,)<br>layer3: The shape of W3 is (15, 1) and the shape of b3 is: (1,)<br>Note: The bias vector b could be represented as a 1-D (n,) or 2-D (n,1) array. Tensorflow utilizes a 1-D representation and this lab will maintain that convention.</p><p>å‘å‰ä¼ æ’­ï¼šä»å·¦åˆ°å³è®¡ç®—ï¼Œæ ¹æ®è¾“å…¥è®¡ç®—å‡ºè¾“å‡ºï¼Œè¾“å‡ºå³é¢„æµ‹ç»“æœï¼Œ<br><img src="/image/LLM/72.png" alt></p><p>ä½¿ç”¨tensorflow å®ç°å‘å‰ä¼ æ’­çš„ç¥ç»ç½‘ç»œ<br><img src="/image/LLM/73.png" alt></p><p>å…·ä½“å®ç°<br><img src="/image/LLM/77.png" alt><br><img src="/image/LLM/78.png" alt><br><img src="/image/LLM/76.png" alt></p><p>Tensorflow models are built layer by layer. A layerâ€™s input dimensions ( ğ‘ ğ‘–ğ‘›  above) are calculated for you. You specify a layerâ€™s output dimensions and this determines the next layerâ€™s input dimension. The input dimension of the first layer is derived from the size of the input data specified in the model.fit statment below.</p><p>Note: It is also possible to add an input layer that specifies the input dimension of the first layer. For example:<br>tf.keras.Input(shape=(400,)), #specify input shape<br>We will include that here to illuminate some model sizing.</p><p>è°ƒç”¨numpy()æ–¹æ³•å¯ä»¥å®ç°å¼ é‡å’Œnumpy matrix ä¹‹é—´çš„è½¬æ¢<br><img src="/image/LLM/74.png" alt><br>ä½¿ç”¨tensorflow å®ç°ç¥ç»ç½‘ç»œçš„å¦å¤–ä¸€ç§æ¶æ„å½¢å¼<br><img src="/image/LLM/75.png" alt></p><p>The model.compile statement defines a loss function and specifies a compile optimization.<br>The model.fit statement runs gradient descent and fits the weights to the data.</p><p><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Advanced%20Learning%20Algorithms/week1/9.Practice%20Lab%20Neural%20networks/C2_W1_Assignment.ipynb#scrollTo=qI3g3oYtRTZp" target="_blank" rel="noopener">å›¾ç‰‡è¯†åˆ«0å’Œ1ç»ƒä¹ </a></p><h1 id="ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹"><a href="#ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹"></a>ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹</h1><p><img src="/image/LLM/78.png" alt><br><img src="/image/LLM/79.png" alt><br><img src="/image/LLM/80.png" alt><br><img src="/image/LLM/81.png" alt><br><img src="/image/LLM/82.png" alt><br><img src="/image/LLM/83.png" alt></p><h2 id="å¦‚ä½•é€‰æ‹©æ¿€æ´»å‡½æ•°"><a href="#å¦‚ä½•é€‰æ‹©æ¿€æ´»å‡½æ•°" class="headerlink" title="å¦‚ä½•é€‰æ‹©æ¿€æ´»å‡½æ•°"></a>å¦‚ä½•é€‰æ‹©æ¿€æ´»å‡½æ•°</h2><p>å¸¸è§çš„ä¸‰ç§æ¿€æ´»å‡½æ•°<br><img src="/image/LLM/84.png" alt></p><p>é€‰æ‹©æ¿€æ´»å‡½æ•°çš„ä¸€èˆ¬è§„åˆ™<br>å¯¹äºè¾“å‡ºå±‚ï¼Œæ ¹æ®è¾“å‡ºå€¼æ¥<br>å¦‚æœæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨sigmoid<br>å¦‚æœæ˜¯è¾“å‡ºæ­£è´Ÿå€¼éƒ½æœ‰å°±é€‰åˆ™çº¿æ€§æ¿€æ´»å‡½æ•°<br>å¦‚æœè¾“å‡ºå€¼éè´Ÿï¼Œé‚£ä¹ˆ å°±ä½¿ç”¨ReLuå‡½æ•°<br>å¯¹äºä¸­é—´å±‚ï¼Œä¸€å¾‹ä½¿ç”¨ReLuå‡½æ•°<br>åŸå› æœ‰ä¸‰</p><ol><li>ä¸€ä¸ªæ˜¯ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œæœ¬èº«è®¡ç®—è¿‡ç¨‹æ¯”sigmoid å‡½æ•°ç®€å•</li><li>reluåªæœ‰åœ¨å°äº0 çš„æ—¶å€™æ–œç‡ä¸º0ï¼Œsigmoid å‡½æ•°åœ¨è¶‹å‘æ­£è´Ÿæ— ç©·çš„æ—¶å€™æœ‰ä¸¤å¤„æ–œç‡è¶‹è¿‘0 çš„æƒ…å†µï¼Œä¼šå¯¼è‡´æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹å˜æ…¢ï¼Œæ‰€ä»¥ReLuå‡½æ•°åœ¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ç›¸æ¯”ä¹‹ä¸‹ä¼šæ›´å¿«ä¸€äº›</li><li>å¦‚æœåœ¨éšè—å±‚ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºå±‚æ˜¯sigmoidå‡½æ•°ï¼Œæ•´ä¸ªè¿‡ç¨‹ç­‰åŒäºçº¿æ€§å›å½’ï¼Œæœ€ç»ˆå§‹ç»ˆä¼šå˜æˆäºŒåˆ†ç±»çš„ç»“æœ</li></ol><p><img src="/image/LLM/85.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ&quot;&gt;&lt;a href=&quot;#ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ&quot; class=&quot;headerlink&quot; title=&quot;ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ&quot;&gt;&lt;/a&gt;ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ&lt;/h1&gt;&lt;p&gt;ç±»ä¼¼äºå¤§è„‘ä¸­çš„ç¥ç»å…ƒä¼ é€’ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œå°†å¤šä¸ªè¾“å…¥é€šè¿‡å¤šå±‚æ¨¡å‹å¤„ç†åå¾—åˆ°ç»“æœè¾“å‡ºçš„æ¶æ„ï¼Œå°±æ˜¯ç¥ç»ç½‘ç»œ&lt;/
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜</title>
    <link href="http://yoohannah.github.io/post/machineLearning/overfitting.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/overfitting.html</id>
    <published>2024-09-17T13:05:37.000Z</published>
    <updated>2024-11-11T08:54:32.585Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ"><a href="#ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ" class="headerlink" title="ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ"></a>ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ</h1><p>è®­ç»ƒå¾—åˆ°çš„é¢„æµ‹æ¨¡å‹å¯¹äºæ¯ä¸ªè®­ç»ƒæ•°æ®éƒ½éå¸¸å»åˆï¼Œå¯¼è‡´å¯¹äºæ–°çš„æµ‹è¯•æ•°æ®æ— æ³•æ­£ç¡®è¯„ä¼°çš„ç°è±¡ï¼Œå°±æ˜¯è¿‡æ‹Ÿåˆ<br>ä¸‹é¢æ˜¯çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’æ¨¡å‹ä¸‰ç§è®­ç»ƒç»“æœçš„å±•ç¤º<br><img src="/image/LLM/57.png" alt><br><img src="/image/LLM/58.png" alt></p><h1 id="è§£å†³åŠæ³•"><a href="#è§£å†³åŠæ³•" class="headerlink" title="è§£å†³åŠæ³•"></a>è§£å†³åŠæ³•</h1><ol><li>æ”¶é›†æ›´å¤šçš„æ•°æ®è¿›è¡Œè®­ç»ƒ</li><li>é€‰æ‹©å’Œä½¿ç”¨æœ‰ä»·å€¼çš„ç‰¹æ€§å€¼å‚ä¸è¿ç®—</li><li>å‡å°éƒ¨åˆ†ç‰¹å¾å€¼(å¯¹äºç»“æœé¢„æµ‹å…³ç³»ä¸å¤§çš„ç‰¹å¾å€¼)çš„å‚æ•°å€¼ï¼ˆæ­£åˆ™åŒ–ï¼‰</li></ol><h1 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h1><p>åœ¨æˆæœ¬å‡½æ•°æˆ–è€…æŸå¤±å‡½æ•°ä¸­å¢åŠ æ­£åˆ™åŒ–å‚æ•°ï¼Œé¿å…è¿‡æ‹Ÿåˆ<br><img src="/image/LLM/59.png" alt></p><p>åœ¨æ¢¯åº¦ä¸‹é™è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œä¼šä½¿å¾—æ¯ä¸ªå‚æ•°åœ¨åŸæ¥åŸºç¡€ä¸Šä¹˜ä»¥ä¸€ä¸ªæ¯”1å°çš„æ•°æ®å†å»è¿›è¡Œå‡æ³•è¿ç®—ï¼Œä»è€Œä½¿å¾—æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å®ç°å‚æ•°è¿›ä¸€æ­¥ç¼©å°<br><img src="/image/LLM/60.png" alt><br><img src="/image/LLM/61.png" alt></p><p>cost and gradient functions for both linear and logistic regression. Note:</p><p>Cost</p><p>The cost functions differ significantly between linear and logistic regression, but adding regularization to the equations is the same.</p><p>Gradient</p><p>The gradient functions for linear and logistic regression are very similar. They differ only in the implementation of $f_{wb}$.</p><h2 id="çº¿æ€§å›å½’æ­£åˆ™åŒ–"><a href="#çº¿æ€§å›å½’æ­£åˆ™åŒ–" class="headerlink" title="çº¿æ€§å›å½’æ­£åˆ™åŒ–"></a>çº¿æ€§å›å½’æ­£åˆ™åŒ–</h2><p><img src="/image/LLM/62.png" alt><br><img src="/image/LLM/63.png" alt><br><img src="/image/LLM/64.png" alt></p><h2 id="é€»è¾‘å›å½’æ­£åˆ™åŒ–"><a href="#é€»è¾‘å›å½’æ­£åˆ™åŒ–" class="headerlink" title="é€»è¾‘å›å½’æ­£åˆ™åŒ–"></a>é€»è¾‘å›å½’æ­£åˆ™åŒ–</h2><p><img src="/image/LLM/65.png" alt><br><img src="/image/LLM/66.png" alt></p><h1 id="å®è·µæ¡ˆä¾‹"><a href="#å®è·µæ¡ˆä¾‹" class="headerlink" title="å®è·µæ¡ˆä¾‹"></a><a href="https://colab.research.google.com/github/kaieye/2022-Machine-Learning-Specialization/blob/main/Supervised%20Machine%20Learning%20Regression%20and%20Classification/week3/9.Week%203%20practice%20lab%20logistic%20regression/C1_W3_Logistic_Regression.ipynb#scrollTo=T8l3AKj8R29G" target="_blank" rel="noopener">å®è·µæ¡ˆä¾‹</a></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ&quot;&gt;&lt;a href=&quot;#ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ&quot; class=&quot;headerlink&quot; title=&quot;ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ&quot;&gt;&lt;/a&gt;ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ&lt;/h1&gt;&lt;p&gt;è®­ç»ƒå¾—åˆ°çš„é¢„æµ‹æ¨¡å‹å¯¹äºæ¯ä¸ªè®­ç»ƒæ•°æ®éƒ½éå¸¸å»åˆï¼Œå¯¼è‡´å¯¹äºæ–°çš„æµ‹è¯•æ•°æ®æ— æ³•æ­£ç¡®è¯„ä¼°çš„ç°è±¡ï¼Œå°±æ˜¯è¿‡æ‹Ÿåˆ&lt;br&gt;ä¸‹é¢
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
  <entry>
    <title>é€»è¾‘å›å½’æ¨¡å‹</title>
    <link href="http://yoohannah.github.io/post/machineLearning/logicRegression.html"/>
    <id>http://yoohannah.github.io/post/machineLearning/logicRegression.html</id>
    <published>2024-09-17T11:31:37.000Z</published>
    <updated>2024-11-11T08:48:06.196Z</updated>
    
    <content type="html"><![CDATA[<h1 id="èƒŒæ™¯-amp-amp-è§£å†³é—®é¢˜"><a href="#èƒŒæ™¯-amp-amp-è§£å†³é—®é¢˜" class="headerlink" title="èƒŒæ™¯&amp;&amp;è§£å†³é—®é¢˜"></a>èƒŒæ™¯&amp;&amp;è§£å†³é—®é¢˜</h1><p>é€»è¾‘å›å½’æ¨¡å‹æ—¶ä¸€ç§è§£å†³äºŒåˆ†ç±»é—®é¢˜çš„ç®—æ³•</p><p>å¦‚æœç”¨çº¿æ€§å›å½’å»è§£å†³åˆ†ç±»é—®é¢˜ï¼Œä¼šå¯¼è‡´è¿‡æ‹Ÿåˆå‡ºç°ï¼Œæ¯å¢åŠ ä¸€ä¸ªæµ‹è¯•æ•°æ®ï¼Œéƒ½å¯èƒ½å¯¼è‡´æ¨¡å‹å‘ç”Ÿå˜åŒ–</p><p><img src="/image/LLM/40.png" alt></p><p>é€šè¿‡ä½¿ç”¨sigmoid functionå‡½æ•°ï¼Œè®¾ç½®é˜ˆå€¼ï¼Œå¯ä»¥å°†çº¿æ€§å›å½’äº§ç”Ÿçš„ç»“æœå½’ç±»åˆ°ä¸¤ä¸ªç»“æœä¸Šå»</p><p><img src="/image/LLM/41.png" alt></p><p><img src="/image/LLM/42.png" alt></p><p>è™½ç„¶ç›®æ ‡æ˜¯äºŒåˆ†ç±»ï¼Œå³ç»“æœåªèƒ½æ˜¯0 æˆ–è€…1<br>ä½†æ˜¯f(w,b) = g(wÂ·x+b) è®¡ç®—çš„ç»“æœå€¼Aåªèƒ½æ— é™æ¥è¿‘è¿™ä¸¤ä¸ªå€¼<br>è¿™é‡Œå¯ä»¥å°†Aç†è§£æˆç»“æœæ˜¯1 çš„å¯èƒ½æ€§</p><p><img src="/image/LLM/43.png" alt></p><h2 id="å†³ç­–è¾¹ç•Œ"><a href="#å†³ç­–è¾¹ç•Œ" class="headerlink" title="å†³ç­–è¾¹ç•Œ"></a>å†³ç­–è¾¹ç•Œ</h2><p>åœ¨é€»è¾‘å›å½’æ¨¡å‹f(w,b) = g(wÂ·x+b)  ä¸­<br>z = wÂ·x+b åˆç§°ä¸º å†³ç­–è¾¹ç•Œï¼Œå°†ä¸åŒç»“æœçš„æ•°æ®åœ¨åæ ‡ç³»ä¸­è¿›è¡Œéš”ç¦»<br>å¦‚æœç‰¹å¾åœ¨z ä¸­æ²¡æœ‰å¤šé¡¹å¼è¿ç®—ï¼Œé‚£ä¹ˆï¼Œå¾—åˆ°çš„è¾¹ç•Œå¿…å®šæ˜¯ç›´çº¿çš„ï¼Œä½†æ˜¯å¦‚æœæœ‰å¤šé¡¹å¼ï¼Œæ‹¿å¾—åˆ°çš„è¾¹ç•Œçº¿å°±æ˜¯éçº¿æ€§çš„<br><img src="/image/LLM/44.png" alt><br><img src="/image/LLM/45.png" alt><br><img src="/image/LLM/46.png" alt><br><img src="/image/LLM/47.png" alt></p><h2 id="æˆæœ¬å‡½æ•°"><a href="#æˆæœ¬å‡½æ•°" class="headerlink" title="æˆæœ¬å‡½æ•°"></a>æˆæœ¬å‡½æ•°</h2><p>çº¿æ€§å›å½’çš„å¹³æ–¹è¯¯å·®ç®—æ³•çš„æˆæœ¬å‡½æ•°åœ¨åº”ç”¨åˆ°é€»è¾‘å›å½’æ—¶ï¼Œä¼šäº§ç”Ÿå¤šä¸ªå±€éƒ¨æœ€å°å€¼ï¼Œå†ç”¨æ¢¯åº¦ä¸‹é™çš„ç®—æ³•å»æ‰¾å‚æ•°æ—¶ï¼Œæ— æ³•æ‰¾åˆ°æœ€å°å€¼</p><p><img src="/image/LLM/48.png" alt></p><p>é€»è¾‘å›å½’å¼•å…¥é€»è¾‘æŸå¤±å‡½æ•°ï¼Œæ ¹æ®å•ä¸ªæ•°æ®é›†éšå‚æ•°å˜åŒ–çš„è¶‹åŠ¿ï¼Œåˆ¤æ–­æ•´ä½“çš„å˜åŒ–è¶‹åŠ¿<br>æ“ä½œå°±æ˜¯å°†åŸæœ¬å¹³æ–¹è¯¯å·®é™¤ä»¥2çš„æ“ä½œç§»åˆ°æ±‚å’Œä¹‹å‰ï¼Œå•ç‹¬è®¡ç®—æ¯ä¸ªç‰¹å¾å€¼çš„éƒ¨åˆ†å°±æ˜¯æŸå¤±å‡½æ•°</p><p>Logistic Regression uses a loss function more suited to the task of categorization where the target is 0 or 1 rather than any number.</p><p>these definitions are used:</p><p>Loss is a measure of the difference of a single example to its target value while the</p><p>Cost is a measure of the losses over the training set</p><p>ä¸‹é¢æ˜¯æ¨å¯¼è¿‡ç¨‹å’Œæœ€ç»ˆçš„å¼å­</p><p><img src="/image/LLM/49.png" alt><br><img src="/image/LLM/50.png" alt><br><img src="/image/LLM/51.png" alt><br><img src="/image/LLM/52.png" alt><br><img src="/image/LLM/53.png" alt></p><h2 id="æ¢¯åº¦ä¸‹é™æ‰¾åˆ°w-amp-b"><a href="#æ¢¯åº¦ä¸‹é™æ‰¾åˆ°w-amp-b" class="headerlink" title="æ¢¯åº¦ä¸‹é™æ‰¾åˆ°w&amp;b"></a>æ¢¯åº¦ä¸‹é™æ‰¾åˆ°w&amp;b</h2><p><img src="/image/LLM/54.png" alt><br><img src="/image/LLM/55.png" alt><br><img src="/image/LLM/56.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;èƒŒæ™¯-amp-amp-è§£å†³é—®é¢˜&quot;&gt;&lt;a href=&quot;#èƒŒæ™¯-amp-amp-è§£å†³é—®é¢˜&quot; class=&quot;headerlink&quot; title=&quot;èƒŒæ™¯&amp;amp;&amp;amp;è§£å†³é—®é¢˜&quot;&gt;&lt;/a&gt;èƒŒæ™¯&amp;amp;&amp;amp;è§£å†³é—®é¢˜&lt;/h1&gt;&lt;p&gt;é€»è¾‘å›å½’æ¨¡å‹æ—¶ä¸€ç§è§£å†³äºŒåˆ†ç±»é—®é¢˜
      
    
    </summary>
    
    
      <category term="machineLearning" scheme="http://yoohannah.github.io/tags/machineLearning/"/>
    
  </entry>
  
</feed>
